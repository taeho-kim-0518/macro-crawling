import pandas as pd
import numpy as np
import requests
import matplotlib
import yfinance as yf
from bs4 import BeautifulSoup
from scipy.stats import linregress
from io import StringIO
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.core.os_manager import ChromeType
import streamlit as st
import time
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
import os
from dotenv import load_dotenv
import time
import seaborn as sns

# load_dotenv()


# API_KEY = os.getenv("FRED_API_KEY")
# EIA_API_KEY = os.getenv("EIA_API_KEY")

# secrets.tomlì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
API_KEY = st.secrets["FRED_API_KEY"]
EIA_API_KEY = st.secrets["EIA_API_KEY"]


@st.cache_resource
def get_driver():
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")

    driver = webdriver.Chrome(
        service=Service(
            ChromeDriverManager(chrome_type=ChromeType.CHROMIUM).install()
        ),
        options=options,
    )
    return driver
   

def get_10years_treasury_yeild():
    url = 'https://api.stlouisfed.org/fred/series/observations'
    params = {
        'series_id' : 'GS10', # 10ë…„ë¬¼ êµ­ì±„ ê¸ˆë¦¬
        'api_key' : API_KEY,
        'file_type' : 'json',
        'observation_start' : '2000-01-01' # ì‹œì‘ì¼(ì›í•˜ëŠ” ë‚ ì§œì§œ)
    }

    try:
        response = requests.get(url, params= params, timeout=10)
        response.raise_for_status() # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
        data = response.json()

        if 'observations' not in data:
            raise ValueError(F"'observations' í‚¤ê°€ ì—†ìŒ : {data}")

        # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
        df = pd.DataFrame(data['observations'])
        df['date'] = pd.to_datetime(df['date'])
        df['value'] = pd.to_numeric(df['value'], errors= 'coerce')

        return df
    
    except Exception as e:
        print(f"[ERROR] FRED API í˜¸ì¶œ ì‹¤íŒ¨ : {e}")
        return pd.DataFrame()


def get_2years_treasury_yeild():
    url = 'https://api.stlouisfed.org/fred/series/observations'
    params = {
        'series_id' : 'GS2', # 2ë…„ë¬¼ êµ­ì±„ ê¸ˆë¦¬
        'api_key' : API_KEY,
        'file_type' : 'json',
        'observation_start' : '2000-01-01' # ì‹œì‘ì¼(ì›í•˜ëŠ” ë‚ ì§œì§œ)
    }

    response = requests.get(url, params= params)
    data = response.json()

    # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
    df = pd.DataFrame(data['observations'])
    df['date'] = pd.to_datetime(df['date'])
    df['value'] = pd.to_numeric(df['value'], errors= 'coerce')

    return df

def get_cpi():
    url = 'https://api.stlouisfed.org/fred/series/observations'
    params = {
        'series_id': 'CPIAUCSL',  # CPI
        'api_key': API_KEY,
        'file_type': 'json',
        'observation_start': '2000-01-01'
    }
    response = requests.get(url, params=params)
    data = response.json()
    df = pd.DataFrame(data['observations'])
    df['date'] = pd.to_datetime(df['date'])
    df['value'] = pd.to_numeric(df['value'], errors='coerce')
    return df

def get_cpi_yoy():
    df = get_cpi() # ì›ë˜ CPIAUCSL ì§€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
    df = df.sort_values('date').dropna()

    df['CPI YOY(%)'] = df['value'].pct_change(periods=12)*100 # 12ê°œì›” ì „ ëŒ€ë¹„ ë³€í™”ìœ¨
    return df

def get_m2() : 
    url = 'https://api.stlouisfed.org/fred/series/observations'
    params = {
        'series_id': 'M2SL',  # M2 í†µí™”ëŸ‰
        'api_key': API_KEY,
        'file_type': 'json',
        'observation_start': '2000-01-01'
    }

    response = requests.get(url, params=params)
    data = response.json()
    df = pd.DataFrame(data['observations'])
    df['date'] = pd.to_datetime(df['date'])
    df['value'] = pd.to_numeric(df['value'], errors='coerce')
    return df

def get_m2_yoy():
    df = get_m2()
    df = df.sort_values('date')
    df['m2_yoy'] = df['value'].pct_change(periods=12) * 100
    return df[['date', 'm2_yoy']]

def analyze_m2_investment_signal(m2_df, m2_yoy_df, cpi_df):
    """
    M2, M2 YoY, CPI YoYë¥¼ ë°”íƒ•ìœ¼ë¡œ ìœ ë™ì„± í™˜ê²½ í‰ê°€ ë° íˆ¬ì ì‹œê·¸ë„ ë¶„ì„
    """
    # ìµœì‹  ê³µí†µ ë‚ ì§œë¡œ ë³‘í•©
    df = pd.merge(m2_df, m2_yoy_df, on='date', how='inner')
    df = pd.merge(df, cpi_df[['date', 'CPI YOY(%)']], on='date', how='inner')
    df = df.dropna().sort_values('date')

    latest = df.iloc[-1]
    m2_val = latest['value']
    m2_yoy = latest['m2_yoy']
    cpi_yoy = latest['CPI YOY(%)']
    date = latest['date'].date()

    signal = [f"ğŸ“… ê¸°ì¤€ì¼: {date}"]
    signal.append(f"ğŸ’° M2 ìˆ˜ì¤€: {m2_val:,.2f}")
    signal.append(f"ğŸ“ˆ M2 YoY: {m2_yoy:.2f}%")
    signal.append(f"ğŸ·ï¸ CPI YoY: {cpi_yoy:.2f}%")
    signal.append("---")

    # ì‹œê·¸ë„ í•´ì„
    if m2_yoy > 5 and cpi_yoy < 3:
        signal.append("ğŸŸ¢ ìœ ë™ì„± í’ë¶€ + ì¸í”Œë ˆ ì•ˆì • â†’ **ì„±ì¥ì£¼/ì£¼ì‹ì‹œì¥ í˜¸ì¬**")
    elif m2_yoy < 0:
        signal.append("ğŸ”´ ìœ ë™ì„± ì¶•ì†Œ (QT) ê²½ê³  â†’ **í˜„ê¸ˆ ë¹„ì¤‘ í™•ëŒ€ ê³ ë ¤**")
    elif m2_yoy < 2 and cpi_yoy > 4:
        signal.append("ğŸŸ  ì¸í”Œë ˆ ê³ ì¡° + ìœ ë™ì„± ì •ì²´ â†’ **ë°©ì–´ì  ìì‚° ì„ í˜¸ êµ¬ê°„**")
    else:
        signal.append("âšª ì¤‘ë¦½ êµ­ë©´ â†’ **ì¶”ê°€ í™•ì¸ í•„ìš”** (ì‹¤ì—…ë¥ , ê¸ˆë¦¬, PER ë“±ê³¼ ì¢…í•© ê³ ë ¤)")

    return "\n".join(signal)




def get_high_yield_spread():
    url = 'https://api.stlouisfed.org/fred/series/observations'
    params = {
        'series_id': 'BAMLH0A0HYM2',  # í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œ
        'api_key': API_KEY,
        'file_type': 'json',
        'observation_start': '2000-01-01'
    }
    response = requests.get(url, params=params)
    data = response.json()
    df = pd.DataFrame(data['observations'])
    df['date'] = pd.to_datetime(df['date'])
    df['value'] = pd.to_numeric(df['value'], errors='coerce')
    return df

def check_high_yield_spread_warning(df):
    """
    í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œ ë°ì´í„°í”„ë ˆì„ì„ ë°›ì•„
    ìµœì‹ ê°’ê³¼ ì „ì¼ ëŒ€ë¹„ ë³€í™”ìœ¨ì„ ì²´í¬í•´ ê²½ê³ ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
    """
    df = df.dropna(subset=['value'])  # NaN ì œê±°
    df = df.sort_values('date')       # ë‚ ì§œìˆœ ì •ë ¬
    
    today_row = df.iloc[-1]
    yesterday_row = df.iloc[-2]
    
    today_value = today_row['value']
    yesterday_value = yesterday_row['value']
    
    change = today_value - yesterday_value  # ë³€í™”ëŸ‰ (í¬ì¸íŠ¸)

    messages = []
    messages.append(f"ğŸ” í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œ ì˜¤ëŠ˜({today_row['date'].date()}) ê°’: {today_value:.2f}%")
    messages.append(f"ğŸ” ì–´ì œ({yesterday_row['date'].date()}) ëŒ€ë¹„ ë³€í™”: {change:+.2f}p")
    
    if today_value >= 7:
        messages.append("ğŸš¨ í•˜ë½ì¥ ê²½ê³ : í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œê°€ 7%ë¥¼ ë„˜ì—ˆìŠµë‹ˆë‹¤!")
    elif today_value >= 5:
        messages.append("âš ï¸ ì¡°ì •ì¥ ê²½ê³ : í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œê°€ 5%ë¥¼ ë„˜ì—ˆìŠµë‹ˆë‹¤!")
    
    if change >= 0.5:
        messages.append("âš¡ ê¸‰ë“± ê²½ê³ : í•˜ë£¨ ë§Œì— ìŠ¤í”„ë ˆë“œê°€ 0.5%p ì´ìƒ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤!")
    
    if (today_value < yesterday_value) and (today_value >= 5):
        messages.append("ğŸ“ˆ ì €ì  ë§¤ìˆ˜ ê°€ëŠ¥ì„± ì‹ í˜¸: ìŠ¤í”„ë ˆë“œê°€ êº¾ì´ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤!")

    return "\n".join(messages)

def get_dollar_index(period="10y"):
    """
    ë‹¬ëŸ¬ ì¸ë±ìŠ¤ (DXY) ë°ì´í„°ë¥¼ yfinanceì—ì„œ ê°€ì ¸ì™€ì„œ DataFrameìœ¼ë¡œ ë°˜í™˜
    period: '1d', '5d', '1mo', '3mo', '6mo', '1y', etc.
    """
    ticker = "DX-Y.NYB"  # yfinance ìƒ DXY ì‹¬ë³¼ (ICE ì„ ë¬¼ì‹œì¥ìš©)
    df = yf.download(ticker, period=period, interval="1d", progress=False)
    df = df.reset_index()

    # ì»¬ëŸ¼ ì •ë¦¬ : ì»¬ëŸ¼ ì´ë¦„ì„ í‘œì¤€í™”
    df = df[['Date', 'Close']].rename(columns={'Date': 'date', 'Close': 'dxy'})
    df['date'] = pd.to_datetime(df['date'])
    return df

def get_snp_inedx(period="10y"):
    
    ticker = '^GSPC'
    df = yf.download(ticker, period=period, interval="1d", progress=False )
    df = df.reset_index()
    df = df[['Date', 'Close']].rename(columns={'Date': 'date', 'Close': 'snp500'})
    df['date'] = pd.to_datetime(df['date'])
    return df

def get_yen_index(period="10y"):
    """
    ì—”í™” ì¸ë±ìŠ¤ (FXY) ETF ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
    - FXYëŠ” ì¼ë³¸ ì—”í™” ê°•ì„¸ì— íˆ¬ìí•˜ëŠ” ETF
    """
    ticker = 'FXY'
    df = yf.download(ticker, period=period, interval='1d', progress=False)
    df = df.reset_index()
    df = df[['Date', 'Close']].rename(columns={'Date': 'date', 'Close': 'yen_index'})
    df['date'] = pd.to_datetime(df['date'])
    return df

def get_japan_policy_rate(api_key: str = API_KEY, start_date="2015-05-18"):
    """
    ì¼ë³¸ ê¸°ì¤€ê¸ˆë¦¬ ë°ì´í„°ë¥¼ FRED APIì—ì„œ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
    API KeyëŠ” FRED í™ˆí˜ì´ì§€ì—ì„œ ë¬´ë£Œ ë°œê¸‰ ê°€ëŠ¥
    """
    url = "https://api.stlouisfed.org/fred/series/observations"
    params = {
        'series_id': 'IRLTLT01JPM156N',  # â† ë°”ë€ ì‹œë¦¬ì¦ˆ ID!
        'api_key': api_key,
        'file_type': 'json',
        'observation_start': start_date
    }

    response = requests.get(url, params=params)
    data = response.json()

    # ì—ëŸ¬ í•¸ë“¤ë§ë§
    if 'observations' not in data:
        raise ValueError(f"API ì˜¤ë¥˜: {data.get('error_message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ì…ë‹ˆë‹¤.')}")

    df = pd.DataFrame(data['observations'])
    df['date'] = pd.to_datetime(df['date'])
    df['japan_policy_rate'] = pd.to_numeric(df['value'], errors='coerce')
    df = df[['date', 'japan_policy_rate']]
    return df



# as-js
# def get_bull_bear_spread():
#     url = ""

#     options = Options()
#     options.add_argument("--headless")
#     options.add_argument("--disable-gpu")
#     options.add_argument("--no-sandbox")

#     driver = webdriver.Chrome(options=options)
#     driver.get(url)
#     time.sleep(5)  # JS ë¡œë”© ëŒ€ê¸°

#     soup = BeautifulSoup(driver.page_source, "html.parser")
#     driver.quit()

#     # "Last Value" í…ìŠ¤íŠ¸ê°€ ìˆëŠ” td ì°¾ê¸°
#     for td in soup.select("td.col-6"):
#         if "Last Value" in td.get_text(strip=True):
#             value_td = td.find_next_sibling("td")
#             if value_td:
#                 return value_td.get_text(strip=True)

#     return None


def get_bull_bear_spread():
    url = "https://ycharts.com/indicators/us_investor_sentiment_bull_bear_spread"

    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")

    # as-js
    # driver = webdriver.Chrome(
    #     service=Service(ChromeDriverManager().install()),
    #     options=options
    # )

    driver = webdriver.Chrome(service=Service(), options=options)
    # driver = webdriver.Chrome(service=Service())

    driver.get(url)
    time.sleep(5)  # JS ë Œë”ë§ ëŒ€ê¸°

    soup = BeautifulSoup(driver.page_source, "html.parser")
    
    for td in soup.select("td.col-6"):
        if "Last Value" in td.get_text(strip=True):
            value_td = td.find_next_sibling("td")
            if value_td:
                return value_td.get_text(strip=True)
            
    return None


def analyze_bull_bear_spread(index):
    '''
    bull-bear ìŠ¤í”„ë ˆë“œ ë¶„ì„(ì—­ë°œìƒ ì§€í‘œ)
    -20ì¼ ê²½ìš° ë§¤ìˆ˜ íƒ€ì´ë°
    -30ì´ë©´ ì ê·¹ ë§¤ìˆ˜ íƒ€ì´ë°
    '''

    try:
        index = float(index.replace('%', '').strip())
    except ValueError:
        return f"âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ì…ë‹ˆë‹¤: {index}"

    messages = []
    messages.append(f"ğŸ” bull-bear ìŠ¤í”„ë ˆë“œ í˜„ì¬ê°’: {index:.2f}%")

    if index <= -30:
        messages.append("âœ… ì ê·¹ ë§¤ìˆ˜ ê¸°íšŒ: ìŠ¤í”„ë ˆë“œê°€ -30 ì´í•˜ì…ë‹ˆë‹¤.")
    elif index <= -20:
        messages.append("âœ… ë§¤ìˆ˜ ê¸°íšŒ: ìŠ¤í”„ë ˆë“œê°€ -20 ì´í•˜ì…ë‹ˆë‹¤.")
    else:
        messages.append("âš ï¸ íŒë‹¨ ë³´ë¥˜: ì¤‘ë¦½ ë˜ëŠ” ê³¼ì—´ êµ¬ê°„ì…ë‹ˆë‹¤.")

    return "\n".join(messages)
    

def get_equity_put_call_ratio():
    url = 'https://ycharts.com/indicators/cboe_equity_put_call_ratio'

    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")

    driver = webdriver.Chrome(options=options)
    driver.get(url)
    time.sleep(5)  # JS ë¡œë”© ëŒ€ê¸°

    soup = BeautifulSoup(driver.page_source, 'html.parser')
    driver.quit()

     # "Last Value" í…ìŠ¤íŠ¸ê°€ ìˆëŠ” td ì°¾ê¸°
    for td in soup.select("td.col-6"):
        if "Last Value" in td.get_text(strip=True):
            value_td = td.find_next_sibling("td")
            if value_td:
                return value_td.get_text(strip=True)

    return None

#as-js
def get_index_put_call_ratio():
    url = 'https://ycharts.com/indicators/cboe_index_put_call_ratio'

    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")

    driver = webdriver.Chrome(options=options)
    driver.get(url)
    time.sleep(5)  # JS ë¡œë”© ëŒ€ê¸°

    soup = BeautifulSoup(driver.page_source, 'html.parser')
    driver.quit()

     # "Last Value" í…ìŠ¤íŠ¸ê°€ ìˆëŠ” td ì°¾ê¸°
    for td in soup.select("td.col-6"):
        if "Last Value" in td.get_text(strip=True):
            value_td = td.find_next_sibling("td")
            if value_td:
                return value_td.get_text(strip=True)

    return None



def get_equity_put_call_trend(days=20):
    url = 'https://ycharts.com/indicators/cboe_equity_put_call_ratio'

    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")

    driver = webdriver.Chrome(options=options)
    driver.get(url)

    try:
        # í…Œì´ë¸”ì˜ ì–´ë–¤ í–‰ì´ë¼ë„ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "table tbody tr"))
        )
    except Exception as e:
        print("âŒ í…Œì´ë¸” ë¡œë”© ì‹¤íŒ¨:", e)
        driver.quit()
        return pd.DataFrame()

    soup = BeautifulSoup(driver.page_source, 'html.parser')
    driver.quit()

    # ëª¨ë“  í…Œì´ë¸”ì˜ í–‰ì„ ì„ íƒí•©ë‹ˆë‹¤.
    rows = soup.select("table tbody tr")
    print(f"âœ… ì¶”ì¶œëœ row ìˆ˜: {len(rows)}")

    data = []
    for row in rows:
        cols = row.find_all("td")
        if len(cols) == 2:
            date = cols[0].get_text(strip=True)
            value = cols[1].get_text(strip=True)
            try:
                data.append((pd.to_datetime(date), float(value)))
            except ValueError:
                # ë‚ ì§œë‚˜ ê°’ì´ ìœ íš¨í•˜ì§€ ì•Šì€ í–‰ì€ ê±´ë„ˆëœë‹ˆë‹¤.
                continue

    df = pd.DataFrame(data, columns=["date", "value"])
    # ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•˜ì—¬ ìµœì‹  'days'ë§Œí¼ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¨ í›„, ë‹¤ì‹œ ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤.
    df = df.sort_values("date", ascending=False).head(days).sort_values("date")
    return df

def get_index_put_call_trend(days=20):
    url = 'https://ycharts.com/indicators/cboe_index_put_call_ratio'

    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")

    driver = webdriver.Chrome(options=options)
    driver.get(url)

    try:
        # í…Œì´ë¸”ì˜ ì–´ë–¤ í–‰ì´ë¼ë„ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "table tbody tr"))
        )
    except Exception as e:
        print("âŒ í…Œì´ë¸” ë¡œë”© ì‹¤íŒ¨:", e)
        driver.quit()
        return pd.DataFrame()

    soup = BeautifulSoup(driver.page_source, 'html.parser')
    driver.quit()

    # ëª¨ë“  í…Œì´ë¸”ì˜ í–‰ì„ ì„ íƒí•©ë‹ˆë‹¤.
    rows = soup.select("table tbody tr")
    print(f"âœ… ì¶”ì¶œëœ row ìˆ˜: {len(rows)}")

    data = []
    for row in rows:
        cols = row.find_all("td")
        if len(cols) == 2:
            date = cols[0].get_text(strip=True)
            value = cols[1].get_text(strip=True)
            try:
                data.append((pd.to_datetime(date), float(value)))
            except ValueError:
                # ë‚ ì§œë‚˜ ê°’ì´ ìœ íš¨í•˜ì§€ ì•Šì€ í–‰ì€ ê±´ë„ˆëœë‹ˆë‹¤.
                continue

    df = pd.DataFrame(data, columns=["date", "value"])
    # ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•˜ì—¬ ìµœì‹  'days'ë§Œí¼ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¨ í›„, ë‹¤ì‹œ ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤.
    df = df.sort_values("date", ascending=False).head(days).sort_values("date")
    return df


def analyze_put_call_ratio_trend(df):
    if df.empty or len(df) < 2:
        return "ë°ì´í„° ë¶€ì¡± (ì¶”ì„¸ ë¶„ì„ ë¶ˆê°€)"

    # ë‚ ì§œë¥¼ ìˆ«ìë¡œ ë³€í™˜ (ì˜ˆ: 1, 2, 3...)
    x = np.arange(len(df))
    y = df['value'].values

    # ì„ í˜• íšŒê·€ ìˆ˜í–‰
    slope, intercept, r_value, p_value, std_err = linregress(x, y)

    trend_status = ""
    
    if slope > 0.001:  # ì–‘ì˜ ê¸°ìš¸ê¸°ê°€ ìœ ì˜ë¯¸í•œ ê²½ìš°
        trend_status = "ìƒìŠ¹ ì¶”ì„¸ (Increasing Trend)"
    elif slope < -0.001: # ìŒì˜ ê¸°ìš¸ê¸°ê°€ ìœ ì˜ë¯¸í•œ ê²½ìš°
        trend_status = "í•˜ë½ ì¶”ì„¸ (Decreasing Trend)"
    else: # ê¸°ìš¸ê¸°ê°€ ê±°ì˜ 0ì¸ ê²½ìš°
        trend_status = "íš¡ë³´ ì¶”ì„¸ (Sideways Trend)"

    return {
        "ê¸°ìš¸ê¸° (Slope)": round(slope, 4),
        "ì¶”ì„¸ ìƒíƒœ": trend_status,
        "R-squared": round(r_value**2, 4) # ì„¤ëª…ë ¥ (0~1, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì„ í˜• ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ì˜ ì„¤ëª…)
    }


def check_put_call_ratio_warning(data, ratio_type):
    """
    í’‹ì½œ ë ˆì´í‹°ì˜¤ ë°ì´í„°ë¥¼ ë°›ì•„ì™€ì„œì„œ
    ë§¤ìˆ˜ í˜¹ì€ ë§¤ë„ ì‹œì ì„ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜

    ratio_type : equity, index ë‘˜ ì¤‘ í•˜ë‚˜ ì…ë ¥
    """

    put_call_ratio = float(data)

    messages = [f"ğŸ“Š Equity Put/Call Ratio: {put_call_ratio}"]

    # ê°„ë‹¨í•œ ì‹œê·¸ë„ íŒë‹¨

    if ratio_type == "equity":
    
        if put_call_ratio > 1.0:
            messages.append("ğŸ“‰ Equity: ê³µí¬ì‹¬ ê³¼ë‹¤ â†’ ë°˜ë“± ê°€ëŠ¥ì„± (ë§¤ìˆ˜ ì‹œì  íƒìƒ‰)")
        elif put_call_ratio < 0.7:
            messages.append("ğŸš¨ Equity: ê³¼ì—´ íƒìš• ìƒíƒœ â†’ ë§¤ë„ ê²½ê³  ë˜ëŠ” ì¡°ì • ê°€ëŠ¥ì„±")
        else:
            messages.append("âš–ï¸ Equity: ì¤‘ë¦½ êµ¬ê°„")

    elif ratio_type == "index":

        if put_call_ratio > 1.5:
            messages.append("ğŸ“‰ Index: í—¤ì§€ ìˆ˜ìš” ê³¼ë„ â†’ ë°˜ë“± ê°€ëŠ¥ì„± â†‘")
        elif put_call_ratio < 0.7:
            messages.append("ğŸš¨ Index: ìƒìŠ¹ ë² íŒ… ê³¼ë‹¤ â†’ ê³¼ì—´ ìœ„í—˜ â†‘")
        else:
            messages.append("âš–ï¸ Index: ì¤‘ë¦½ êµ¬ê°„")

    else:
        messages.append("âŒ ì˜¤ë¥˜: ratio_typeì€ 'equity' ë˜ëŠ” 'index'ë§Œ ê°€ëŠ¥")
        
    return "\n".join(messages)

def get_fed_funds_rate():
    '''
    ë¯¸êµ­ ê¸°ì¤€ ê¸ˆë¦¬ ê³„ì‚°
    '''
    url = 'https://api.stlouisfed.org/fred/series/observations'
    params = {
        'series_id': 'FEDFUNDS',
        'api_key': API_KEY,
        'file_type': 'json',
        'observation_start': '2000-01-01'
    }
    response = requests.get(url, params=params)
    data = response.json()
    df = pd.DataFrame(data['observations'])
    df['date'] = pd.to_datetime(df['date'])
    df['fed_funds_rate'] = pd.to_numeric(df['value'], errors='coerce')
    return df

def get_vix_index(period='10y'):
    df = yf.download('^VIX', period=period, interval='1d', progress=False)
    df = df.reset_index()
    df = df[['Date', 'Close']].rename(columns={'Date': 'date', 'Close': 'vix'})
    df['date'] = pd.to_datetime(df['date'])
    return df

def analyze_vix():
    df_vix = get_vix_index()
    df_vix = df_vix.sort_values('date')
    latest = df_vix.iloc[-1]

    date = latest['date']
    vix = float(latest['vix'])  # â† ì—¬ê¸°ì„œ float ë³€í™˜

    result = [f"ğŸ“… ê¸°ì¤€ì¼: {date}",
              f"ğŸ“Š VIX ì§€ìˆ˜ (S&P 500 ë³€ë™ì„±): {vix:.2f}"]

    if vix < 12:
        result.append("ğŸ“‰ ê³¼ë„í•œ ë‚™ê´€ ìƒíƒœ â†’ ì €ë³€ë™ì„± í™˜ê²½ (ê³ ì  ê²½ê³„ ê°€ëŠ¥ì„±)")
    elif vix < 20:
        result.append("ğŸŸ¢ ì‹œì¥ì´ ì•ˆì •ì ì¸ ìƒíƒœ (ë‚™ê´€ì  ì‹¬ë¦¬)")
    elif vix < 30:
        result.append("ğŸŸ  ì‹œì¥ ë¶ˆí™•ì‹¤ì„± ì¦ê°€ â†’ íˆ¬ìì ì£¼ì˜ í•„ìš”")
    else:
        result.append("ğŸ”´ ê·¹ë‹¨ì  ê³µí¬ ìƒíƒœ â†’ ê³¼ë§¤ë„/ì €ì  ë°˜ë“± ê°€ëŠ¥ì„± (ì—­ë°œìƒ ë§¤ìˆ˜ ê³ ë ¤ êµ¬ê°„)")

    return "\n".join(result)

def analyze_real_rate_and_yield_spread():
    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    df_10y = get_10years_treasury_yeild()
    df_2y = get_2years_treasury_yeild()
    df_cpi_yoy = get_cpi_yoy()
    df_fed = get_fed_funds_rate()

    # ë‚ ì§œ ì •ë ¬
    df_10y = df_10y.sort_values("date")
    df_2y = df_2y.sort_values("date")
    df_cpi_yoy = df_cpi_yoy.sort_values("date")
    df_fed = df_fed.sort_values("date")

    # ë³‘í•©
    merged = pd.merge(df_10y, df_2y, on='date', suffixes=('_10y', '_2y'), how='inner')
    merged = pd.merge(merged, df_cpi_yoy[['date', 'CPI YOY(%)']], on='date', how='inner')
    merged = pd.merge(merged, df_fed[['date', 'fed_funds_rate']], on='date', how='inner')
    merged = merged.dropna()

    # ê°€ì¥ ìµœê·¼ ê°’ ì¶”ì¶œ
    latest = merged.iloc[-1]
    date = latest['date'].date()
    rate_10y = latest['value_10y']
    rate_2y = latest['value_2y']
    fed_rate = latest['fed_funds_rate']
    cpi_yoy = latest['CPI YOY(%)']

    # ê³„ì‚°
    real_rate_long = rate_10y - cpi_yoy        # ì¥ê¸° ì‹¤ì§ˆê¸ˆë¦¬
    real_rate_short = fed_rate - cpi_yoy       # ë‹¨ê¸° ì‹¤ì§ˆê¸ˆë¦¬
    yield_spread = rate_10y - rate_2y          # ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨

    # ì¶œë ¥ ë©”ì‹œì§€
    result = [f"ğŸ“… ê¸°ì¤€ì¼: {date}",
              f"ğŸ“ˆ 10ë…„ë¬¼ êµ­ì±„ê¸ˆë¦¬: {rate_10y:.2f}%",
              f"ğŸ“‰ 2ë…„ë¬¼ êµ­ì±„ê¸ˆë¦¬: {rate_2y:.2f}%",
              f"ğŸ”º ë¯¸êµ­ ê¸°ì¤€ê¸ˆë¦¬ (Fed Funds): {fed_rate:.2f}%",
              f"ğŸ“Š CPI YoY: {cpi_yoy:.2f}%",
              f"ğŸ’¡ ì¥ê¸° ì‹¤ì§ˆê¸ˆë¦¬ (10Y - CPI YoY): {real_rate_long:.2f}%",
              f"ğŸ’¡ ë‹¨ê¸° ì‹¤ì§ˆê¸ˆë¦¬ (ê¸°ì¤€ê¸ˆë¦¬ - CPI YoY): {real_rate_short:.2f}%",
              f"ğŸ”€ ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨ (10Y - 2Y): {yield_spread:.2f}%"]

    # ì¥ê¸° ì‹¤ì§ˆê¸ˆë¦¬ í•´ì„
    if real_rate_long < 0:
        result.append("ğŸŸ¦ ì¥ê¸° ì‹¤ì§ˆê¸ˆë¦¬ < 0 â†’ ìœ ë™ì„± í’ë¶€í•œ í™˜ê²½ â†’ ì„±ì¥ì£¼ ìš°í˜¸")
    elif real_rate_long <= 1.5:
        result.append("âš–ï¸ ì¥ê¸° ì‹¤ì§ˆê¸ˆë¦¬ 0~1.5% â†’ ê· í˜• ì¡íŒ ì‹œì¥ í™˜ê²½ â†’ ì¤‘ë¦½ ë˜ëŠ” ì ì§„ì  ê¸´ì¶•")
    else:
        result.append("ğŸŸ¥ ì¥ê¸° ì‹¤ì§ˆê¸ˆë¦¬ > 1.5% â†’ í• ì¸ìœ¨ ë¶€ë‹´ ì»¤ì§ â†’ ì£¼ì‹ì‹œì¥ ì—­í’ ìš°ë ¤")

    # ë‹¨ê¸° ì‹¤ì§ˆê¸ˆë¦¬ í•´ì„
    if real_rate_short < 0:
        result.append("ğŸŸ© ë‹¨ê¸° ì‹¤ì§ˆê¸ˆë¦¬ < 0 â†’ ì—¬ì „íˆ ì™„í™”ì  í†µí™”ì •ì±… (ìœ ë™ì„± ê³µê¸‰)")
    elif real_rate_short <= 1.5:
        result.append("âš–ï¸ ë‹¨ê¸° ì‹¤ì§ˆê¸ˆë¦¬ 0~1.5% â†’ ì¤‘ë¦½ì  ì •ì±… í™˜ê²½")
    else:
        result.append("ğŸŸ¥ ë‹¨ê¸° ì‹¤ì§ˆê¸ˆë¦¬ > 1.5% â†’ ëª…í™•í•œ ê¸´ì¶• í™˜ê²½ â†’ íˆ¬ìì ë¹„ìš© ë¶€ë‹´ ìƒìŠ¹")

    # ê¸ˆë¦¬ì°¨ í•´ì„
    if yield_spread < 0:
        result.append("ğŸŸ§ ì¥ë‹¨ê¸° ê¸ˆë¦¬ ì—­ì „ â†’ ê²½ê¸° ì¹¨ì²´ ì „ì¡° (6~12ê°œì›” í›„ ì¹¨ì²´ ê°€ëŠ¥ì„±)")
    else:
        result.append("ğŸŸ© ì¥ë‹¨ê¸° ê¸ˆë¦¬ ì •ìƒ êµ¬ì¡° â†’ ê²½ê¸° í™•ì¥ ê°€ëŠ¥ì„±")

    return "\n".join(result)


def get_ecri_leading_index_with_trend(days=20):
    url = 'https://api.stlouisfed.org/fred/series/observations'
    params = {
        'series_id': 'USSLIND',
        'api_key': API_KEY,
        'file_type': 'json',
        'observation_start': '2000-01-01'
    }

    response = requests.get(url, params=params)
    data = response.json()

    if 'observations' not in data:
        print("âŒ ìš”ì²­ ì‹¤íŒ¨:", data.get('error_message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'))
        return None, "ë°ì´í„° ìˆ˜ì‹  ì‹¤íŒ¨"

    df = pd.DataFrame(data['observations'])
    df['date'] = pd.to_datetime(df['date'])
    df['value'] = pd.to_numeric(df['value'], errors='coerce')
    df = df.dropna().sort_values("date").reset_index(drop=True)

    # ìµœê·¼ days ì£¼ ë™ì•ˆ ì¶”ì„¸ ë¶„ì„
    if len(df) >= days:
        recent = df.tail(days)
        x = np.arange(len(recent))
        y = recent['value'].values
        slope, intercept, r_value, p_value, std_err = linregress(x, y)

        if slope > 0.05:
            trend = "ğŸ“ˆ ìƒìŠ¹ ì¶”ì„¸ (íšŒë³µ ì¡°ì§)"
        elif slope < -0.05:
            trend = "ğŸ“‰ í•˜ë½ ì¶”ì„¸ (ê²½ê¸° ë‘”í™”)"
        else:
            trend = "â– íš¡ë³´ ì¶”ì„¸ (ë¶ˆí™•ì‹¤ì„± ì§€ì†)"
    else:
        trend = "ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì¶”ì„¸ íŒë‹¨ ë¶ˆê°€"

    return df.rename(columns={'value': 'ECRI Leading Index'}), trend

def get_unemployment_rate():
    url = 'https://api.stlouisfed.org/fred/series/observations'
    params = {
        'series_id': 'UNRATE',
        'api_key': API_KEY,
        'file_type': 'json',
        'observation_start': '2000-01-01'
    }
    response = requests.get(url, params=params)
    data = response.json()
    df = pd.DataFrame(data['observations'])
    df['date'] = pd.to_datetime(df['date'])
    df['unemployment_rate'] = pd.to_numeric(df['value'], errors='coerce')
    return df

def get_ism_pmi():
    """
    TradingEconomics í•œêµ­ì–´ ì‚¬ì´íŠ¸ì—ì„œ ISM ì œì¡°ì—… PMI ì§€í‘œë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    """
    url = "https://ko.tradingeconomics.com/united-states/manufacturing-pmi"

    options = Options()
    # options.add_argument('--headless')  # â† ì¼ë‹¨ êº¼ë‘ì„¸ìš”
    options.add_argument('--disable-gpu')
    options.add_argument('--no-sandbox')
    options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
    )

    driver = webdriver.Chrome(options=options)
    driver.get(url)

    try:
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "table.table"))
        )
        soup = BeautifulSoup(driver.page_source, 'html.parser')
    except Exception as e:
        driver.quit()
        raise Exception("âŒ í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨: table ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.") from e
    finally:
        driver.quit()

    table = soup.find('table', class_='table table-hover')
    if not table:
        raise Exception("âŒ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    rows = table.find('tbody').find_all('tr')
    for row in rows:
        columns = row.find_all('td')
        if len(columns) >= 5:
            name = columns[0].get_text(strip=True)
            if "ISM ì œì¡°ì—… PMI" in name:
                value = columns[1].get_text(strip=True)
                date = columns[4].get_text(strip=True)
                return {
                    "ì§€í‘œëª…": name,
                    "ê°’": value,
                    "ë°œí‘œì¼": date
                }

    raise Exception("âŒ 'ISM ì œì¡°ì—… PMI' í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def get_ECRI():
    '''
    ECRIê°€ ë°œí‘œí•˜ëŠ” ì§€í‘œë¥¼ ê³µì‹ì ìœ¼ë¡œ FREDì— ì œê³µí•˜ëŠ” í˜•íƒœ
    ìƒìŠ¹ì‹œ ê²½ê¸°íšŒë³µ/í™•ì¥ ì˜ë¯¸, í•˜ë½ì‹œ ê²½ê¸° ë‘”í™”/ì¹¨ì²´ ì˜ë¯¸
    '''
     
    url = 'https://api.stlouisfed.org/fred/series/observations'
    params = {
        'series_id': 'USSLIND',
        'api_key': API_KEY,
        'file_type': 'json',
        'observation_start': '2000-01-01'
    }
    response = requests.get(url, params=params)
    data = response.json()
    df = pd.DataFrame(data['observations'])
    df['date'] = pd.to_datetime(df['date'])
    df['ECRI_index'] = pd.to_numeric(df['value'], errors='coerce')
    return df

def analyze_ecri_trend(df):
    x = np.arange(len(df))
    y = df['ECRI_index'].values
    slope, _, r_value, _, _ = linregress(x, y)

    if slope > 0.05:
        return "ğŸ“ˆ ìƒìŠ¹ ì¶”ì„¸ (ê²½ê¸° íšŒë³µ ê¸°ëŒ€)"
    elif slope < -0.05:
        return "ğŸ“‰ í•˜ë½ ì¶”ì„¸ (ê²½ê¸° ë‘”í™” ìœ„í—˜)"
    else:
        return "â– íš¡ë³´ ì¶”ì„¸ (ë¶ˆí™•ì‹¤ì„± ì§€ì†)"


def get_fred_series(series_id: str, column_name: str):
    """
    FRED APIì—ì„œ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë²”ìš© í•¨ìˆ˜
    - series_id: FREDì˜ ì‹œë¦¬ì¦ˆ ID (ì˜ˆ: 'NAPM' â†’ ISM PMI)
    - column_name: ê²°ê³¼ DataFrameì—ì„œ ì‚¬ìš©í•  ì»¬ëŸ¼ëª…
    """
    url = 'https://api.stlouisfed.org/fred/series/observations'
    params = {
        'series_id': series_id,
        'api_key': API_KEY,
        'file_type': 'json',
        'observation_start': '2000-01-01'
    }

    response = requests.get(url, params=params)
    data = response.json()

    if 'observations' not in data:
        raise Exception(f"FRED API ì˜¤ë¥˜: {data.get('error_message', 'ì‘ë‹µì— ë°ì´í„° ì—†ìŒ')}")

    df = pd.DataFrame(data['observations'])
    df['date'] = pd.to_datetime(df['date'])
    df[column_name] = pd.to_numeric(df['value'], errors='coerce')
    return df[['date', column_name]]


def get_wti_crude_oil_price():
    """
    FRED APIë¥¼ í†µí•´ WTI ì›ìœ  ê°€ê²©(DCOILWTICO) ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
    """
    url = 'https://api.stlouisfed.org/fred/series/observations'
    params = {
        'series_id': 'DCOILWTICO',
        'api_key': API_KEY,
        'file_type': 'json',
        'observation_start': '2000-01-01'
    }

    response = requests.get(url, params=params)
    data = response.json()

    if 'observations' not in data:
        raise Exception(f"API ì˜¤ë¥˜ ë°œìƒ: {data.get('error_message', 'ì‘ë‹µì— ë°ì´í„° ì—†ìŒ')}")

    df = pd.DataFrame(data['observations'])
    df['date'] = pd.to_datetime(df['date'])
    df['wti_crude_oil_price'] = pd.to_numeric(df['value'], errors='coerce')
    return df[['date', 'wti_crude_oil_price']]

def get_industrial_production_index():
    """
    ë¯¸êµ­ ì‚°ì—…ìƒì‚°ì§€ìˆ˜(INDPRO)ë¥¼ FRED APIì—ì„œ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜
    """
    url = 'https://api.stlouisfed.org/fred/series/observations'
    params = {
        'series_id': 'INDPRO',
        'api_key': API_KEY,  # ì‚¬ìš© ì¤‘ì¸ FRED API í‚¤
        'file_type': 'json',
        'observation_start': '2000-01-01'
    }

    response = requests.get(url, params=params)
    data = response.json()

    if 'observations' not in data:
        raise Exception(f"âŒ API ì˜¤ë¥˜ ë°œìƒ: {data.get('error_message', 'ì‘ë‹µì— ë°ì´í„° ì—†ìŒ')}")

    df = pd.DataFrame(data['observations'])
    df['date'] = pd.to_datetime(df['date'])
    df['industrial_production'] = pd.to_numeric(df['value'], errors='coerce')
    return df[['date', 'industrial_production']]

def get_saudi_production():
    """
    FRED APIë¥¼ í†µí•´ ì‚¬ìš°ë”” ì›ìœ  ìƒì‚°ëŸ‰(OPECOPM) ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
    """
    url = 'https://api.stlouisfed.org/fred/series/observations'
    params = {
        'series_id': 'SAUNGDPMOMBD',
        'api_key': API_KEY,
        'file_type': 'json',
        'observation_start': '2000-01-01'
    }

    response = requests.get(url, params=params)
    data = response.json()

    if 'observations' not in data:
        raise Exception(f"API ì˜¤ë¥˜ ë°œìƒ: {data.get('error_message', 'ì‘ë‹µì— ë°ì´í„° ì—†ìŒ')}")

    df = pd.DataFrame(data['observations'])
    df['date'] = pd.to_datetime(df['date'])
    df['saudi_crude_production'] = pd.to_numeric(df['value'], errors='coerce')
    return df[['date', 'saudi_crude_production']]

def get_eia_series_v2(series_id: str, column_name: str):
    url = f'https://api.eia.gov/v2/seriesid/{series_id}'
    params = {'api_key': EIA_API_KEY}
    response = requests.get(url, params=params)
    data = response.json()

    if 'response' in data and 'data' in data['response']:
        records = data['response']['data']
        df = pd.DataFrame(records)
        df['date'] = pd.to_datetime(df['period'])
        df = df[['date', 'value']].rename(columns={'value': column_name})
        return df
    else:
        raise Exception(f"API ì˜¤ë¥˜ ë°œìƒ: {data.get('error', 'ë°ì´í„° ì—†ìŒ')}")

# ì‹œë¦¬ì¦ˆ ID ëª©ë¡
series_ids = {
    'crude_production': 'PET.MCRFPUS2.M',   # ì›ìœ  ìƒì‚°ëŸ‰ (ì›”ê°„, ë¯¸êµ­)
    'crude_inventory': 'PET.WCESTUS1.W',    # ì›ìœ  ì¬ê³ ëŸ‰ (ì£¼ê°„, ë¯¸êµ­)
    'crude_imports': 'PET.MCRIMUS2.M'       # ì›ìœ  ìˆ˜ì…ëŸ‰ (ì›”ê°„, ë¯¸êµ­)
}



def analyze_oil_price_change_causes(
    oil_df, indpro_df,
    saudi_df, us_prod_df, inventory_df, imports_df
): #ism_df
    def to_monthly(df, colname):
        return df.set_index('date').resample('M').mean().rename(columns={colname: f'{colname}_m'})

    dfs = [
        to_monthly(oil_df, 'wti_crude_oil_price'),
        # to_monthly(ism_df, 'ism'),
        to_monthly(indpro_df, 'industrial_production'),
        to_monthly(saudi_df, 'saudi_crude_production'),
        to_monthly(us_prod_df, 'us_crude_production'),
        to_monthly(inventory_df, 'us_crude_inventory'),
        to_monthly(imports_df, 'us_crude_imports')
    ]

    merged = pd.concat(dfs, axis=1).dropna().reset_index()
    recent = merged.tail(2)
    delta = recent.iloc[1, 1:] - recent.iloc[0, 1:]

    analysis = []

    if delta['wti_crude_oil_price_m'] > 0:
        analysis.append(f"ğŸ“ˆ ìœ ê°€ ìƒìŠ¹ ê°ì§€: +{delta['wti_crude_oil_price_m']:.2f}ë‹¬ëŸ¬")
        # if delta['ism_m'] > 0:
        #     analysis.append("ğŸ”¼ ISM PMI ìƒìŠ¹ â†’ ì œì¡°ì—… íšŒë³µ ê¸°ëŒ€")
        if delta['industrial_production_m'] > 0:
            analysis.append("ğŸ­ ì‚°ì—…ìƒì‚° ì¦ê°€ â†’ ì—ë„ˆì§€ ìˆ˜ìš” ì¦ê°€ ê°€ëŠ¥ì„±")
        if delta['saudi_crude_production_m'] < 0:
            analysis.append("ğŸ‡¸ğŸ‡¦ ì‚¬ìš°ë”” ì‚°ìœ ëŸ‰ ê°ì†Œ â†’ ê³µê¸‰ ê°ì†Œ")
        if delta['us_crude_production_m'] < 0:
            analysis.append("ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ì‚°ìœ ëŸ‰ ê°ì†Œ â†’ ê³µê¸‰ ê°ì†Œ")
        if delta['us_crude_inventory_m'] < 0:
            analysis.append("ğŸ“‰ ì›ìœ  ì¬ê³  ê°ì†Œ â†’ ê³µê¸‰ ë¶€ì¡± ê°€ëŠ¥ì„±")
        if delta['us_crude_imports_m'] < 0:
            analysis.append("ğŸ›¬ ìˆ˜ì… ê°ì†Œ â†’ ê³µê¸‰ ì••ë°•")
    else:
        analysis.append(f"ğŸ“‰ ìœ ê°€ í•˜ë½ ë˜ëŠ” ë³€í™” ì—†ìŒ: {delta['wti_crude_oil_price_m']:.2f}ë‹¬ëŸ¬")

    return analysis

def get_UMCSENT_index():
    '''
    ë¯¸ì‹œê°„ ì†Œë¹„ì ì‹¬ë¦¬ì§€ìˆ˜
    100ì´ìƒ : ë‚™ê´€ì  ë¶„ìœ„ê¸°
    80~100 : ì–‘í˜¸í•œ ì‹¬ë¦¬, ê±´ì „í•œ ì†Œë¹„ ì˜ˆìƒ
    60~80 : ì†Œë¹„ì ë¶ˆì•ˆì •, ì†Œë¹„ ìœ„ì¶• ê°€ëŠ¥ì„±
    60 ì´í•˜ : ê²½ê¸° ì¹¨ì²´ ì‹ í˜¸ ê°€ëŠ¥ì„±(ì†Œë¹„ ê¸‰ê° ìš°ë ¤ë ¤)
    '''

    url = 'https://api.stlouisfed.org/fred/series/observations'
    params = {
        'series_id': 'UMCSENT',
        'api_key': API_KEY,
        'file_type': 'json',
        'observation_start': '2000-01-01'
    }
    response = requests.get(url, params=params)
    data = response.json()
    df = pd.DataFrame(data['observations'])
    df['date'] = pd.to_datetime(df['date'])
    df['umcsent_index'] = pd.to_numeric(df['value'], errors='coerce')
    return df 


def get_forward_pe():
    url = 'https://en.macromicro.me/series/20052/sp500-forward-pe-ratio'

    options = Options()
    # options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")

    driver = webdriver.Chrome(options=options)
    driver.get(url)


    try:
        # âœ… í•´ë‹¹ ìš”ì†Œê°€ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 10ì´ˆ)
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div.sidebar-sec.chart-stat-lastrows span.val"))
        )
    except:
        driver.quit()
        raise RuntimeError("ğŸ“› í˜ì´ì§€ ë¡œë”© ì¤‘ Forward PE ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    soup = BeautifulSoup(driver.page_source, 'html.parser')
    driver.quit()

    latest_val = soup.select_one("div.sidebar-sec.chart-stat-lastrows span.val")
    date = soup.select_one("div.sidebar-sec.chart-stat-lastrows .date-label")

    if latest_val and date:
        date_text = date.text.strip()
        pe_val = float(latest_val.text.strip())
        df = pd.DataFrame([{"date": date_text, "forward_pe": pe_val}])
        return {
            "date": date_text,
            "forward_pe": pe_val,
            "df": df
        }
    else:
        raise ValueError("ğŸ“› Forward PE ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    

def get_ttm_pe():
    url = "https://ycharts.com/indicators/sp_500_pe_ratio"

    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")

    driver = webdriver.Chrome(options=options)
    driver.get(url)
    time.sleep(5)  # JS ë¡œë”© ëŒ€ê¸°

    soup = BeautifulSoup(driver.page_source, "html.parser")
    driver.quit()

    # "Last Value" í…ìŠ¤íŠ¸ê°€ ìˆëŠ” td ì°¾ê¸°
    for td in soup.select("td.col-6"):
        if "Last Value" in td.get_text(strip=True):
            value_td = td.find_next_sibling("td")
            if value_td:
                return value_td.get_text(strip=True)

    return None


def analyze_pe(forward_pe: float, ttm_pe: float) -> str:
    message = f"ğŸ“Š S&P 500 Forward PER: {forward_pe:.2f}\n"
    message += f"ğŸ“Š S&P 500 TTM PER: {ttm_pe:.2f}\n\n"

    # ì ˆëŒ€ì  ê³ í‰ê°€/ì €í‰ê°€ íŒë‹¨
    if forward_pe > 21:
        message += "âš ï¸ Forward PER ê¸°ì¤€ìœ¼ë¡œ **ê³ í‰ê°€** êµ¬ê°„ì…ë‹ˆë‹¤.\n"
    elif forward_pe < 17:
        message += "âœ… Forward PER ê¸°ì¤€ìœ¼ë¡œ **ì €í‰ê°€** êµ¬ê°„ì…ë‹ˆë‹¤.\n"
    else:
        message += "âš–ï¸ Forward PER ê¸°ì¤€ìœ¼ë¡œ **í‰ê·  ë²”ìœ„**ì…ë‹ˆë‹¤.\n"

    # TTM ëŒ€ë¹„ Forward ë¹„êµ
    if ttm_pe > forward_pe:
        message += "ğŸŸ¢ ì‹œì¥ì€ **í–¥í›„ ì‹¤ì  ê°œì„ **ì„ ê¸°ëŒ€í•˜ëŠ” ë‚™ê´€ì ì¸ íë¦„ì…ë‹ˆë‹¤."
    elif ttm_pe < forward_pe:
        message += "ğŸ”´ ì‹œì¥ì€ **ì‹¤ì  ë‘”í™”**ë¥¼ ë°˜ì˜í•˜ëŠ” ë³´ìˆ˜ì ì¸ íë¦„ì…ë‹ˆë‹¤."
    else:
        message += "âšª ì‹œì¥ì€ í˜„ì¬ ì‹¤ì  ìˆ˜ì¤€ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•  ê²ƒìœ¼ë¡œ ë³´ê³  ìˆìŠµë‹ˆë‹¤."

    return message

 


treasury_10years_df = get_10years_treasury_yeild()
treasury_2years_df = get_2years_treasury_yeild()
cpi_df = get_cpi_yoy()
m2_df = get_m2()
m2_yoy = get_m2_yoy()
m2_signal = analyze_m2_investment_signal(m2_df, m2_yoy, cpi_df)
high_yield_spread_df = get_high_yield_spread()
high_yield_warnging = check_high_yield_spread_warning(high_yield_spread_df)
dollar_index = get_dollar_index()
snp_index = get_snp_inedx()
yen_index = get_yen_index()
japan_policy_rate = get_japan_policy_rate()
japan_policy_rate = japan_policy_rate.set_index('date').resample('D').ffill().reset_index()
bull_bear_ratio = get_bull_bear_spread()
bull_bear_warning = analyze_bull_bear_spread(bull_bear_ratio)
equity_put_call_ratio = get_equity_put_call_ratio()
equity_put_call_trend = get_equity_put_call_trend()
equity_put_call_trend_warning = analyze_put_call_ratio_trend(equity_put_call_trend)
equity_put_call_ratio_warning = check_put_call_ratio_warning(equity_put_call_ratio, 'equity')

index_put_call_ratio = get_index_put_call_ratio()
index_put_call_trend = get_index_put_call_trend()
index_put_call_trend_warning = analyze_put_call_ratio_trend(index_put_call_trend)
index_put_call_ratio_warning = check_put_call_ratio_warning(index_put_call_ratio, 'index')

fed_base_interest_rate = get_fed_funds_rate()
vix_index = get_vix_index()
vix_analysis = analyze_vix()
real_rate_and_yield_spread = analyze_real_rate_and_yield_spread()
ecri = get_ECRI()
ecri_trend = analyze_ecri_trend(ecri)
unemployment_rate = get_unemployment_rate()
ism_pmi = get_ism_pmi()

oil_price = get_wti_crude_oil_price()
Indpro_index = get_industrial_production_index()
saudi_oil_production = get_saudi_production()
us_oil_inventory = get_eia_series_v2(series_ids['crude_inventory'], 'us_crude_inventory')
us_oil_production = get_eia_series_v2(series_ids['crude_production'], 'us_crude_production')
us_oil_imports = get_eia_series_v2(series_ids['crude_imports'], 'us_crude_imports')
analyze_oil_price_change = analyze_oil_price_change_causes(oil_price, Indpro_index, saudi_oil_production, us_oil_production, us_oil_inventory, us_oil_imports)
umcsent_index = get_UMCSENT_index()
snp_forward_pe = get_forward_pe()
snp_ttm_pe = float(get_ttm_pe())
evaluate_pe = analyze_pe(snp_forward_pe['forward_pe'], snp_ttm_pe)


## ì¶œë ¥

print("ë¯¸êµ­ ê¸°ì¤€ ê¸ˆë¦¬")
print(fed_base_interest_rate.tail())

print("ë¯¸êµ­ 10ë…„ë¬¼ êµ­ì±„ê¸ˆë¦¬")
print(treasury_10years_df.tail())

print("ë¯¸êµ­ 2ë…„ë¬¼ êµ­ì±„ê¸ˆë¦¬")
print(treasury_2years_df.tail())

print("ë¯¸êµ­ CPI ì§€í‘œ")
print(cpi_df.tail())

print("ì‹œì¥ ë‚´ ìœ í†µ í†µí™”")
print(m2_df)

print("M2 YoY ì¦ê°€ìœ¨")
print(m2_yoy)

print("M2 ë¶„ì„")
print(m2_signal)

print("í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œ")
print(high_yield_spread_df)

print("í•˜ì´ì¼ë“œ ê²½ê³  ë° ë§¤ìˆ˜ ì‹ í˜¸")
print(high_yield_warnging)

print('ë‹¬ëŸ¬ ì¸ë±ìŠ¤')
print(dollar_index)

print('S&P500 ì§€ìˆ˜')
print(snp_index)

print('ì—” ì§€ìˆ˜(eft ëŒ€ì²´)')
print(yen_index)

print('ì¼ë³¸ 10ë…„ë¬¼ êµ­ì±„ ê¸ˆë¦¬')
print(japan_policy_rate)

print("bull/bear spread ratio")
print(bull_bear_ratio)

print('bull-bear spread ë¶„ì„')
print(bull_bear_warning)

print("equity_put/call ratio")
print(equity_put_call_ratio)

print("equity_put/call ratio ì¶”ì„¸")
print(equity_put_call_trend)

print("equity_put/call ratio ë¶„ì„")
print(equity_put_call_trend_warning)

print("index_put/call ratio")
print(index_put_call_ratio)

print("index_put/call ratio ì¶”ì„¸")
print(index_put_call_trend)

print("index_put/call ratio ë¶„ì„")
print(index_put_call_trend_warning)

print("í˜„ ì‹œì  index put call ratio í‰ê°€")
print(index_put_call_ratio_warning)

print("ë¯¸êµ­ ê¸°ì¤€ ê¸ˆë¦¬")
print(fed_base_interest_rate)

print("VIX ì§€ìˆ˜")
print(vix_index)

print("VIX í•´ì„")
print(vix_analysis)

print("ì‹¤ì§ˆê¸ˆë¦¬&ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨ë¡œ ë³´ëŠ” ì‹œì¥ì˜ˆìƒ")
print(real_rate_and_yield_spread)

print('ECRI ì„ í–‰ì§€ìˆ˜ ë° ì¶”ì„¸')
print(ecri)

print("ì‹¤ì—…ë¥ ")
print(unemployment_rate)

print("ISM ì œì¡°ì—… PMI ì§€ìˆ˜") # 50 ì´í•˜ì¼ ë•Œ ìˆ˜ì¶• ì‹ í˜¸ --> ê²½ê¸° ë¯¼ê° ì—…ì¢… ì£¼ê°€ì— ì˜í–¥
print(ism_pmi)

print("ECRI ë¶„ì„")
print(ecri)

print("ì›ìœ  ê°€ê²©")
print(oil_price)

print("INDPRO ì§€ìˆ˜")
print(Indpro_index)

print("ì‚¬ìš°ë”” ì‚°ìœ ëŸ‰")
print(saudi_oil_production)

print("ë¯¸êµ­ ì›ìœ  ìƒì‚°ëŸ‰")
print(us_oil_production)

print("ìœ ê°€ ë³€ë™ ë¶„ì„")
print(analyze_oil_price_change)

print("ë¯¸ì‹œê°„ ì†Œë¹„ì ì‹¬ë¦¬ì§€ìˆ˜")
print(umcsent_index)

print("S&P500 í¬ì›Œë“œ PER")
print(snp_forward_pe)

print("S&P500 í˜„ì¬ PER")
print(snp_ttm_pe)

print("PE ì €/ê³ í‰ê°€ ì—¬ë¶€")
print(evaluate_pe)


# ì‹œê°í™” ì‘ì—…
import matplotlib.pyplot as plt

fig, ax1 = plt.subplots()

# ì²« ë²ˆì§¸ yì¶•: 10ë…„ë¬¼ êµ­ì±„ê¸ˆë¦¬
# color = 'tab:blue'
# ax1.set_xlabel('Date')
# ax1.set_ylabel('10Y Treasury Yield (%)', color=color)
# ax1.plot(treasury_df['date'], treasury_df['value'], color=color, label='10Y Treasury Yield')
# ax1.tick_params(axis='y', labelcolor=color)

# # ë‘ ë²ˆì§¸ yì¶•: CPI
# ax2 = ax1.twinx()  # ë‘ ë²ˆì§¸ yì¶• ê³µìœ 
# color = 'tab:orange'
# ax2.set_ylabel('CPI YOY', color=color)
# ax2.plot(cpi_df['date'], cpi_df['CPI YOY(%)'], color=color, label='CPI')
# ax2.tick_params(axis='y', labelcolor=color)

# # ì œëª©ê³¼ ë³´ì—¬ì£¼ê¸°
# plt.title('US 10Y Treasury Yield & CPI Trend (Dual Axis)')
# fig.tight_layout()
# plt.show()


