import os
import time
from dateutil.relativedelta import relativedelta
import pandas as pd
import numpy as np
from datetime import datetime
import requests
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns
import yfinance as yf
from bs4 import BeautifulSoup
from scipy.stats import linregress
from io import StringIO
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from zoneinfo import ZoneInfo


from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.core.os_manager import ChromeType

from md_updater import MarginDebtUpdater
from ism_pmi_updater import ISMPMIUpdater
from SNP_forward_pe_updater import forwardpe_updater
from putcall_ratio_updater import PutCallRatioUpdater
from bullbear_spread_updater import BullBearSpreadUpdater
from lei_updater import LEIUpdater

# í•œê¸€ í°íŠ¸ ì„¤ì • (Windowsì—ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ 'Malgun Gothic' ê°€ëŠ¥)
mpl.rcParams['font.family'] = 'Malgun Gothic'  # ë˜ëŠ” 'NanumGothic', 'AppleGothic' (Mac)
mpl.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤(-) ê¹¨ì§ ë°©ì§€

# ğŸ”‘ í™˜ê²½ë³€ìˆ˜ ë¡œë”©ìš© (í•„ìš” ì‹œ pip install python-dotenv)
from dotenv import load_dotenv
load_dotenv()  # .env íŒŒì¼ ì½ì–´ì„œ os.environì— ìë™ìœ¼ë¡œ ë“±ë¡


class MacroCrawler:
    def __init__(self):
        self.fred_api_key = os.environ.get("FRED_API_KEY")
        self.eia_api_key = os.environ.get("EIA_API_KEY")
        
        if not self.fred_api_key:
            raise ValueError("FRED_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        if not self.eia_api_key:
            raise ValueError("EIA_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        print("âœ… FRED & EIA API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸° ì„±ê³µ")

        # ë§ˆì§„ ë¶€ì±„ ì—…ë°ì´íŠ¸ê¸° ì—°ê²°
        self.margin_updater = MarginDebtUpdater("md_df.csv")
        # ISM PMI ì—…ë°ì´íŠ¸ê¸° ì—°ê²°
        self.pmi_updater = ISMPMIUpdater("pmi_data.csv")
        # Forward PE ì—…ë°ì´íŠ¸ê¸° ì—°ê²°
        self.snp_forwardpe_updater = forwardpe_updater("forward_pe_data.csv")
        # PUT CALL Ratio ì—…ë°ì´íŠ¸ê¸° ì—°ê²°
        self.put_call_ratio_updater = PutCallRatioUpdater("put_call_ratio.csv")
        # Bull Bear Spread ì—…ë°ì´íŠ¸ê¸° ì—°ê²°
        self.bull_bear_spread_updater = BullBearSpreadUpdater("bull_bear_spread.csv")
        # LEI ì—…ë°ì´íŠ¸ê¸° ì—°ê²°
        self.lei_updater = LEIUpdater("lei_data.csv")


    # Clear 1ê°œì›” ë”œë ˆì´ ë°ì´í„°
    def get_10years_treasury_yeild(self):
        '''
        FRED API : ë¯¸êµ­ 10ë…„ë¬¼ êµ­ì±„ ìˆ˜ìµë¥ 
        '''

        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id' : 'GS10', # 10ë…„ë¬¼ êµ­ì±„ ê¸ˆë¦¬
            'api_key' : self.fred_api_key,
            'file_type' : 'json',
            'observation_start' : '2000-01-01' # ì‹œì‘ì¼(ì›í•˜ëŠ” ë‚ ì§œì§œ)
        }

        try:
            response = requests.get(url, params= params, timeout=10)
            response.raise_for_status() # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
            data = response.json()

            if 'observations' not in data:
                raise ValueError(F"'observations' í‚¤ê°€ ì—†ìŒ : {data}")

            # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
            df = pd.DataFrame(data['observations'])
            df['date'] = pd.to_datetime(df['date'])
            df['value'] = pd.to_numeric(df['value'], errors= 'coerce')

            return df
        
        except Exception as e:
            print(f"[ERROR] FRED API í˜¸ì¶œ ì‹¤íŒ¨ : {e}")
            return pd.DataFrame()

    # Clear - 1ê°œì›” ë”œë ˆì´ ë°ì´í„°    
    def get_2years_treasury_yeild(self):
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id' : 'GS2', # 2ë…„ë¬¼ êµ­ì±„ ê¸ˆë¦¬
            'api_key' : self.fred_api_key,
            'file_type' : 'json',
            'observation_start' : '2000-01-01' # ì‹œì‘ì¼(ì›í•˜ëŠ” ë‚ ì§œì§œ)
        }

        try:
            response = requests.get(url, params= params, timeout=10)
            response.raise_for_status() # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
            data = response.json()

            if 'observations' not in data:
                raise ValueError(F"'observations' í‚¤ê°€ ì—†ìŒ : {data}") 

            # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
            df = pd.DataFrame(data['observations'])
            df['date'] = pd.to_datetime(df['date'])
            df['value'] = pd.to_numeric(df['value'], errors= 'coerce')


            return df
        
        except Exception as e:
            print(f"[ERROR] FRED API í˜¸ì¶œ ì‹¤íŒ¨ : {e}")
            return pd.DataFrame()

    # Clear - 1ê°œì›” ë”œë ˆì´ ë°ì´í„°     
    def get_cpi(self):
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'CPIAUCSL',  # CPI
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '1999-01-01'
        }
        
        try:
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
        except Exception as e:
            print("âŒ API ìš”ì²­ ë˜ëŠ” JSON íŒŒì‹± ì‹¤íŒ¨:", e)
            print("ğŸ“¦ ì‘ë‹µ ë‚´ìš©:", response.text)
            return pd.DataFrame()

        if 'observations' not in data:
            print("âŒ 'observations' í‚¤ ì—†ìŒ. ì‘ë‹µ ë‚´ìš©:", data)
            return pd.DataFrame()

        if not data['observations']:
            print("âŒ observations ë¦¬ìŠ¤íŠ¸ ë¹„ì–´ìˆìŒ:", data)
            return pd.DataFrame()

        df = pd.DataFrame(data['observations'])

        if 'date' not in df.columns:
            print("âŒ 'date' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ. df.columns:", df.columns)
            return pd.DataFrame()

        df['date'] = pd.to_datetime(df['date'])
        df['value'] = pd.to_numeric(df['value'], errors='coerce')

        df.to_csv("cpi_data.csv", encoding='utf-8-sig')

        return df
    
    def get_cpi_yoy(self):
        df = self.get_cpi() # ì›ë˜ CPIAUCSL ì§€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
        df = df.sort_values('date').dropna()

        df['CPI YOY(%)'] = df['value'].pct_change(periods=12)*100 # 12ê°œì›” ì „ ëŒ€ë¹„ ë³€í™”ìœ¨
        return df
    
    # Clear - 1ê°œì›” ë”œë ˆì´ ë°ì´í„°  
    def get_m2(self) : 
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'M2SL',  # M2 í†µí™”ëŸ‰
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '2000-01-01'
        }
        try:
            response = requests.get(url, params=params)
            data = response.json()
        except Exception as e:
            print("âŒ API ìš”ì²­ ë˜ëŠ” JSON íŒŒì‹± ì‹¤íŒ¨:", e)
            print("ğŸ“¦ ì‘ë‹µ ë‚´ìš©:", response.text)
            return pd.DataFrame()
        
        df = pd.DataFrame(data['observations'])
        df['date'] = pd.to_datetime(df['date'])
        df['value'] = pd.to_numeric(df['value'], errors='coerce')
        return df
    
  
    def get_m2_yoy(self):
        df = self.get_m2()
        df = df.sort_values('date')
        df['m2_yoy'] = df['value'].pct_change(periods=12) * 100
        return df[['date', 'm2_yoy']]

    # Clear 1ê°œì›” ë”œë ˆì´ ë°ì´í„°
    def update_margin_debt_data(self):
        '''
        ë¡œì»¬ì— ì €ì¥ëœ margin_debt íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
        '''
        try:
            md_df = self.margin_updater.update_csv()
            print("âœ… ë§ˆì§„ ë¶€ì±„ CSV ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        except Exception as e:
            print("ğŸ“› ë§ˆì§„ ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:", e)
        return md_df


    # def get_margin_debt_data(self):
    #     '''
    #     ë§ˆì§„ ë¶€ì±„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°(ê³ ì  íŒë‹¨)
    #     '''
    #     # 1ë…„ì¹˜ ë°ì´í„° í¬ë¡¤ë§
    #     url = "https://www.finra.org/rules-guidance/key-topics/margin-accounts/margin-statistics"

    #     try:
    #         response = requests.get(url, timeout=20)
    #         response.raise_for_status()
    #         soup = BeautifulSoup(response.text, "html.parser")

    #     except Exception as e:
    #         print("âŒ API ìš”ì²­ ë˜ëŠ” JSON íŒŒì‹± ì‹¤íŒ¨:", e)
    #         print("ğŸ“¦ ì‘ë‹µ ë‚´ìš©:", response.text)
    #         return pd.DataFrame()
        
    #     table = soup.select_one("table")  # ê°€ì¥ ì²« ë²ˆì§¸ í…Œì´ë¸” ì„ íƒ
    #     rows = table.find_all("tr")
        
    #     data = []
    #     headers = [th.get_text(strip=True) for th in rows[0].find_all("th")]

    #     for row in rows[1:]:
    #         cols = [td.get_text(strip=True).replace(",", "") for td in row.find_all("td")]
    #         if len(cols) == len(headers):
    #             data.append(cols)

    #     df = pd.DataFrame(data, columns=headers)
    #     df['Month/Year'] = pd.to_datetime(df['Month/Year'], format='%b-%y')
    #     # df = df.rename(columns={"Debit Balances in Customers' Securities Margin Accounts" : "margin_debt"})
    #     for col in df.columns[1:]:
    #         df[col] = pd.to_numeric(df[col], errors='coerce')
    #     return df
    
      # ì „ì²´ ë°ì´í„° ì—‘ì…€ë¡œ ë‹¤ìš´ë¡œë“œ í›„ ë¶ˆëŸ¬ì˜¤ê¸°
        # try:
        #     df = pd.read_excel('margin-statistics001.xlsx')

        #     # ì»¬ëŸ¼ëª… ì •ë¦¬
        #     df = df.rename(columns={
        #         'Year-Month': 'date',
        #         "Debit Balances in Customers' Securities Margin Accounts": 'margin_debt'
        #     })

        #     # ë‚ ì§œ íƒ€ì… ë³€í™˜
        #     df['date'] = pd.to_datetime(df['date'], format='%Y-%m')
        #     df['margin_debt'] = pd.to_numeric(df['margin_debt'].astype(str).str.replace(',', ''), errors='coerce')

        #     # 2000ë…„ ì´í›„ ë°ì´í„°ë§Œ í•„í„°ë§
        #     df = df[df['date'] >= '2000-01-01'].dropna(subset=['margin_debt'])

        #     # í•„ìš” ì»¬ëŸ¼ë§Œ ë°˜í™˜
        #     return df[['date', 'margin_debt']]

        # except Exception as e:
        #     print("âŒ Excel íŒŒì¼ ì½ê¸° ë˜ëŠ” ì²˜ë¦¬ ì˜¤ë¥˜:", e)
        #     return pd.DataFrame()

    
    # Clear  
    def get_margin_yoy_change(self):
        '''
        ë§ˆì§„ ë¶€ì±„ì˜ ì „ë…„ ëŒ€ë¹„ YOY (%) ë³€í™”ìœ¨ ê³„ì‚°
        '''
        df = self.update_margin_debt_data()
        if df.empty:
            return pd.DataFrame()

        df = df.sort_values("Month/Year")
        df["margin_debt"] = df["Debit Balances in Customers' Securities Margin Accounts"]
        df["margin_debt_clean"] = df["margin_debt"].astype(str).str.replace(',', '', regex=False)
        df["margin_debt"] = pd.to_numeric(df["margin_debt_clean"], errors="coerce").fillna(0).astype(int)
        df = df.drop(columns=["margin_debt_clean"])
        df["Margin YoY (%)"] = df["margin_debt"].pct_change(periods=12) * 100
        return df[["Month/Year", "margin_debt", "Margin YoY (%)"]]


    ## ìœ ë™ì„± ê´€ë ¨
    # Clear
    def generate_zscore_trend_signals(self):
        """
        Margin Debt / M2 ë¹„ìœ¨ì˜ z-score ë° ì¶”ì„¸ ì¡°ê±´ ê¸°ë°˜ ì „ëµ

        ë§¤ìˆ˜ ì¡°ê±´:
            - margin_debt / m2 ë¹„ìœ¨ì˜ z-score < -1.5
            - ë¹„ìœ¨ì´ ì „ì›” ëŒ€ë¹„ ìƒìŠ¹ (ë°˜ë“± ì‹œì‘)

        ë§¤ë„ ì¡°ê±´:
            - z-score > 1.5
            - ë¹„ìœ¨ì´ ì „ì›” ëŒ€ë¹„ -5% ì´ìƒ ê¸‰ë½

        ì‹¤ì œ ë§¤ë§¤ëŠ” ì‹ í˜¸ì¼ ê¸°ì¤€ +2ê°œì›” í›„ ì§„ì…
        ìˆ˜ìµë¥ ì€ ì§„ì…ì¼ë¶€í„° 3ê°œì›” í›„ê¹Œì§€ì˜ S&P500 ì¢…ê°€ ê¸°ì¤€

        Parameters:
            df : DataFrame with 'date', 'm2', 'margin_debt', 'sp500_close' columns

        Returns:
            DataFrame with signal type, signal date, action date, and 3-month return
        """
        df = self.merge_m2_margin_sp500_abs()
        df = df.sort_values("date").copy()
        df["ratio"] = df["margin_debt"] / df["m2"]
        df["ratio_z"] = (df["ratio"] - df["ratio"].rolling(window=36, min_periods=12).mean()) / \
                        df["ratio"].rolling(window=36, min_periods=12).std()
        df["ratio_change_pct"] = df["ratio"].pct_change() * 100

        # ì‹ í˜¸ ì •ì˜
        df["buy_signal"] = (df["ratio_z"] < -1.2) & (df["ratio_change_pct"] > 0)
        df["sell_signal"] = (df["ratio_z"] > 1.5) & (df["ratio_change_pct"] < -5)

        results = []
        for idx, row in df.iterrows():
            if row["buy_signal"] or row["sell_signal"]:
                signal = "BUY" if row["buy_signal"] else "SELL"
                signal_date = row["date"]
                action_date = signal_date + relativedelta(months=2)

                future_df = df[df["date"] >= action_date].reset_index(drop=True)
                if len(future_df) < 3:
                    continue

                entry_price = future_df.loc[0, "sp500_close"]
                exit_price = future_df.loc[2, "sp500_close"]
                return_pct = (exit_price - entry_price) / entry_price

                results.append({
                    "signal": signal,
                    "original_signal_date": signal_date,
                    "action_date": future_df.loc[0, "date"],
                    "return_3m": return_pct
                })

        return pd.DataFrame(results)
    
    # Clear
    def generate_mdyoy_signals(self):
        '''
        Margin Debt YoY ì „ëµ ê¸°ë°˜ ë§¤ìˆ˜/ë§¤ë„ ì‹ í˜¸ ìƒì„± í•¨ìˆ˜ (2ê°œì›” ë°œí‘œ ì§€ì—° ë°˜ì˜)
        df : ë³‘í•©ëœ ë°ì´í„°í”„ë ˆì„(merge_m2_margin_sp500_abs)
        '''

        df = self.merge_m2_margin_sp500_abs()
        df = df.copy()
        df["margin_yoy"] = df["margin_debt"].pct_change(periods=12) * 100

        # ì‹ í˜¸ ì¡°ê±´
        df["buy_signal"] = (df["margin_yoy"] > 0) & (df["margin_yoy"].shift(1) <= 0)
        df["sell_signal"] = (df["margin_yoy"] < -10) & (df["margin_yoy"].shift(1) >= -10)

        # ë°œí‘œ ì§€ì—° ê°ì•ˆí•œ ì§„ì… ì‹œì  ê³„ì‚°
        df["signal_date"] = df["date"]
        df["action_date"] = df["signal_date"] + pd.DateOffset(months=2)

        return df

    # Clear - ì‹¤ì‹œê°„ ë°ì´í„°
    def get_sp500(self):
        '''
        S&P500 ì§€ìˆ˜ ì¡°íšŒ
        '''

        ticker = '^GSPC'
        df = yf.download(ticker, start='2000-01-01', interval="1d", progress=False)

        # ì¸ë±ìŠ¤ê°€ ë‚ ì§œì¸ ê²½ìš° reset_index í•„ìš”
        if not isinstance(df.index, pd.RangeIndex):
            df = df.reset_index()

        # Date ì»¬ëŸ¼ ì´ë¦„ ì²˜ë¦¬ (í™˜ê²½ë§ˆë‹¤ ë‹¤ë¦„)
        possible_date_cols = ['Date', 'Datetime', 'date']
        for col in possible_date_cols:
            if col in df.columns:
                df = df.rename(columns={col: 'date'})
                break

        # Close ì»¬ëŸ¼ ì´ë¦„ ì²˜ë¦¬
        if 'Close' in df.columns:
            df = df.rename(columns={'Close': 'sp500_close'})
        elif ('Close', ticker) in df.columns:
            df = df.rename(columns={('Close', ticker): 'sp500_close'})

        # ë©€í‹°ì¸ë±ìŠ¤ ì»¬ëŸ¼ ë°©ì–´ì½”ë“œ
        df.columns = [c[0] if isinstance(c, tuple) else c for c in df.columns]

        # date ì»¬ëŸ¼ íƒ€ì… ë³€í™˜
        df['date'] = pd.to_datetime(df['date'], errors='coerce')

        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë‚¨ê¸°ê¸°
        df = df[['date', 'sp500_close']].dropna(subset=['date', 'sp500_close'])

        return df
        # ticker = '^GSPC'
        # df = yf.download(ticker, start='2000-01-01', interval="1d", progress=False )
        # # ì¸ë±ìŠ¤ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
        # df = df.reset_index()

        # # ë©€í‹°ì¸ë±ìŠ¤ ì»¬ëŸ¼ --> ë‹¨ì¼ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
        # df.columns = [col[0] if isinstance(col,tuple) else col for col in df.columns]

        # # ì»¬ëŸ¼ëª… ì •ë¦¬
        # df = df.rename(columns={'Date': 'date', 'Close': 'sp500_close'})
        
        # # ì›” ë‹¨ìœ„ë¡œ ë§ì¶°ì£¼ê¸° (Period â†’ Timestamp)
        # df['date'] = pd.to_datetime(df['date']) #dt.to_period('M').dt.to_timestamp()

        # # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë°˜í™˜
        # df = df[['date', 'sp500_close']]
        

        # return df

    
    # Clear
    def merge_m2_margin_sp500_abs(self):
        '''
        M2, margin_debt, S&P500 ì§€ìˆ˜ ë°ì´í„°í”„ë ˆì„ ë³‘í•©
        '''
        
        df_m2 = self.get_m2().copy()
        df_m2['date'] = df_m2['date'].dt.to_period('M').dt.to_timestamp()
        df_m2 = df_m2.rename(columns={'value' : 'm2'})

        df_margin = self.get_margin_yoy_change().copy()
        df_margin['date'] = df_margin['Month/Year'].dt.to_period('M').dt.to_timestamp()
        #df_margin["margin_debt"] = df_margin["Debit Balances in Customers' Securities Margin Accounts"]
        #df_margin["margin_debt"] = df_margin["margin_debt"].str.replace(',','').astype(int)

        df_sp500 = self.get_sp500().copy()
        df_sp500['date'] = pd.to_datetime(df_sp500['date'])  # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ì•ˆì „í•˜ê²Œ
        df_sp500['month'] =  df_sp500['date'].dt.to_period('M').dt.to_timestamp()

        # ê° ì›”ì˜ ì²« ë²ˆì§¸ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” S&P500 ê°’ë§Œ ì¶”ì¶œ
        sp_monthly_first = df_sp500.sort_values('date').groupby('month').first().reset_index()

        # âœ… ê¸°ì¡´ 'date' ì»¬ëŸ¼ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        sp_monthly_first = sp_monthly_first.drop(columns=['date'])
        
        # âœ… ë‚ ì§œë¥¼ í•´ë‹¹ ì›”ì˜ 1ì¼ë¡œ ë°”ê¿”ì¤Œ
        sp_monthly_first = sp_monthly_first.rename(columns={'month': 'date'})
        sp_monthly_first = sp_monthly_first[["date", "sp500_close"]]

        df = pd.merge(df_m2, df_margin[['date', 'margin_debt']], on='date', how='inner')
        df = pd.merge(df, sp_monthly_first, on='date', how='inner')
        df["ratio"] = df["margin_debt"] / df["m2"]   # â† ì´ ì¤„ ì¶”ê°€
        return df
 
    # Clear
    def plot_sp500_with_signals_and_graph(self, save_to=None):
        """
        S&P500 ì¢…ê°€ + Margin Debt/M2 ë¹„ìœ¨ + ë°œí‘œì‹œì°¨(ë‹¤ìŒë‹¬ 25ì¼) ë°˜ì˜ ì‹ í˜¸ ì‹œê°í™”

        - ì‹ í˜¸ ê³„ì‚°ì€ ì›”ë³„(MS)ë¡œ ìˆ˜í–‰ (36ê°œì›” z-score)
        - ê° ì›”ì˜ ì§€í‘œëŠ” 'ë‹¤ìŒ ë‹¬ 25ì¼'ì— ê³µê°œëœë‹¤ê³  ê°€ì •
        - ë°œí‘œì¼ì´ ì£¼ë§/íœ´ì¼ì´ë©´ 'ë°œí‘œì¼ ì´í›„ ì²« ê±°ë˜ì¼'ì— ì‹ í˜¸ì™€ ë¹„ìœ¨ì´ ìœ íš¨
        """

        import numpy as np
        import pandas as pd
        import matplotlib.pyplot as plt

        # 1) ì›ìë£Œ ë³‘í•© (ì¼ë‹¨ ì¼ë³„ S&P500ê³¼ ì›”ë³„ ì§€í‘œê°€ í•¨ê»˜ ë“¤ì–´ìˆëŠ” dfë¼ ê°€ì •)
        df = self.merge_m2_margin_sp500_abs().copy()
        df["date"] = pd.to_datetime(df["date"])
        df = df.sort_values("date")

        # ---- ì›”ë³„ í…Œì´ë¸” ë§Œë“¤ê¸° (ê° ì›” 1ì¼ ê¸°ì¤€) ----
        # margin_debt, m2ëŠ” ì›”ë³„ì´ë¯€ë¡œ ì›” ì´ˆ ê¸°ì¤€ìœ¼ë¡œ ëŒ€í‘œê°’ì„ í•˜ë‚˜ ë½‘ì•„ì˜¨ë‹¤.
        # (ì—¬ê¸°ì„œëŠ” í•´ë‹¹ ì›”ì˜ ì²« ê°’ ì‚¬ìš©; í•„ìš”ì‹œ last/meanìœ¼ë¡œ ë°”ê¿€ ìˆ˜ ìˆìŒ)
        # m_month = (
        #     df.loc[:, ["date", "margin_debt", "m2"]]
        #     .dropna(subset=["margin_debt", "m2"])
        #     .copy()
        # )
        # m_month["month"] = m_month["date"].values.astype("datetime64[M]")  # ì›” ë‹¨ìœ„ë¡œ ë²„í‚·íŒ… (MS)
        # m_month = (
        #     m_month.sort_values(["month", "date"])
        #         .groupby("month", as_index=False)
        #         .first()[["month", "margin_debt", "m2"]]
        # )
        # m_month = m_month.rename(columns={"month": "month_start"})  # ì›” ì´ˆ(ì˜ˆ: 2025-07-01)

        m_src = (
        df.loc[:, ["date", "margin_debt", "m2"]]
        .dropna(subset=["margin_debt", "m2"])
        .copy()
        )

        # ì›”ì´ˆ ë¼ë²¨ë¡œ ê·¸ë£¹í•‘í•˜ê³  'ê·¸ ë‹¬ì˜ ë§ˆì§€ë§‰ ê´€ì¸¡ê°’'ì„ ì‚¬ìš©
        monthly = (
            m_src.set_index("date")
                .groupby(pd.Grouper(freq="MS"))
                .last()                # ê·¸ ë‹¬ ë§ì¼ ì‹œì ì˜ 'ì•Œê³  ìˆë˜' ê°’
                .dropna()
                .reset_index()
        )

        # â˜… í•µì‹¬: ì´ ê°’ì€ 'ì´ì „ ì›”'ì˜ ê²½ì œì§€í‘œì´ë¯€ë¡œ ì›” ë¼ë²¨ì„ 1ê°œì›” ë’¤ë¡œ ë‹¹ê²¨ì„œ(âˆ’1M) ì‹¤ì œ ê¸°ì¤€ì›”ë¡œ ë§ì¶¤
        # monthly["month_start"] = (monthly["date"] - pd.offsets.MonthBegin(1))
        monthly["month_start"] = monthly["date"]
                                  
        m_month = (
            monthly[["month_start", "margin_debt", "m2"]]
                .sort_values("month_start")
                .reset_index(drop=True)
        )

        # 2) ì›”ë³„ ë¹„ìœ¨ ë° z-score ê³„ì‚° (36ê°œì›” ë¡¤ë§)
        m_month["ratio"] = m_month["margin_debt"] / m_month["m2"]
        m_month["ratio_ma"] = m_month["ratio"].rolling(window=36, min_periods=12).mean()
        m_month["ratio_sd"] = m_month["ratio"].rolling(window=36, min_periods=12).std()
        m_month["ratio_z"] = (m_month["ratio"] - m_month["ratio_ma"]) / m_month["ratio_sd"]
        m_month["ratio_change_pct"] = m_month["ratio"].pct_change() * 100

        # 3) ì›”ë³„ ì‹ í˜¸ (ì™„í™” ì¡°ê±´ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
        m_month["buy_signal"]  = (m_month["ratio_z"] < -1.2) & (m_month["ratio_change_pct"] > 0)
        m_month["sell_signal"] = (m_month["ratio_change_pct"] < -7)
        # m_month["sell_signal"] = (m_month["ratio_z"] > 1.2) & (m_month["ratio_change_pct"] < -5)

        # 4) 'ë°œí‘œì¼' ê³„ì‚°: ë‹¤ìŒ ë‹¬ 25ì¼
        #    ì˜ˆ: 7ì›” ë°ì´í„° -> 8ì›” 25ì¼
        m_month["release_date"] = (
            m_month["month_start"] + pd.offsets.MonthBegin(1) + pd.DateOffset(days=24)
        )

    
        # 5) ë°œí‘œì¼ì„ 'ë°œí‘œì¼ ì´í›„ ì²« ê±°ë˜ì¼'ë¡œ ë§ì¶”ê¸°
        # âœ… ë°˜ë“œì‹œ 'ì¼ë³„' S&P500 ë¼ì¸ í™•ë³´
        sp_daily = self.get_sp500().copy()  # ì¼ë³„ë¡œ ë°›ëŠ” í•¨ìˆ˜ ì‚¬ìš©(ì—†ìœ¼ë©´ self.get_sp500())
        sp_daily["date"] = pd.to_datetime(sp_daily["date"])

        # ì»¬ëŸ¼ í‘œì¤€í™”
        if "close" in sp_daily.columns:
            sp_daily = sp_daily.rename(columns={"close": "sp500_close"})
        elif "Close" in sp_daily.columns:
            sp_daily = sp_daily.rename(columns={"Close": "sp500_close"})
        # ì´ë¯¸ sp500_closeë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©

        sp_line = (
            sp_daily[["date", "sp500_close"]]
            .dropna()
            .drop_duplicates(subset=["date"])
            .sort_values("date")
            .reset_index(drop=True)
        )

        # ê±°ë˜ì¼ ìº˜ë¦°ë” = ì‹¤ì œ ê°€ê²©ì´ ìˆëŠ” ë‚ ì§œë¡œ ì‚¬ìš© (íœ´ì¼ ìë™ ì œì™¸)
        trade_days = sp_line[["date"]].copy()
        sp_dates = trade_days["date"].to_numpy()

        def next_trading_day(dt):
            i = np.searchsorted(sp_dates, np.datetime64(dt), side="left")
            return pd.NaT if i >= len(sp_dates) else pd.Timestamp(sp_dates[i])

        m_month["effective_date"] = m_month["release_date"].apply(next_trading_day)

        # 6) 'ë°œí‘œ í›„ì—ë§Œ ë³´ì´ëŠ”' ì¼ë³„ ë¹„ìœ¨ ì‹œê³„ì—´ ë§Œë“¤ê¸° (ê±°ë˜ì¼ ìº˜ë¦°ë” ê¸°ì¤€)
        full_days = trade_days.copy()
        full_days["ratio_published"] = np.nan

        published = (
            m_month.loc[:, ["effective_date", "ratio"]]
                .dropna()
                .sort_values("effective_date")
        )

        eff  = published["effective_date"].to_list()
        vals = published["ratio"].to_list()

        for i, start in enumerate(eff):
            end = eff[i+1] if i+1 < len(eff) else full_days["date"].iloc[-1] + pd.Timedelta(days=1)
            mask = (full_days["date"] >= start) & (full_days["date"] < end)
            full_days.loc[mask, "ratio_published"] = vals[i]

        # í”Œë¡¯ìš© DF: ê±°ë˜ì¼ â¨¯ ê°€ê²© â¨¯ ratio_published
        plot_df = trade_days.merge(sp_line, on="date", how="left").merge(full_days, on="date", how="left")
        plot_df["sp500_close"] = pd.to_numeric(plot_df["sp500_close"], errors="coerce").ffill()  # âœ” ì—°ì† ë¼ì¸ ë³´ì¥

        # --- ì‹œê·¸ë„ DF ë§Œë“¤ê¸° (ê°€ê²© ë¶™ì´ê¸°) ---
        signals = m_month.loc[
            (m_month["buy_signal"] | m_month["sell_signal"]) & m_month["effective_date"].notna(),
            ["month_start", "release_date", "effective_date", "ratio_z", "ratio_change_pct", "buy_signal", "sell_signal"]
        ].copy()

        signals["signal_type"] = np.where(signals["buy_signal"], "BUY", "SELL")

        # âœ” ë°œí‘œì¼(=ì£¼ë¬¸ì¼) ë‹¹ì¼ì— ê°€ê²©ì´ ë¹„ì–´ ìˆìœ¼ë©´ ë‹¤ìŒ ê±°ë˜ì¼ ê°€ê²©ì„ ë¶™ì´ë„ë¡ asof ë³‘í•©
        signals = pd.merge_asof(
            signals.sort_values("effective_date"),
            sp_line.sort_values("date"),
            left_on="effective_date",
            right_on="date",
            direction="forward"   # ë°œí‘œì¼ ì´í›„ ì²« ê°€ìš© ê°€ê²©
        )
        signals = signals.drop(columns=["date"])
        signals = signals[[
            "effective_date", "release_date", "month_start",
            "signal_type", "sp500_close", "ratio_z", "ratio_change_pct"
        ]]

        # --- ê·¸ë˜í”„ ì‹œê°í™” (fig, ax1 ìƒì„±) ---
        fig, ax1 = plt.subplots(figsize=(14, 6))

        ax1.plot(plot_df["date"], plot_df["sp500_close"], linewidth=2, label="S&P500 ì§€ìˆ˜", color="blue")
        ax1.set_ylabel("S&P500 ì¢…ê°€", color="blue")
        ax1.tick_params(axis="y", labelcolor="blue")

        buys  = signals[signals["signal_type"] == "BUY"]
        sells = signals[signals["signal_type"] == "SELL"]

        ax1.scatter(buys["effective_date"],  buys["sp500_close"],  marker="^", s=100, label="ë§¤ìˆ˜ ì‹ í˜¸", color="green")
        ax1.scatter(sells["effective_date"], sells["sp500_close"], marker="v", s=100, label="ë§¤ë„ ì‹ í˜¸", color="red")

        ax2 = ax1.twinx()
        ax2.plot(plot_df["date"], plot_df["ratio_published"], linestyle="--", label="Margin Debt/M2 (ë°œí‘œ ë°˜ì˜)", color="gray")
        ax2.set_ylabel("Margin Debt / M2 ë¹„ìœ¨", color="gray")
        ax2.tick_params(axis="y", labelcolor="gray")

        fig.suptitle("S&P500 + ë§¤ìˆ˜/ë§¤ë„ ì‹ í˜¸(ë°œí‘œì‹œì°¨ ë°˜ì˜) + Margin Debt/M2 ë¹„ìœ¨", fontsize=14)

        lines, labels = [], []
        for ax in [ax1, ax2]:
            l, lab = ax.get_legend_handles_labels()
            lines += l; labels += lab
        fig.legend(lines, labels, loc="upper left", bbox_to_anchor=(0.1, 0.92))

        fig.tight_layout()

        # âœ… ì»¬ëŸ¼ëª… ë³€ê²½
        signals = signals.rename(columns={
            "effective_date": "ì£¼ë¬¸ì¼",
            "release_date": "ë°œí‘œì¼",
            "month_start": "ë°ì´í„° ê¸°ì¤€ì¼",
            "ratio_change_pct": "ì „ì›”ëŒ€ë¹„ ìƒìŠ¹ë¥ "
        })

        if save_to:
            fig.savefig(save_to, format="png")
            # plt.close(fig)
        # else:
        #     plt.show()   # âœ… VS Codeì—ì„œë„ ì°½ ëœ¸

        # âœ… ê·¸ë˜í”„ì™€ ì‹ í˜¸ í…Œì´ë¸” ë°˜í™˜
        return fig, ax1, signals
    
    def get_today_signal_with_m2_and_margin_debt(self, today=None, market_tz="America/New_York"):
        """
        ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ ë§¤ìˆ˜/ë§¤ë„/ëŒ€ê¸° ì˜ì‚¬ê²°ì • + ì»¨í…ìŠ¤íŠ¸(ìµœê·¼ ë°œí‘œë¶„) ë°˜í™˜
        - ë°œí‘œì‹œì°¨(ë‹¤ìŒë‹¬ 25ì¼) + 'ë°œí‘œ í›„ ì²« ê±°ë˜ì¼' ê·œì¹™ ì¤€ìˆ˜
        - ì˜¤ëŠ˜ ì‹ í˜¸ ì—†ìœ¼ë©´ ìµœê·¼ ë°œí‘œë¶„ì„ WAITìœ¼ë¡œ í‘œì‹œ
        """
        import numpy as np
        import pandas as pd

        # â”€â”€ ì˜¤ëŠ˜(ë¯¸êµ­ ì‹œì¥ì‹œê°„ëŒ€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if today is None:
            today_ts = pd.Timestamp.now(tz=market_tz).normalize()
        else:
            t = pd.Timestamp(today)
            if t.tzinfo is None:
                t = t.tz_localize(market_tz)
            today_ts = t.normalize()
        today_naive = today_ts.tz_localize(None)

        # â”€â”€ ì›”ë³„ ì§€í‘œ í…Œì´ë¸” (ë¼ë²¨ ë³´ì •) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        df = self.merge_m2_margin_sp500_abs().copy()
        df["date"] = pd.to_datetime(df["date"])
        df = df.sort_values("date").reset_index(drop=True)  # âœ… ì „ì²´ ì •ë ¬(ì¤‘ìš”)

        m_src = df.loc[:, ["date", "margin_debt", "m2"]].dropna().copy()

        monthly = (
            m_src.set_index("date")
                .groupby(pd.Grouper(freq="MS"))
                .last()           # ê·¸ ë‹¬ ë§ì¼ê¹Œì§€ 'ì•Œê³  ìˆë˜' ê°’
                .dropna()
                .reset_index()
        )
        # ë§ì¼ê°’ì€ ì‹¤ì œë¡œ 'ì´ì „ ì›”' ì§€í‘œì´ë¯€ë¡œ ë¼ë²¨ -1M
        # monthly["month_start"] = monthly["date"] - pd.offsets.MonthBegin(1)

        # ìˆ˜ì •: í•´ë‹¹ ì›” ê·¸ëŒ€ë¡œ ì‚¬ìš©
        monthly["month_start"] = monthly["date"] 

        m_month = (
            monthly[["month_start", "margin_debt", "m2"]]
                .sort_values("month_start")
                .reset_index(drop=True)
        )

        # â”€â”€ ratio / z / ëª¨ë©˜í…€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        m_month["ratio"] = m_month["margin_debt"] / m_month["m2"]
        m_month["ratio_ma"] = m_month["ratio"].rolling(36, min_periods=12).mean()
        m_month["ratio_sd"] = m_month["ratio"].rolling(36, min_periods=12).std()
        m_month["ratio_z"]  = (m_month["ratio"] - m_month["ratio_ma"]) / m_month["ratio_sd"]
        m_month["ratio_change_pct"] = m_month["ratio"].pct_change() * 100

        # â”€â”€ ì‹ í˜¸ ê·œì¹™ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        m_month["buy_signal"]  = (m_month["ratio_z"] < -1.2) & (m_month["ratio_change_pct"] > 0)
        m_month["sell_signal"] = (m_month["ratio_change_pct"] < -7)

        # â”€â”€ ë°œí‘œì¼/ì£¼ë¬¸ì¼(ë°œí‘œ í›„ ì²« ê±°ë˜ì¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        m_month["release_date"] = m_month["month_start"] + pd.offsets.MonthBegin(1) + pd.DateOffset(days=24)

        # ê±°ë˜ì¼ ë‹¬ë ¥: ê°€ê²© ì¼ì(ìµœì†Œ ìš”ê±´)ë¡œ ì‚¬ìš©
        sp_daily = self.get_sp500().copy()
        sp_daily["date"] = pd.to_datetime(sp_daily["date"])
        if "close" in sp_daily.columns:
            sp_daily = sp_daily.rename(columns={"close": "sp500_close"})
        elif "Close" in sp_daily.columns:
            sp_daily = sp_daily.rename(columns={"Close": "sp500_close"})
        sp_line = (
            sp_daily[["date", "sp500_close"]]
            .dropna()
            .drop_duplicates(subset=["date"])
            .sort_values("date")
            .reset_index(drop=True)
        )
        trade_days = sp_line[["date"]].copy()
        if trade_days.empty:
            # ê°€ê²© ë‹¬ë ¥ì´ ì—†ë‹¤ë©´ í‰ì¼ ë‹¬ë ¥ìœ¼ë¡œ ëŒ€ì²´
            start = (m_month["release_date"].min() - pd.Timedelta(days=10)).normalize()
            end   = (max(today_naive, m_month["release_date"].max()) + pd.Timedelta(days=10)).normalize()
            trade_days = pd.DataFrame({"date": pd.bdate_range(start, end)})

        td = trade_days["date"].to_numpy()
        def next_trading_day(dt):
            i = np.searchsorted(td, np.datetime64(dt), side="left")
            return pd.NaT if i >= len(td) else pd.Timestamp(td[i])

        m_month["effective_date"] = m_month["release_date"].apply(next_trading_day)

        # â”€â”€ ì˜¤ëŠ˜ ë°œìƒ ì‹ í˜¸(ì´ë²¤íŠ¸) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        mask_today = (
            m_month["effective_date"].notna()
            & (m_month["effective_date"].dt.normalize() == today_naive)
            & (m_month["buy_signal"] | m_month["sell_signal"])
        )
        sig_today = m_month.loc[mask_today].copy()

        # â”€â”€ ìµœê·¼ ë°œí‘œë¶„ ì»¨í…ìŠ¤íŠ¸(ì˜¤ëŠ˜ ì£¼ë¬¸ ì—†ì„ ë•Œ ë³´ì—¬ì¤„ 1í–‰) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        mask_ctx = m_month["effective_date"].notna() & (m_month["effective_date"] <= today_naive)
        context = m_month.loc[mask_ctx].sort_values("effective_date").tail(1).copy()

        # ê°€ê²© ë¶™ì´ê³  í¬ë§·í•˜ê¸°
        def _attach_and_format(df_in):
            if df_in.empty:
                return df_in
            out = pd.merge_asof(
                df_in.sort_values("effective_date"),
                sp_line.sort_values("date"),
                left_on="effective_date",
                right_on="date",
                direction="forward"
            ).drop(columns=["date"])
            out["signal_type"] = np.where(out["buy_signal"], "BUY",
                                np.where(out["sell_signal"], "SELL", "WAIT"))
            out = out.rename(columns={
                "effective_date": "ì£¼ë¬¸ì¼",
                "release_date":  "ë°œí‘œì¼",
                "month_start":   "ë°ì´í„° ê¸°ì¤€ì¼",
                "ratio_change_pct": "ì „ì›”ë¹„ ë³€í™”ìœ¨(%)"
            })[
                ["ì£¼ë¬¸ì¼","ë°œí‘œì¼","ë°ì´í„° ê¸°ì¤€ì¼","signal_type","sp500_close","ratio_z","ì „ì›”ë¹„ ë³€í™”ìœ¨(%)"]
            ]
            out["ratio_z"] = out["ratio_z"].round(3)
            out["ì „ì›”ë¹„ ë³€í™”ìœ¨(%)"] = out["ì „ì›”ë¹„ ë³€í™”ìœ¨(%)"].round(2)
            return out

        if not sig_today.empty:
            details = _attach_and_format(sig_today)
            action = "SELL" if (details["signal_type"] == "SELL").any() else "BUY"
        elif not context.empty:
            # ì»¨í…ìŠ¤íŠ¸ë¥¼ WAITìœ¼ë¡œ ê°•ì œ í‘œê¸°
            context.loc[:, ["buy_signal","sell_signal"]] = False
            details = _attach_and_format(context)
            details.loc[:, "signal_type"] = "WAIT"
            # âœ… ì¶”ê°€: ëŒ€ê¸° í™”ë©´ì—ì„œëŠ” 'ì£¼ë¬¸ì¼'ì„ ì˜¤ëŠ˜ ë‚ ì§œë¡œ ë®ì–´ì“°ê¸°
            details.loc[:, "ì£¼ë¬¸ì¼"] = today_naive   # ë˜ëŠ” today_naive.date()ë¡œ 'ë‚ ì§œë§Œ'
            action = "NONE"

        else:
            # ì´ˆê¸° êµ¬ê°„ ë“± ì•„ë¬´ ë°ì´í„°ë„ ì—†ì„ ë•Œ
            cols = ["ì£¼ë¬¸ì¼","ë°œí‘œì¼","ë°ì´í„° ê¸°ì¤€ì¼","signal_type","sp500_close","ratio_z","ì „ì›”ë¹„ ë³€í™”ìœ¨(%)"]
            details = pd.DataFrame(columns=cols)
            action = "NONE"

        # â”€â”€ ì˜¤ëŠ˜ ê±°ë˜ì¼ ì—¬ë¶€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        is_trading_day = (today_naive.normalize() in set(trade_days["date"])) or (today_naive.weekday() < 5)

        # â”€â”€ ë‹¤ìŒ ë°œí‘œ/ì£¼ë¬¸ ì˜ˆì •(ë‹¬ë ¥ ê¸°ì¤€ìœ¼ë¡œ í•­ìƒ 'ì•'ì„ ê°€ë¦¬í‚¤ê²Œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        rel = (today_naive.replace(day=25)
            if today_naive.day <= 25
            else (today_naive + pd.offsets.MonthBegin(1)).replace(day=25))
        eff = next_trading_day(rel)
        next_rel = {"release_date": rel, "effective_date": eff, "estimated": True}

        return {
            "today": today_ts,
            "is_trading_day": is_trading_day,
            "action": action,      # ì˜¤ëŠ˜ ì£¼ë¬¸ ì´ë²¤íŠ¸: BUY/SELL/NONE
            "details": details,    # ì˜¤ëŠ˜ ì‹ í˜¸ or ìµœê·¼ ë°œí‘œë¶„ WAIT 1í–‰
            "next_release": next_rel
        }
    
    # Clear
    def check_today_md_signal(self):
        """
        ì˜¤ëŠ˜ì´ generate_zscore_trend_signals ë˜ëŠ” generate_mdyoy_signals ê¸°ì¤€
        ë§¤ìˆ˜/ë§¤ë„ ìœ íš¨ì›”(month)ì— ì†í•˜ëŠ”ì§€ í™•ì¸

        - todayê°€ action_dateì™€ ê°™ì€ ë‹¬(Month)ì´ë©´ ìœ íš¨
        - ê·¸ ë‹¬ ì „ì²´ë¥¼ ë§¤ë§¤ ìœ íš¨ ì‹œì ìœ¼ë¡œ ê°„ì£¼
        """

        today = pd.Timestamp.today().normalize()  
        # today = pd.Timestamp("2023-03-15").normalize()  # í…ŒìŠ¤íŠ¸ìš© ë‚ ì§œ ê°•ì œ ì„¤ì • 
        today_month = today.to_period("M")  # ì›” ë‹¨ìœ„ ë¹„êµìš©

        print(f"ğŸ“… ì˜¤ëŠ˜ ë‚ ì§œ (í™•ì¸ ê¸°ì¤€): {today.date()}")

        # ë°ì´í„° ë³‘í•©
        df = self.merge_m2_margin_sp500_abs()

        # --- ì „ëµ 1: z-score ê¸°ë°˜
        zscore_signal_df = self.generate_zscore_trend_signals()
        zscore_signal_df["action_month"] = zscore_signal_df["action_date"].dt.to_period("M")
        zscore_today = zscore_signal_df[zscore_signal_df["action_month"] == today_month]

        # --- ì „ëµ 2: margin YoY ê¸°ë°˜
        mdyoy_df = self.generate_mdyoy_signals()
        mdyoy_df["action_month"] = mdyoy_df["action_date"].dt.to_period("M")
        mdyoy_today = mdyoy_df[mdyoy_df["action_month"] == today_month]

        signal_found = False

        if not zscore_today.empty:
            print("\nğŸ“Œ [Z-Score ì „ëµ] ì´ë²ˆ ë‹¬ ë§¤ë§¤ ì‹ í˜¸ ìˆìŒ!")
            for _, row in zscore_today.iterrows():
                print(f"ğŸ‘‰ {row['action_date'].date()} : {row['signal']} ì‹ í˜¸ (ë°œìƒì¼: {row['original_signal_date'].date()})")
            signal_found = True

        mdyoy_filtered = mdyoy_today[mdyoy_today["buy_signal"] | mdyoy_today["sell_signal"]]
        if not mdyoy_filtered.empty:
            print("\nğŸ“Œ [Margin YoY ì „ëµ] ì´ë²ˆ ë‹¬ ë§¤ë§¤ ì‹ í˜¸ ìˆìŒ!")
            for _, row in mdyoy_filtered.iterrows():
                if row["buy_signal"]:
                    print(f"ğŸ‘‰ {row['action_date'].date()} : BUY ì‹ í˜¸ (ë°œìƒì¼: {row['signal_date'].date()})")
                elif row["sell_signal"]:
                    print(f"ğŸ‘‰ {row['action_date'].date()} : SELL ì‹ í˜¸ (ë°œìƒì¼: {row['signal_date'].date()})")
            signal_found = True

        if not signal_found:
            print("\nâœ… ì´ë²ˆ ë‹¬ì€ ë§¤ìˆ˜/ë§¤ë„ ì§„ì… ì‹œì ì´ ì•„ë‹™ë‹ˆë‹¤.")

    # Clear - ì›”ë³„ë°ì´í„° - 1ê°œì›” ì§€ì—°
    def get_fed_funds_rate(self):
        '''
        ë¯¸êµ­ ê¸°ì¤€ ê¸ˆë¦¬ ê³„ì‚°
        '''
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'FEDFUNDS',
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '2000-01-01'
        }
        response = requests.get(url, params=params)
        data = response.json()
        df = pd.DataFrame(data['observations'])
        df['date'] = pd.to_datetime(df['date'])
        df['fed_funds_rate'] = pd.to_numeric(df['value'], errors='coerce')

        return df

    # Clear    
    def generate_fed_rate_turning_points(self):
        """
        ê¸°ì¤€ê¸ˆë¦¬ ë³€í™”ì—ì„œ ì¸í•˜ ì‹œì‘ì  (rate_cut=True), ì¸ìƒ ì‹œì‘ì  (rate_hike=True)ë§Œ ì¡ëŠ” í•¨ìˆ˜
        """
        fed_rate_df = self.get_fed_funds_rate()
        df = fed_rate_df.copy()
        df["date"] = pd.to_datetime(df["date"])
        df = df.sort_values("date")

        df["prev_rate"] = df["fed_funds_rate"].shift(1)
        df["rate_diff"] = df["fed_funds_rate"] - df["prev_rate"]

        # ê¸°ì¤€ê¸ˆë¦¬ ë³€í™” ë°©í–¥
        df["trend"] = df["rate_diff"].apply(lambda x: "up" if x > 0 else ("down" if x < 0 else "flat"))
        df["prev_trend"] = df["trend"].shift(1)

        # ì „í™˜ì : flat â†’ ì œì™¸
        df["rate_cut"] = (df["prev_trend"] != "down") & (df["trend"] == "down")
        df["rate_hike"] = (df["prev_trend"] != "up") & (df["trend"] == "up")

        return df[["date", "fed_funds_rate", "rate_cut", "rate_hike"]]

    # Clear
    def get_rate_signal(self):
        '''
        ê¸ˆë¦¬ ê¸°ë°˜ ë³´ì¡° ì§€í‘œ ì‹œê·¸ë„ ê³„ì‚°

        Parameters:
            latest_10y (float): ìµœì‹  10ë…„ë¬¼ êµ­ì±„ ìˆ˜ìµë¥  (%)
            latest_2y (float): ìµœì‹  2ë…„ë¬¼ êµ­ì±„ ìˆ˜ìµë¥  (%)
            latest_fed_rate (float): ìµœì‹  ë¯¸êµ­ ê¸°ì¤€ê¸ˆë¦¬ (%)
            latest_cpi_yoy (float): ìµœì‹  CPI YoY (%)
            prev_cpi_yoy (float): ì§ì „ì›” CPI YoY (%)

        Returns:
            signal (int): -1 (ë§¤ë„), 0 (ì¤‘ë¦½), +1 ì´ìƒ (ë§¤ìˆ˜ ìš°í˜¸ì )
            comments (list): íŒë‹¨ ê·¼ê±° ì„¤ëª…
        '''
        signal = 0
        comments = []

        latest_10y = self.get_10years_treasury_yeild()['value'].iloc[-1]
        latest_2y = self.get_2years_treasury_yeild()['value'].iloc[-1]
        prev_10y = self.get_10years_treasury_yeild()['value'].iloc[-2]
        prev_2y = self.get_2years_treasury_yeild()['value'].iloc[-2]
        latest_cpi_yoy = self.get_cpi_yoy()['CPI YOY(%)'].iloc[-1]
        latest_fed_rate = self.get_fed_funds_rate()['fed_funds_rate'].iloc[-1]
        prev_cpi_yoy = self.get_cpi_yoy()['CPI YOY(%)'].iloc[-2]

        # ì‹¤ì§ˆê¸ˆë¦¬ ê³„ì‚°
        real_10y = latest_10y - latest_cpi_yoy
        real_2y = latest_2y - latest_cpi_yoy

        # ì‹¤ì§ˆê¸ˆë¦¬ ì¡°ê±´ (CPI ì¶”ì„¸ ë°˜ì˜)
        if real_10y < 0:
            print("10ë…„ë¬¼ ê¸ˆë¦¬ : ", latest_10y, "CPI_YoY : ", latest_cpi_yoy)
            if latest_cpi_yoy < prev_cpi_yoy:
                signal += 1
                comments.append("ğŸ”¼ ì‹¤ì§ˆê¸ˆë¦¬ < 0 & CPI YoY í•˜ë½ â†’ ì™„í™” ì‹ í˜¸")
            else:
                signal -= 1
                comments.append("âš ï¸ ì‹¤ì§ˆê¸ˆë¦¬ < 0 but CPI YoY ìƒìŠ¹ â†’ ì¸í”Œë ˆ ì••ë ¥")
        else:
            comments.append("â„¹ï¸ ì‹¤ì§ˆê¸ˆë¦¬ ì–‘í˜¸ (10Y > CPI YoY)")

        if real_2y > 2:
            print("2ë…„ë¬¼ ê¸ˆë¦¬ : ", latest_2y, "CPI_YoY : ", latest_cpi_yoy)
            signal -= 1
            comments.append("ğŸ“‰ ë‹¨ê¸° ì‹¤ì§ˆê¸ˆë¦¬ > 2% â†’ ê¸´ì¶• ìš°ë ¤")

        # ê¸ˆë¦¬ì°¨ (ì¥ë‹¨ê¸° ìŠ¤í”„ë ˆë“œ)
        spread = latest_10y - latest_2y
        prev_spread = prev_10y - prev_2y

        # ë³€í™”ëŸ‰
        delta_spread = spread - prev_spread

        # íŒë‹¨
        if spread < -0.5:
            if delta_spread > 0:
                signal += 1
                comments.append("ğŸ”¼ ì¥ë‹¨ê¸° ê¸ˆë¦¬ì—­ì „ ìƒíƒœì§€ë§Œ ì •ìƒí™” ì¶”ì„¸ â†’ ê¸ì •ì  ë³€í™”")
            else:
                signal -= 1
                comments.append("âš ï¸ ì¥ë‹¨ê¸° ê¸ˆë¦¬ì—­ì „ + ì¶”ê°€ ì•…í™” â†’ ì¹¨ì²´ ì‹ í˜¸")
        elif spread > 0:
            if delta_spread < 0:
                signal -= 1
                comments.append("âš ï¸ ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨ ì–‘ìˆ˜ì§€ë§Œ ì—­ì „ ë°©í–¥ìœ¼ë¡œ ì¶•ì†Œ ì¤‘ â†’ ì£¼ì˜")
            else:
                signal += 1
                comments.append("ğŸ”¼ ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨ ì •ìƒ + í™•ì¥ ì¶”ì„¸ â†’ íšŒë³µ ê¸°ëŒ€")
        else:
            comments.append("â¸ï¸ ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨ ì¤‘ë¦½ êµ¬ê°„")

        # # ê¸°ì¤€ê¸ˆë¦¬ vs 2ë…„ë¬¼ (ë¯¸ë˜ ê¸ˆë¦¬ ì¸í•˜ ê¸°ëŒ€ ì—¬ë¶€)
        # if latest_2y < latest_fed_rate:
        #     signal += 1
        #     comments.append("ğŸ”½ 2Y < ê¸°ì¤€ê¸ˆë¦¬ â†’ ê¸ˆë¦¬ ì¸í•˜ ê¸°ëŒ€ (ì™„í™” ì‹œê·¸ë„)")
        # else:
        #     comments.append("â¸ 2Y â‰¥ ê¸°ì¤€ê¸ˆë¦¬ â†’ ê¸´ì¶• ì§€ì† ë˜ëŠ” ë¶ˆí™•ì‹¤ì„±")

        return signal, comments

    # Clear
    def plot_rate_indicators_vs_sp500(self):
        # ë°ì´í„° ì¤€ë¹„
        sp500 = self.get_sp500()
        df_10y = self.get_10years_treasury_yeild()
        df_2y = self.get_2years_treasury_yeild()
        cpi_yoy = self.get_cpi_yoy()
        fed = self.get_fed_funds_rate()

        # ì›” ë‹¨ìœ„ ì •ë ¬
      
        sp500['date'] = pd.to_datetime(sp500['date'])  # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ì•ˆì „í•˜ê²Œ
        sp500['month'] = pd.to_datetime(sp500['date']).dt.to_period('M').dt.to_timestamp()

        # ê° ì›”ì˜ ì²« ë²ˆì§¸ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” S&P500 ê°’ë§Œ ì¶”ì¶œ
        sp_monthly_first = sp500.sort_values('date').groupby('month').first().reset_index()

        # âœ… ê¸°ì¡´ 'date' ì»¬ëŸ¼ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        sp_monthly_first = sp_monthly_first.drop(columns=['date'])
        
        # âœ… ë‚ ì§œë¥¼ í•´ë‹¹ ì›”ì˜ 1ì¼ë¡œ ë°”ê¿”ì¤Œ
        sp_monthly_first = sp_monthly_first.rename(columns={'month': 'date'})
        sp_monthly_first = sp_monthly_first[["date", "sp500_close"]]


        df_10y['date'] = df_10y['date'].dt.to_period('M').dt.to_timestamp()
        df_2y['date'] = df_2y['date'].dt.to_period('M').dt.to_timestamp()
        cpi_yoy['date'] = cpi_yoy['date'].dt.to_period('M').dt.to_timestamp()
        fed['date'] = fed['date'].dt.to_period('M').dt.to_timestamp()

        # ë³‘í•©
        df = sp_monthly_first.copy()
        df = df.merge(df_10y[['date', 'value']], on='date', how='inner').rename(columns={'value': '10y'})
        df = df.merge(df_2y[['date', 'value']], on='date', how='inner').rename(columns={'value': '2y'})
        df = df.merge(cpi_yoy[['date', 'CPI YOY(%)']], on='date', how='inner').rename(columns={'CPI YOY(%)': 'cpi_yoy'})
        df = df.merge(fed[['date', 'fed_funds_rate']], on='date', how='inner')

        # ì§€í‘œ ê³„ì‚°
        df['real_10y'] = df['10y'] - df['cpi_yoy']
        df['spread'] = df['10y'] - df['2y']
        # df['ffr_vs_2y'] = df['fed_funds_rate'] - df['2y']

        # ì‹œê°í™”
        fig, axs = plt.subplots(3, 1, figsize=(14, 12), sharex=True)

        # 1. S&P500
        axs[0].plot(df['date'], df['sp500_close'], label='S&P500', color='black')
        axs[0].set_ylabel('S&P500')
        axs[0].legend(loc='upper left')
        axs[0].grid(True)

        # 2. ì‹¤ì§ˆê¸ˆë¦¬ (10Y - CPI YoY)
        axs[1].plot(df['date'], df['real_10y'], label='ì‹¤ì§ˆ 10Y ê¸ˆë¦¬', color='green')
        axs[1].axhline(0, color='gray', linestyle='--')
        axs[1].set_ylabel('10Y - CPI YoY (%)')
        axs[1].legend(loc='upper left')
        axs[1].grid(True)

        # 3. ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨ (10Y - 2Y)
        axs[2].plot(df['date'], df['spread'], label='10Y - 2Y', color='blue')
        axs[2].axhline(0, color='gray', linestyle='--')
        axs[2].fill_between(df['date'], df['spread'], 0, where=(df['spread'] < 0), color='red', alpha=0.2, label='ì—­ì „ êµ¬ê°„')
        axs[2].set_ylabel('10Y - 2Y (%)')
        axs[2].legend(loc='upper left')
        axs[2].grid(True)

        # # 4. ê¸°ì¤€ê¸ˆë¦¬ - 2Y
        # axs[3].plot(df['date'], df['ffr_vs_2y'], label='ê¸°ì¤€ê¸ˆë¦¬ - 2Y', color='orange')
        # axs[3].axhline(0, color='gray', linestyle='--')
        # axs[3].set_ylabel('FFR - 2Y (%)')
        # axs[3].legend(loc='upper left')
        # axs[3].grid(True)

        fig.suptitle("ğŸ“Š ê¸ˆë¦¬ ê¸°ë°˜ ì£¼ìš” ì§€í‘œ vs S&P500", fontsize=16)
        plt.tight_layout()
        plt.show()

    # Clear
    def plot_rate_indicators_vs_sp500_with_signal(self):
        # ë°ì´í„° ì¤€ë¹„
        sp500 = self.get_sp500()
        df_10y = self.get_10years_treasury_yeild()
        df_2y = self.get_2years_treasury_yeild()
        cpi_yoy = self.get_cpi_yoy()
        fed = self.get_fed_funds_rate()

        # ì›” ë‹¨ìœ„ ì •ë ¬
      
        sp500['date'] = pd.to_datetime(sp500['date'])  # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ì•ˆì „í•˜ê²Œ
        sp500['month'] = pd.to_datetime(sp500['date']).dt.to_period('M').dt.to_timestamp()

        # ê° ì›”ì˜ ì²« ë²ˆì§¸ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” S&P500 ê°’ë§Œ ì¶”ì¶œ
        sp_monthly_first = sp500.sort_values('date').groupby('month').first().reset_index()

        # âœ… ê¸°ì¡´ 'date' ì»¬ëŸ¼ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        sp_monthly_first = sp_monthly_first.drop(columns=['date'])
        
        # âœ… ë‚ ì§œë¥¼ í•´ë‹¹ ì›”ì˜ 1ì¼ë¡œ ë°”ê¿”ì¤Œ
        sp_monthly_first = sp_monthly_first.rename(columns={'month': 'date'})
        sp_monthly_first = sp_monthly_first[["date", "sp500_close"]]


        # ë‚ ì§œ ì²˜ë¦¬
        for df in [df_10y, df_2y, cpi_yoy, fed]:
            df['date'] = pd.to_datetime(df['date']).dt.to_period('M').dt.to_timestamp()

        # ë³‘í•©
        df = sp_monthly_first.copy()
        df = df.merge(df_10y[['date', 'value']], on='date').rename(columns={'value': '10y'})
        df = df.merge(df_2y[['date', 'value']], on='date').rename(columns={'value': '2y'})
        df = df.merge(cpi_yoy[['date', 'CPI YOY(%)']], on='date').rename(columns={'CPI YOY(%)': 'cpi_yoy'})
        df = df.merge(fed[['date', 'fed_funds_rate']], on='date')

        # ì§€í‘œ ê³„ì‚°
        df['real_10y'] = df['10y'] - df['cpi_yoy']
        df['spread'] = df['10y'] - df['2y']
        # df['ffr_vs_2y'] = df['fed_funds_rate'] - df['2y']

        # ğŸ“Œ ê³¼ê±° ì‹œì ë³„ rate_signal ê³„ì‚°
        signal_list = []
        for i in range(1, len(df)):
            try:
                latest_10y = df.iloc[i]['10y']
                latest_2y = df.iloc[i]['2y']
                prev_10y = df.iloc[i-1]['10y']
                prev_2y = df.iloc[i-1]['2y']
                latest_cpi_yoy = df.iloc[i]['cpi_yoy']
                prev_cpi_yoy = df.iloc[i-1]['cpi_yoy']
                latest_fed_rate = df.iloc[i]['fed_funds_rate']

                # ì¬í˜„í•œ rate_signal ë¡œì§
                signal = 0
                real_10y = latest_10y - latest_cpi_yoy
                real_2y = latest_2y - latest_cpi_yoy
                spread = latest_10y - latest_2y
                prev_spread = prev_10y - prev_2y
                delta_spread = spread - prev_spread

                if real_10y < 0:
                    if latest_cpi_yoy < prev_cpi_yoy:
                        signal += 1
                    else:
                        signal -= 1
                if real_2y > 2:
                    signal -= 1
                if spread < -0.5:
                    signal += 1 if delta_spread > 0 else -1
                elif spread > 0:
                    signal += 1 if delta_spread >= 0 else -1
                if latest_2y < latest_fed_rate:
                    signal += 1

                signal_list.append(signal)
            except:
                signal_list.append(None)

        df = df.iloc[1:].copy()
        df['rate_signal'] = signal_list

        # ì‹œê°í™”
        fig, axs = plt.subplots(3, 1, figsize=(14, 12), sharex=True)

        # 1. S&P500
        axs[0].plot(df['date'], df['sp500_close'], label='S&P500', color='black')
        axs[0].scatter(df[df['rate_signal'] >= 2]['date'], df[df['rate_signal'] >= 2]['sp500_close'], marker='^', color='green', label='ğŸ“ˆ ë§¤ìˆ˜ ì‹ í˜¸', s=80)
        axs[0].scatter(df[df['rate_signal'] <= -2]['date'], df[df['rate_signal'] <= -2]['sp500_close'], marker='v', color='red', label='ğŸ“‰ ë§¤ë„ ì‹ í˜¸', s=80)
        axs[0].set_ylabel('S&P500')
        axs[0].legend(loc='upper left')
        axs[0].grid(True)

        # 2. ì‹¤ì§ˆê¸ˆë¦¬ (10Y - CPI YoY)
        axs[1].plot(df['date'], df['real_10y'], label='ì‹¤ì§ˆ 10Y ê¸ˆë¦¬', color='green')
        axs[1].axhline(0, color='gray', linestyle='--')
        axs[1].set_ylabel('10Y - CPI YoY (%)')
        axs[1].legend(loc='upper left')
        axs[1].grid(True)

        # 3. ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨ (10Y - 2Y)
        axs[2].plot(df['date'], df['spread'], label='10Y - 2Y', color='blue')
        axs[2].axhline(0, color='gray', linestyle='--')
        axs[2].fill_between(df['date'], df['spread'], 0, where=(df['spread'] < 0), color='red', alpha=0.2)
        axs[2].set_ylabel('10Y - 2Y (%)')
        axs[2].legend(loc='upper left')
        axs[2].grid(True)

        # 4. ê¸°ì¤€ê¸ˆë¦¬ - 2Y
        # axs[3].plot(df['date'], df['ffr_vs_2y'], label='ê¸°ì¤€ê¸ˆë¦¬ - 2Y', color='orange')
        # axs[3].axhline(0, color='gray', linestyle='--')
        # axs[3].set_ylabel('FFR - 2Y (%)')
        # axs[3].legend(loc='upper left')
        # axs[3].grid(True)

        fig.suptitle("ğŸ“Š ê¸ˆë¦¬ ê¸°ë°˜ ì£¼ìš” ì§€í‘œ vs S&P500 + ì‹œê·¸ë„ ë§ˆí‚¹", fontsize=16)
        plt.tight_layout()
        plt.show()

    def analyze_rate_correlations(self, show_plot: bool = True):
        """
        S&P500 ì¢…ê°€ì™€ ê¸ˆë¦¬ ê´€ë ¨ ì£¼ìš” ì§€í‘œ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„ ë° ì‹œê°í™”
        - ì‹¤ì§ˆ 10ë…„ ê¸ˆë¦¬ (10Y - CPI YoY)
        - ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨ (10Y - 2Y)
        - ê¸°ì¤€ê¸ˆë¦¬ - 2ë…„ë¬¼

        Returns:
            dict: ê° ì§€í‘œì™€ S&P500 ê°„ì˜ í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜
        """
        # 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
        sp500 = self.get_sp500()
        df_10y = self.get_10years_treasury_yeild()
        df_2y = self.get_2years_treasury_yeild()
        cpi_yoy = self.get_cpi_yoy()
        fed = self.get_fed_funds_rate()

        # 2. ë‚ ì§œ í†µì¼ (ì›” ë‹¨ìœ„)
        for df in [sp500, df_10y, df_2y, cpi_yoy, fed]:
            df['date'] = pd.to_datetime(df['date']).dt.to_period('M').dt.to_timestamp()

        # 3. ë³‘í•©
        df = sp500.copy()
        df = df.merge(df_10y[['date', 'value']], on='date').rename(columns={'value': '10y'})
        df = df.merge(df_2y[['date', 'value']], on='date').rename(columns={'value': '2y'})
        df = df.merge(cpi_yoy[['date', 'CPI YOY(%)']], on='date').rename(columns={'CPI YOY(%)': 'cpi_yoy'})
        df = df.merge(fed[['date', 'fed_funds_rate']], on='date')

        # 4. ì§€í‘œ ê³„ì‚°
        df['real_10y'] = df['10y'] - df['cpi_yoy']
        df['spread'] = df['10y'] - df['2y']
        # df['ffr_vs_2y'] = df['fed_funds_rate'] - df['2y']

        # 5. ìƒê´€ê´€ê³„ ê³„ì‚°
        corr_matrix = df[['sp500_close', 'real_10y', 'spread']].corr()
        result = {
            'S&P500 vs ì‹¤ì§ˆ 10Y ê¸ˆë¦¬': round(corr_matrix.loc['sp500_close', 'real_10y'], 3),
            'S&P500 vs ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨': round(corr_matrix.loc['sp500_close', 'spread'], 3)
            #'S&P500 vs ê¸°ì¤€ê¸ˆë¦¬ - 2Y': round(corr_matrix.loc['sp500_close', 'ffr_vs_2y'], 3)
        }
        
        print(result)

        # 6. ì‹œê°í™” (ì„ íƒì )
        if show_plot:
            import matplotlib.pyplot as plt
            import seaborn as sns
            plt.figure(figsize=(8, 6))
            sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', square=True)
            plt.title("S&P500ê³¼ ê¸ˆë¦¬ ê´€ë ¨ ì§€í‘œ ê°„ ìƒê´€ê´€ê³„", fontsize=13)
            plt.tight_layout()
            plt.show()

        return result    

    # Clear - ì›”ë³„ë°ì´í„° - 1ê°œì›” ì§€ì—°
    def get_unemployment_rate(self):
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'UNRATE',
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '2000-01-01'
        }
        response = requests.get(url, params=params)
        data = response.json()
        df = pd.DataFrame(data['observations'])
        df['date'] = pd.to_datetime(df['date'])
        df['unemployment_rate'] = pd.to_numeric(df['value'], errors='coerce')
    
        return df
    
    def get_ism_pmi(self):
        """
        TradingEconomics í•œêµ­ì–´ ì‚¬ì´íŠ¸ì—ì„œ ISM ì œì¡°ì—… PMI ì§€í‘œë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
        """
        url = "https://ko.tradingeconomics.com/united-states/manufacturing-pmi"

        options = Options()
        # options.add_argument('--headless')  # â† ì¼ë‹¨ êº¼ë‘ì„¸ìš”
        options.add_argument('--disable-gpu')
        options.add_argument('--no-sandbox')
        options.add_argument(
            "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
        )

        driver = webdriver.Chrome(options=options)
        driver.get(url)

        try:
            WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "table.table"))
            )
            soup = BeautifulSoup(driver.page_source, 'html.parser')
        except Exception as e:
            driver.quit()
            raise Exception("âŒ í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨: table ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.") from e
        finally:
            driver.quit()

        table = soup.find('table', class_='table table-hover')
        if not table:
            raise Exception("âŒ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        rows = table.find('tbody').find_all('tr')
        for row in rows:
            columns = row.find_all('td')
            if len(columns) >= 5:
                name = columns[0].get_text(strip=True)
                if "ISM ì œì¡°ì—… PMI" in name:
                    value = columns[1].get_text(strip=True)
                    date = columns[4].get_text(strip=True)
                    return {
                        "ì§€í‘œëª…": name,
                        "ê°’": value,
                        "ë°œí‘œì¼": date
                    }

        raise Exception("âŒ 'ISM ì œì¡°ì—… PMI' í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # Clear - ì›”ë³„ ë°ì´í„° - 1ê°œì›” ì§€ì—°
    def update_ism_pmi_data(self):
        '''
        ë¡œì»¬ì— ì €ì¥ëœ ism_pmi íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
        '''
        try:
            pmi_df = self.pmi_updater.update_csv()
            print("âœ… ISM PMI data CSV ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        except Exception as e:
            print("ğŸ“› ISM PMI data ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:", e)
        return pmi_df

    # Clear - ì›”ë³„ë°ì´í„° - 2ê°œì›” ì§€ì—°
    def get_UMCSENT_index(self):
        '''
        ë¯¸ì‹œê°„ ì†Œë¹„ì ì‹¬ë¦¬ì§€ìˆ˜
        100ì´ìƒ : ë‚™ê´€ì  ë¶„ìœ„ê¸°
        80~100 : ì–‘í˜¸í•œ ì‹¬ë¦¬, ê±´ì „í•œ ì†Œë¹„ ì˜ˆìƒ
        60~80 : ì†Œë¹„ì ë¶ˆì•ˆì •, ì†Œë¹„ ìœ„ì¶• ê°€ëŠ¥ì„±
        60 ì´í•˜ : ê²½ê¸° ì¹¨ì²´ ì‹ í˜¸ ê°€ëŠ¥ì„±(ì†Œë¹„ ê¸‰ê° ìš°ë ¤ë ¤)
        '''

        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'UMCSENT',
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '2000-01-01'
        }
        response = requests.get(url, params=params)
        data = response.json()
        df = pd.DataFrame(data['observations'])
        df['date'] = pd.to_datetime(df['date'])
        df['umcsent_index'] = pd.to_numeric(df['value'], errors='coerce')
  
        return df 

    # ë¯¸êµ­ ì„ í–‰ ì§€ìˆ˜ - ì›”ë³„ë°ì´í„°
    def get_us_leading_index_actual(self):
        """
        TradingEconomics ì›¹ í˜ì´ì§€ì—ì„œ ë¯¸êµ­ ì„ í–‰ ì§€ìˆ˜ì˜ ì‹¤ì œê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.

        Args:
            url (str): ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ TradingEconomics í˜ì´ì§€ì˜ URL.

        Returns:
            str: ì‹¤ì œê°’ (ì˜ˆ: '98.80') ë˜ëŠ” ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° None.
        """

        url = "https://ko.tradingeconomics.com/united-states/leading-economic-index"
    
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        
        extracted_data = []

        try:
            # ì›¹ í˜ì´ì§€ì— GET ìš”ì²­ ë³´ë‚´ê¸°
            print(f"URLì— ì ‘ì† ì¤‘: {url}")
            response = requests.get(url, headers=headers)
            response.raise_for_status() # HTTP ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì˜ˆì™¸ ë°œìƒ

            # BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±
            soup = BeautifulSoup(response.text, 'html.parser')

            # 'ctl00_ContentPlaceHolder1_ctl00_ctl00_PanelPeers' IDë¥¼ ê°€ì§„ divë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            panel_peers_div = soup.find('div', id='ctl00_ContentPlaceHolder1_ctl00_ctl00_PanelPeers')
            
            if panel_peers_div:
                # í•´ë‹¹ div ì•ˆì—ì„œ 'table-responsive' í´ë˜ìŠ¤ë¥¼ ê°€ì§„ divë¥¼ ì°¾ê³  ê·¸ ì•ˆì˜ 'table table-hover' í…Œì´ë¸”ì„ ì°¾ìŠµë‹ˆë‹¤.
                table_responsive_div = panel_peers_div.find('div', class_='table-responsive')
                if table_responsive_div:
                    data_table = table_responsive_div.find('table', class_='table table-hover')
                    
                    if data_table:
                        # í…Œì´ë¸” í—¤ë” ì¶”ì¶œ
                        header_row = data_table.find('thead').find('tr')
                        if header_row:
                            headers = [th.get_text(strip=True) for th in header_row.find_all('th')]
                            # ì²« ë²ˆì§¸ ë¹ˆ í—¤ë” ì œê±°
                            if headers and headers[0] == '':
                                headers = headers[1:]
                            print(f"ì¶”ì¶œëœ í—¤ë”: {headers}") # ë””ë²„ê¹…ìš©

                            # 'ë§ˆì§€ë§‰'ê³¼ 'ì°¸ê³ ' ì—´ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
                            try:
                                last_index = headers.index("ë§ˆì§€ë§‰")
                                ref_date_index = headers.index("ì°¸ê³ ")
                            except ValueError as e:
                                print(f"ERROR: í•„ìš”í•œ í—¤ë”('ë§ˆì§€ë§‰' ë˜ëŠ” 'ì°¸ê³ ')ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                                return []

                            # ë°ì´í„° í–‰ ìˆœíšŒ: tbody ìœ ë¬´ì™€ ìƒê´€ì—†ì´ í…Œì´ë¸” ë‚´ì˜ ëª¨ë“  <tr>ì„ ì°¾ê³ , í—¤ë” ë‹¤ìŒ í–‰ë¶€í„° ë°ì´í„°ë¡œ ì²˜ë¦¬
                            all_table_rows = data_table.find_all('tr')
                            
                            # í—¤ë” í–‰ ë‹¤ìŒë¶€í„° ì‹¤ì œ ë°ì´í„° í–‰ìœ¼ë¡œ ê°„ì£¼
                            # í—¤ë”ê°€ <thead> ì•ˆì— ìˆê³ , ë°ì´í„°ëŠ” <tbody> ì•ˆì— ëª…ì‹œë  ìˆ˜ë„ ìˆì§€ë§Œ,
                            # <tbody>ê°€ ì—†ëŠ” ê²½ìš° <tr>ì´ <table> ë°”ë¡œ ì•„ë˜ì— ì˜¬ ìˆ˜ ìˆìŒ.
                            # ë”°ë¼ì„œ thead ì•ˆì˜ trì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ trì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
                            data_rows = [row for row in all_table_rows if row.find_parent('thead') is None]

                            if data_rows:
                                for row in data_rows:
                                    # ì²« ë²ˆì§¸ tdëŠ” ì§€í‘œ ì´ë¦„ì´ë¯€ë¡œ ë”°ë¡œ ì²˜ë¦¬
                                    indicator_name_tag = row.find('td', style="padding-left: 10px; text-align: left;")
                                    indicator_name = indicator_name_tag.get_text(strip=True) if indicator_name_tag else "N/A"

                                    # ì§€í‘œ ì´ë¦„ ì…€ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì…€ì—ì„œ ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
                                    data_cells_excluding_indicator_name = row.find_all('td')[1:] 
                                    processed_data_cells = [cell.get_text(strip=True) for cell in data_cells_excluding_indicator_name]

                                    last_value = None
                                    ref_date = None

                                    # ì¶”ì¶œëœ í—¤ë”ì˜ ì¸ë±ìŠ¤ì— ë”°ë¼ ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
                                    if last_index < len(processed_data_cells):
                                        last_value = processed_data_cells[last_index]
                                    if ref_date_index < len(processed_data_cells):
                                        ref_date = processed_data_cells[ref_date_index]
                                    
                                    extracted_data.append({
                                        "indicator": indicator_name,
                                        "value": last_value,
                                        "date": ref_date
                                    })
                            else:
                                print("ERROR: í…Œì´ë¸”ì—ì„œ ë°ì´í„° í–‰(<tr>)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            print("ERROR: í…Œì´ë¸” í—¤ë” í–‰(<thead><tr>)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        print("ERROR: 'table table-hover' í´ë˜ìŠ¤ë¥¼ ê°€ì§„ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    print("ERROR: 'table-responsive' divë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print("ERROR: 'ctl00_ContentPlaceHolder1_ctl00_ctl00_PanelPeers' IDë¥¼ ê°€ì§„ divë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        except requests.exceptions.RequestException as e:
            print(f"ì›¹ í˜ì´ì§€ì— ì ‘ì†í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        except Exception as e:
            print(f"ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        return extracted_data[0]
    
    # LEI ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    def update_lei_data(self):
        '''
        ë¡œì»¬ì— ì €ì¥ëœ lei íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
        '''
        try:
            lei_df = self.lei_updater.update_csv()
            print("âœ… LEI CSV ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        except Exception as e:
            print("ğŸ“› LEI CSV ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:", e)

        return lei_df    

    def plot_sp500_with_lei_signals(
        self,
        lei_csv_path: str = "lei_data.csv",
        pmi_csv_path: str = "pmi_data.csv",
        sell_delta_pp: float = -0.5,   # 6ê°œì›” ê¸ˆë¦¬ ë³€í™” ì„ê³„ê°’ (ë§¤ë„) : â‰¤ -0.5%p
        buy_delta_pp: float = 0.25,     # 6ê°œì›” ê¸ˆë¦¬ ë³€í™” ì„ê³„ê°’ (ë§¤ìˆ˜) : â‰¥ +0.5%p
        lag_months: int = 1,           # ë°œí‘œì‹œì°¨(ì „ì›”ê°’ì„ ë‹¤ìŒë‹¬ 1ì¼ì— ì•Œ ìˆ˜ ìˆìŒ)
        show_components: bool = False, # Trueë©´ LEI/PMI/Fed ë¼ì¸ë„ ë³´ì¡°ì¶•ì— í•¨ê»˜ ê·¸ë¦¼
        save_to: str | None = None     # íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ì‹¶ìœ¼ë©´ ê²½ë¡œ ì§€ì •
    ):
        """
        S&P500 ì›”ì´ˆ(ì²« ê±°ë˜ì¼) ì¢…ê°€ì— ë§¤ìˆ˜/ë§¤ë„ ë§ˆí¬ì—…ì„ ì°ëŠ” í•¨ìˆ˜
        - LEI/PMIëŠ” CSVì—ì„œ ì½ê³ , ê¸°ì¤€ê¸ˆë¦¬ëŠ” self.get_fed_funds_rate()ë¡œ í˜¸ì¶œ
        - ë°œí‘œì‹œì°¨(ì „ì›” ë°ì´í„°ë¥¼ ë‹¤ìŒ ë‹¬ 1ì¼ì— í™•ì¸)ë¥¼ ë°˜ì˜í•˜ì—¬ ì‹ í˜¸ë¥¼ 'ë°œí‘œì›”ì˜ ì›”ì´ˆ ì¢…ê°€'ì— í‘œì‹œ

        Returns
        -------
        fig : matplotlib.figure.Figure
        signals : pd.DataFrame  # ì‹ í˜¸ ë°œìƒ í–‰ë§Œ ëª¨ì€ ìš”ì•½ í…Œì´ë¸”
        """

        # 1) ë°ì´í„° ë¡œë“œ ----------------------------------------------------------
        # S&P500 (ì¼ë³„) â†’ ì›”ì´ˆ ì¢…ê°€(ì²« ê±°ë˜ì¼)ë¡œ ë³€í™˜
        sp = self.get_sp500().copy()
        sp["date"] = pd.to_datetime(sp["date"])
        sp = sp.sort_values("date")
        # ì›”ì´ˆ ë¹ˆ(label)ìœ¼ë¡œ ë¦¬ìƒ˜í”Œí•˜ë©´ í•´ë‹¹ ì›”ì˜ ì²« ê´€ì¸¡ì¹˜ê°€ ë“¤ì–´ê°
        sp_month_start = (
            sp.set_index("date")
            .resample("MS")            # Month Start
            .first()
            .rename_axis("date")
            .reset_index()[["date", "sp500_close"]]
        )
        sp_month_start["ym"] = sp_month_start["date"].dt.to_period("M")

        # LEI
        lei = pd.read_csv(lei_csv_path)
        # ì»¬ëŸ¼ ìœ ì—° ì²˜ë¦¬
        if "date" not in lei.columns:
            raise ValueError("lei_data.csvì—ëŠ” 'date' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        lei["date"] = pd.to_datetime(lei["date"], format="mixed")
        if "LEI" not in lei.columns:
            # ì¼ë°˜ì ìœ¼ë¡œ 'value'ë¡œ ë“¤ì–´ì˜´
            if "value" in lei.columns:
                lei = lei.rename(columns={"value": "LEI"})
            else:
                raise ValueError("lei_data.csvì—ì„œ LEI ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ('LEI' ë˜ëŠ” 'value' ì»¬ëŸ¼ í•„ìš”)")
        # ì›”ë§ ê¸°ì¤€ ëŒ€í‘œê°’
        lei_m = (lei.set_index("date").resample("M").last().reset_index()[["date", "LEI"]])
        lei_m["ym"] = lei_m["date"].dt.to_period("M")

        # PMI
        pmi = pd.read_csv(pmi_csv_path)
        # ë‚ ì§œ ì»¬ëŸ¼ ìœ ì—° ì²˜ë¦¬
        if "date" in pmi.columns:
            pmi["date"] = pd.to_datetime(pmi["date"])
        elif "Month/Year" in pmi.columns:
            pmi["date"] = pd.to_datetime(pmi["Month/Year"])
        elif "DATE" in pmi.columns:
            pmi["date"] = pd.to_datetime(pmi["DATE"])
        else:
            raise ValueError("pmi_data.csvì— ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. (date / Month/Year / DATE ì¤‘ í•˜ë‚˜)")
        # ê°’ ì»¬ëŸ¼ ìœ ì—° ì²˜ë¦¬
        if "PMI" not in pmi.columns:
            if "value" in pmi.columns:
                pmi = pmi.rename(columns={"value": "PMI"})
            else:
                raise ValueError("pmi_data.csvì—ì„œ PMI ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ('PMI' ë˜ëŠ” 'value')")
        pmi["PMI"] = pd.to_numeric(pmi["PMI"], errors="coerce")
        pmi_m = (pmi.set_index("date").resample("M").last().reset_index()[["date", "PMI"]])
        pmi_m["ym"] = pmi_m["date"].dt.to_period("M")

        # Fed Funds (FRED API)
        fed = self.get_fed_funds_rate().copy()
        fed["date"] = pd.to_datetime(fed["date"])
        fed["fed_funds_rate"] = pd.to_numeric(fed["fed_funds_rate"], errors="coerce")
        # ì›”ë§ ëŒ€í‘œê°’
        fed_m = (
            fed.set_index("date")
            .resample("M")
            .last()
            .reset_index()[["date", "fed_funds_rate"]]
            .rename(columns={"fed_funds_rate": "FEDFUNDS"})
        )
        fed_m["ym"] = fed_m["date"].dt.to_period("M")

        # 2) ë³‘í•© (ì›” ê¸°ì¤€) -------------------------------------------------------
        df = (
            sp_month_start[["date", "ym", "sp500_close"]]
            .merge(lei_m[["ym", "LEI"]], on="ym", how="left")
            .merge(pmi_m[["ym", "PMI"]], on="ym", how="left")
            .merge(fed_m[["ym", "FEDFUNDS"]], on="ym", how="left")
            .sort_values("date")
            .reset_index(drop=True)
        )

        # 3) ê¸ˆë¦¬ 6ê°œì›” ë³€í™”(í¼ì„¼íŠ¸ í¬ì¸íŠ¸) + ë°œí‘œì‹œì°¨ ë°˜ì˜ --------------------------
        df["FEDFUNDS_6M_chg"] = df["FEDFUNDS"] - df["FEDFUNDS"].shift(6)

        # ë°œí‘œì‹œì°¨: ì „ì›” ë°ì´í„°ë¥¼ ë‹¤ìŒë‹¬ 1ì¼ì— ì•Œ ìˆ˜ ìˆìœ¼ë¯€ë¡œ 'lag_months'ë§Œí¼ ì‹œí”„íŠ¸
        df["LEI_used"] = df["LEI"].shift(lag_months)
        df["PMI_used"] = df["PMI"].shift(lag_months)
        df["FEDFUNDS_6M_chg_used"] = df["FEDFUNDS_6M_chg"].shift(lag_months)

        # 4) ì‹ í˜¸ ì •ì˜ ------------------------------------------------------------
        # sell_mask = (df["LEI_used"] < 100) & (df["PMI_used"] < 50) & (df["FEDFUNDS_6M_chg_used"] <= sell_delta_pp)
        buy_mask  = (df["LEI_used"] > 100) & (df["PMI_used"] > 50) & (df["FEDFUNDS_6M_chg_used"] >= buy_delta_pp)

        # df["sell_signal"] = sell_mask.fillna(False)
        df["buy_signal"]  = buy_mask.fillna(False)

        # 5) í”Œë¡¯ -----------------------------------------------------------------
        fig, ax1 = plt.subplots(figsize=(13, 6))
        ax1.plot(df["date"], df["sp500_close"], label="S&P500 (ì›”ì´ˆ ì¢…ê°€)", linewidth=1.6)

        # ë§¤ìˆ˜/ë§¤ë„ ë§ˆí¬ì—…
        buy_pts  = df[df["buy_signal"]]
        # sell_pts = df[df["sell_signal"]]
        ax1.scatter(buy_pts["date"],  buy_pts["sp500_close"],  marker="^", s=60, color = 'red', label=f"Buy (LEI>100 & PMI>50 & 6M â‰¥ {buy_delta_pp:+.1f}pp)")
        # ax1.scatter(sell_pts["date"], sell_pts["sp500_close"], marker="v", s=60, color = 'navy', label=f"Sell (LEI<100 & PMI<50 & 6M â‰¤ {sell_delta_pp:+.1f}pp)")

        ax1.set_title("S&P500 Signals at Month Start (Prev-Month Announced Data)")
        ax1.set_ylabel("S&P500")
        ax1.legend(loc="upper left")

        # ë³´ì¡°ì¶•ì— êµ¬ì„±ìš”ì†Œë„ ë³´ê³  ì‹¶ë‹¤ë©´
        if show_components:
            ax2 = ax1.twinx()
            ax2.plot(df["date"], df["LEI"], alpha=0.6, label="LEI")
            ax2.set_ylabel("LEI")
            # PMIëŠ” ì •ê·œí™”í•´ì„œ ê°™ì€ ì¶•ì—
            pmi_norm = (df["PMI"] - df["PMI"].min()) / (df["PMI"].max() - df["PMI"].min()) * 100
            ax2.plot(df["date"], pmi_norm, linestyle="--", alpha=0.6, label="PMI (norm)")
            # Fed FundsëŠ” ë°”ê¹¥ìª½ ì¶•
            ax3 = ax1.twinx()
            ax3.spines["right"].set_position(("outward", 60))
            ax3.plot(df["date"], df["FEDFUNDS"], linestyle=":", alpha=0.7, label="Fed Funds (%)")
            # ë²”ë¡€ í•©ì¹˜ê¸°
            lines, labels = [], []
            for ax in [ax1, ax2, ax3]:
                l, lab = ax.get_legend_handles_labels()
                lines += l; labels += lab
            ax1.legend(lines, labels, loc="upper left")

        fig.tight_layout()
        if save_to:
            fig.savefig(save_to, dpi=150)

        plt.show()

        # 6) ì‹ í˜¸ í…Œì´ë¸” ë°˜í™˜ ------------------------------------------------------
        signals = df.loc[df["buy_signal"],
                        ["date", "sp500_close", "LEI_used", "PMI_used", "FEDFUNDS_6M_chg_used",
                        "buy_signal"]].reset_index(drop=True)
        
        # ì£¼ë¬¸ì¼ = ì‹¤ì œ ì›”ì´ˆ ì¢…ê°€ê°€ ì°íŒ ë‚ ì§œ
        signals = signals.rename(columns={"date": "ì£¼ë¬¸ì¼"})

        # ë°ì´í„° ê¸°ì¤€ì¼ = ì£¼ë¬¸ì¼ì—ì„œ lag_months ë§Œí¼ ë‹¹ê¸´ ë‹¬
        signals["ë°ì´í„° ê¸°ì¤€ì¼"] = signals["ì£¼ë¬¸ì¼"] - pd.DateOffset(months=lag_months)

        # ë³´ê¸° ì¢‹ê²Œ ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
        signals = signals[["ë°ì´í„° ê¸°ì¤€ì¼", "ì£¼ë¬¸ì¼", "sp500_close",
                        "LEI_used", "PMI_used", "FEDFUNDS_6M_chg_used",
                        "buy_signal"]]
        
        signals = signals.loc[signals['buy_signal'] == True]

        return fig, signals

    def decide_today_lei_signal_min(
        self,
        lei_csv_path: str = "lei_data.csv",
        pmi_csv_path: str = "pmi_data.csv",
        buy_delta_pp: float = 0.25,
        lag_months: int = 1,
        market_tz: str = "America/New_York",  # S&P500 ê±°ë˜ì›” íŒë‹¨ìš©
        today_tz: str = "Asia/Seoul",         # "ì˜¤ëŠ˜ ë‚ ì§œ" í‘œê¸°ìš©
    ):
        
        """
        ì˜¤ëŠ˜ ê¸°ì¤€(ë¡œì»¬ today_tz)ìœ¼ë¡œ, ì´ë²ˆ ë‹¬ ì£¼ë¬¸ì¼(ë¯¸êµ­ì¥ ì›”ì´ˆ ì²« ê±°ë˜ì¼)ì—
        ë§¤ìˆ˜ ì‹ í˜¸ê°€ ìˆëŠ”ì§€ ìš”ì•½í•´ì„œ ë°˜í™˜.

        return: dict (í‚¤ ìˆœì„œ ìœ ì§€)
        - ì˜¤ëŠ˜ ë‚ ì§œ
        - ì‹œê·¸ë„          ("ë§¤ìˆ˜" | "ëŒ€ê¸°" | "ë°ì´í„°ì—†ìŒ")
        - ì£¼ë¬¸ì¼          (ì´ë²ˆ ë‹¬ ì›”ì´ˆ ì²« ê±°ë˜ì¼)
        - ë°ì´í„° ê¸°ì¤€ì¼    (= ì£¼ë¬¸ì¼ - lag_monthsê°œì›”)
        - LEI             (LEI_used)
        - PMI             (PMI_used)
        - 6ê°œì›” ê°„ ê¸ˆë¦¬ë³€ë™ í­ (FEDFUNDS_6M_chg_used)
        """
        import pandas as pd
        import numpy as np

        # --- ì˜¤ëŠ˜ ë‚ ì§œ(ë¡œì»¬ í‘œê¸°ë¥¼ ìœ„í•´ today_tz ì‚¬ìš©)
        today_local = pd.Timestamp.now(tz=today_tz).date()

        # --- S&P500: ì¼ë³„ â†’ ì›”ì´ˆ(ì²« ê±°ë˜ì¼)
        sp = self.get_sp500().copy()
        sp["date"] = pd.to_datetime(sp["date"])
        sp = sp.sort_values("date")
        sp_month_start = (
            sp.set_index("date").resample("MS").first().rename_axis("date").reset_index()
        )
        sp_month_start["ym"] = sp_month_start["date"].dt.to_period("M")

        # --- LEI
        lei = pd.read_csv(lei_csv_path)
        if "date" not in lei.columns:
            raise ValueError("lei_data.csvì—ëŠ” 'date' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        lei["date"] = pd.to_datetime(lei["date"], format='mixed')
        if "LEI" not in lei.columns:
            if "value" in lei.columns:
                lei = lei.rename(columns={"value": "LEI"})
            else:
                raise ValueError("lei_data.csvì—ì„œ LEI ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ('LEI' ë˜ëŠ” 'value')")
        lei_m = lei.set_index("date").resample("M").last().reset_index()[["date", "LEI"]]
        lei_m["ym"] = lei_m["date"].dt.to_period("M")

        # --- PMI
        pmi = pd.read_csv(pmi_csv_path)
        if "date" in pmi.columns:
            pmi["date"] = pd.to_datetime(pmi["date"])
        elif "Month/Year" in pmi.columns:
            pmi["date"] = pd.to_datetime(pmi["Month/Year"])
        elif "DATE" in pmi.columns:
            pmi["date"] = pd.to_datetime(pmi["DATE"])
        else:
            raise ValueError("pmi_data.csvì— ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. (date / Month/Year / DATE ì¤‘ í•˜ë‚˜)")
        if "PMI" not in pmi.columns:
            if "value" in pmi.columns:
                pmi = pmi.rename(columns={"value": "PMI"})
            else:
                raise ValueError("pmi_data.csvì—ì„œ PMI ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ('PMI' ë˜ëŠ” 'value')")
        pmi["PMI"] = pd.to_numeric(pmi["PMI"], errors="coerce")
        pmi_m = pmi.set_index("date").resample("M").last().reset_index()[["date", "PMI"]]
        pmi_m["ym"] = pmi_m["date"].dt.to_period("M")

        # --- Fed Funds (ì›”ë§ ëŒ€í‘œê°’ â†’ 6ê°œì›” ë³€í™”)
        fed = self.get_fed_funds_rate().copy()
        fed["date"] = pd.to_datetime(fed["date"])
        fed["fed_funds_rate"] = pd.to_numeric(fed["fed_funds_rate"], errors="coerce")
        fed_m = (
            fed.set_index("date").resample("M").last().reset_index()[["date", "fed_funds_rate"]]
            .rename(columns={"fed_funds_rate": "FEDFUNDS"})
        )
        fed_m["ym"] = fed_m["date"].dt.to_period("M")

        # --- ë³‘í•©(ì›” ê¸°ì¤€) & ë°œí‘œì‹œì°¨ ë°˜ì˜
        df = (
            sp_month_start[["date", "ym", "sp500_close"]]
            .merge(lei_m[["ym", "LEI"]], on="ym", how="left")
            .merge(pmi_m[["ym", "PMI"]], on="ym", how="left")
            .merge(fed_m[["ym", "FEDFUNDS"]], on="ym", how="left")
            .sort_values("date")
            .reset_index(drop=True)
        )

        # --- ë°œí‘œ ì‹œì°¨(ë§¤ì›” 25ì¼ ê·œì¹™) ë°˜ì˜: ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ ë™ì  lag ê³„ì‚°
        now_us = pd.Timestamp.now(tz=market_tz)  # ë¯¸êµ­ì¥ ê¸°ì¤€ ì˜¤ëŠ˜
        effective_lag = 2 if now_us.day < 25 else 1


        df["FEDFUNDS_6M_chg"] = df["FEDFUNDS"] - df["FEDFUNDS"].shift(6)

        df["LEI_used"] = df["LEI"].shift(effective_lag)
        df["PMI_used"] = df["PMI"].shift(lag_months)
        df["FEDFUNDS_6M_chg_used"] = df["FEDFUNDS_6M_chg"].shift(lag_months)

        buy_mask = (
            (df["LEI_used"] > 100)
            & (df["PMI_used"] > 50)
            & (df["FEDFUNDS_6M_chg_used"] >= buy_delta_pp)
        )
        df["buy_signal"] = buy_mask.fillna(False)

        # --- ì´ë²ˆ ë‹¬ ì£¼ë¬¸ì¼(ë¯¸êµ­ì¥ ê¸°ì¤€ ì›”) ê²°ì •
        now_us = pd.Timestamp.now(tz=market_tz)
        current_period_us = now_us.to_period("M")

        this_row = df[df["date"].dt.to_period("M") == current_period_us].tail(1)
        if this_row.empty:
            # ì´ë²ˆ ë‹¬ ì²« ê±°ë˜ì¼ ë°ì´í„°ê°€ ì•„ì§ ì—†ê±°ë‚˜ ì†ŒìŠ¤ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°
            return {
                "ì˜¤ëŠ˜ ë‚ ì§œ": today_local,
                "ì‹œê·¸ë„": "ë°ì´í„°ì—†ìŒ",
                "ì£¼ë¬¸ì¼": None,
                "ë°ì´í„° ê¸°ì¤€ì¼": None,
                "LEI": None,
                "PMI": None,
                "6ê°œì›” ê°„ ê¸ˆë¦¬ë³€ë™ í­": None,
            }

        row = this_row.iloc[0]
        order_day = pd.to_datetime(row["date"]).date()
        base_day = (pd.to_datetime(row["date"]) - pd.DateOffset(months=lag_months)).date()

        # ì•ˆì „í•œ ì†Œìˆ˜/ê²°ì¸¡ ì²˜ë¦¬
        def _fmt(x, nd=2):
            v = None if pd.isna(x) else float(x)
            return None if v is None else (round(v, nd) if nd is not None else v)

        result = {
            "ì˜¤ëŠ˜ ë‚ ì§œ": today_local,
            "ì‹œê·¸ë„": "BUY" if bool(row["buy_signal"]) else "HOLD",
            "ì£¼ë¬¸ì¼": order_day,
            "ë°ì´í„° ê¸°ì¤€ì¼": base_day,
            "LEI": _fmt(row["LEI_used"], 1),
            "PMI": _fmt(row["PMI_used"], 1),
            "Change_rate": _fmt(row["FEDFUNDS_6M_chg_used"], 2),
        }
        return result

   # Clear - ì›”ë³„ë°ì´í„°(ECRI)
    def get_USSLIND(self):
        '''
        St. Louis Fedê°€ ë°œí‘œí•˜ëŠ” ì§€í‘œë¥¼ ê³µì‹ì ìœ¼ë¡œ FREDì— ì œê³µí•˜ëŠ” í˜•íƒœ
        ìƒìŠ¹ì‹œ ê²½ê¸°íšŒë³µ/í™•ì¥ ì˜ë¯¸, í•˜ë½ì‹œ ê²½ê¸° ë‘”í™”/ì¹¨ì²´ ì˜ë¯¸
        '''
        
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'USSLIND',
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '2000-01-01'
        }
        response = requests.get(url, params=params)
        data = response.json()
        df = pd.DataFrame(data['observations'])
        df['date'] = pd.to_datetime(df['date'])
        df['LI_index'] = pd.to_numeric(df['value'], errors='coerce')
        
        return df
    
    # Clear - ì›”ë³„ë°ì´í„°
    def get_CLI(self):
        '''
        CLIê°€ ë°œí‘œí•˜ëŠ” ì§€í‘œë¥¼ ê³µì‹ì ìœ¼ë¡œ FREDì— ì œê³µí•˜ëŠ” í˜•íƒœ
        ìƒìŠ¹ì‹œ ê²½ê¸°íšŒë³µ/í™•ì¥ ì˜ë¯¸, í•˜ë½ì‹œ ê²½ê¸° ë‘”í™”/ì¹¨ì²´ ì˜ë¯¸
        '''
        
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'USALOLITONOSTSAM',
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '2000-01-01'
        }
        response = requests.get(url, params=params)
        data = response.json()
        df = pd.DataFrame(data['observations'])
        df['date'] = pd.to_datetime(df['date'])
        df['CLI_index'] = pd.to_numeric(df['value'], errors='coerce')
        
        return df

    def analyze_ecri_trend(self):

        df = self.get_CLI()
        x = np.arange(len(df))
        y = df['CLI_index'].values
        slope, _, r_value, _, _ = linregress(x, y)

        if slope > 0.05:
            return "ğŸ“ˆ ìƒìŠ¹ ì¶”ì„¸ (ê²½ê¸° íšŒë³µ ê¸°ëŒ€)"
        elif slope < -0.05:
            return "ğŸ“‰ í•˜ë½ ì¶”ì„¸ (ê²½ê¸° ë‘”í™” ìœ„í—˜)"
        else:
            return "â– íš¡ë³´ ì¶”ì„¸ (ë¶ˆí™•ì‹¤ì„± ì§€ì†)"

    
    def generate_rate_cut_signals(self):
        """
        ê¸°ì¤€ê¸ˆë¦¬ ì¸í•˜ ì‹œì ë¶€í„° 6ê°œì›” ì´ë‚´ì— CLI < 130 ê·¸ë¦¬ê³  PMI < 50ì¸ ê²½ìš° ë§¤ë„ ì‹œê·¸ë„ í‘œì‹œ

        Returns:
            signal_df: ë§¤ë„ ì‹œê·¸ë„ í¬í•¨ëœ DataFrame (date, sp500_close, cli, pmi, rate_cut, signal)
        """
        # 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
        sp500_df = self.get_sp500()
        fed_df = self.generate_fed_rate_turning_points()  # ì „í™˜ì ë§Œ True
        cli_df = self.get_CLI()
        pmi_df = ISMPMIUpdater().preprocess_raw_csv()

        # 2. ë‚ ì§œ ì •ì œ
        sp500_df["date"] = pd.to_datetime(sp500_df["date"])
        sp500_df['month'] = pd.to_datetime(sp500_df['date']).dt.to_period('M').dt.to_timestamp()

        # ê° ì›”ì˜ ì²« ë²ˆì§¸ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” S&P500 ê°’ë§Œ ì¶”ì¶œ
        sp_monthly_first = sp500_df.sort_values('date').groupby('month').first().reset_index()

        # âœ… ê¸°ì¡´ 'date' ì»¬ëŸ¼ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        sp_monthly_first = sp_monthly_first.drop(columns=['date'])
        
        # âœ… ë‚ ì§œë¥¼ í•´ë‹¹ ì›”ì˜ 1ì¼ë¡œ ë°”ê¿”ì¤Œ
        sp_monthly_first = sp_monthly_first.rename(columns={'month': 'date'})
        sp_monthly_first = sp_monthly_first[["date", "sp500_close"]]


        fed_df["date"] = pd.to_datetime(fed_df["date"])
        cli_df["date"] = pd.to_datetime(cli_df["date"])
        pmi_df.rename(columns={"Month/Year": "date"}, inplace=True)
        pmi_df["date"] = pd.to_datetime(pmi_df["date"])

        # 3. ëª¨ë“  ë°ì´í„° ë³‘í•© (outer merge â†’ date ê¸°ì¤€)
        df = sp_monthly_first.merge(cli_df, on="date", how="outer")
        df = df.merge(pmi_df, on="date", how="outer")
        df = df.merge(fed_df[["date", "rate_cut"]], on="date", how="left")

        df = df.sort_values("date").reset_index(drop=True)

        # 4. ë§¤ë„ ì‹œê·¸ë„ ì´ˆê¸°í™”
        df["signal"] = False

        # 5. ê¸°ì¤€ê¸ˆë¦¬ ì¸í•˜ ì‹œì ë¶€í„° 6ê°œì›” ë™ì•ˆ ì¡°ê±´ ì²´í¬
        cut_dates = df[df["rate_cut"] == True]["date"].tolist()

        for cut_date in cut_dates:
            end_date = cut_date + pd.DateOffset(months=6)
            mask = (df["date"] > cut_date) & (df["date"] <= end_date)
            condition = (df["CLI_index"] < 130) & (df["PMI"] < 50)
            df.loc[mask & condition, "signal"] = True

        return df

    # Clear
    def plot_sp500_with_sell_signals(self, save_to = None):

        signal_df = self.generate_rate_cut_signals()
        df = signal_df.copy()
        fig = plt.figure(figsize=(14, 6))
        plt.plot(df["date"], df["sp500_close"], label="S&P500", color="black")

        # ë§¤ë„ ì‹œê·¸ë„ ì‹œê°í™”
        sell_signals = df[df["signal"] == True]
        plt.scatter(sell_signals["date"], sell_signals["sp500_close"],
                    color="red", label="Sell Signal", zorder=5)

        plt.title("S&P500 with Sell Signals (CLI < 130 and PMI < 50 within 6 months of rate cut)")
        plt.xlabel("Date")
        plt.ylabel("S&P500")
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.show()
        if save_to:
            fig.savefig(save_to, format='png')
            plt.close(fig)
        else:
            plt.show()

    # Clear
    def generate_buy_signals_from_hike(self):

        """
        ê¸°ì¤€ê¸ˆë¦¬ ì¸ìƒ ì‹œì‘ ì‹œì  ì´í›„ 6ê°œì›” ì´ë‚´ì—
        CLII > 130 AND PMI > 50 ì¸ ê²½ìš° ë§¤ìˆ˜ ì‹œê·¸ë„ ìƒì„±

        Returns:
            buy_df: ['date', 'cli', 'pmi', 'sp500_close', 'rate_hike', 'buy_signal']
        """
        # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
        fed_df = self.generate_fed_rate_turning_points()  # includes 'rate_hike'
        cli_df = self.get_CLI()
        pmi_df = self.update_ism_pmi_data()
        pmi_df.rename(columns={"Month/Year": "date", "PMI": "pmi"}, inplace=True)
        sp_df = self.get_sp500()

        # âœ… ê° ë‹¬ì˜ ì²« ê±°ë˜ì¼ë§Œ ì¶”ì¶œ
        sp_df['year_month'] = sp_df['date'].dt.to_period('M')
        sp_monthly_first = sp_df.sort_values('date').groupby('year_month').first().reset_index()
        
        # âœ… ë‚ ì§œë¥¼ í•´ë‹¹ ì›”ì˜ 1ì¼ë¡œ ë°”ê¿”ì¤Œ
        sp_monthly_first["date"] = sp_monthly_first["year_month"].dt.to_timestamp()
        sp_monthly_first = sp_monthly_first[["date", "sp500_close"]]


        # ë³‘í•©
        df = fed_df.merge(cli_df, on="date", how="outer")
        df = df.merge(pmi_df, on="date", how="outer")
        df = df.merge(sp_monthly_first, on="date", how="outer")
        df = df.sort_values("date").reset_index(drop=True)

        # 1. rate_hike ë°œìƒ ì‹œì  ëª©ë¡
        hike_dates = df[df["rate_hike"] == True]["date"].tolist()

        # 2. ê° ê¸°ì¤€ê¸ˆë¦¬ ì¸ìƒ ì‹œì‘ ì´í›„ 6ê°œì›” ë™ì•ˆ ì¡°ê±´ ì¶©ì¡± ì—¬ë¶€ í™•ì¸
        df["buy_signal"] = False

        for hike_date in hike_dates:
            window_end = hike_date + pd.DateOffset(months=6)
            window_mask = (df["date"] > hike_date) & (df["date"] <= window_end)
            condition = (df["CLI_index"] > 130) & (df["pmi"] > 50)
            df.loc[window_mask & condition, "buy_signal"] = True

        return df[["date", "fed_funds_rate", "rate_hike", "CLI_index", "pmi", "sp500_close", "buy_signal"]]

    # Clear
    def plot_buy_signals_from_hike(self, save_to = None):
        """
        generate_buy_signals_from_hike() ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ
        S&P500 ì§€ìˆ˜ ê·¸ë˜í”„ ìœ„ì— ë§¤ìˆ˜ ì‹œê·¸ë„ ì‹œì ì„ í‘œì‹œí•˜ëŠ” ì‹œê°í™” í•¨ìˆ˜
        """
        df = self.generate_buy_signals_from_hike()

        fig = plt.figure(figsize=(14, 6))
        plt.plot(df["date"], df["sp500_close"], label="S&P500", color="blue")

        # ë§¤ìˆ˜ ì‹œê·¸ë„ í‘œì‹œ
        buy_signals = df[df["buy_signal"] == True]
        plt.scatter(buy_signals["date"], buy_signals["sp500_close"], color="green", label="Buy Signal", marker="^", s=100)

        plt.title("Buy Signals After Fed Rate Hike Start (CLI > 130 & PMI > 50)")
        plt.xlabel("Date")
        plt.ylabel("S&P500 Index")
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.show()
        if save_to:
            fig.savefig(save_to, format='png')
            plt.close(fig)
        else:
            plt.show()


    def find_signals_from_erci_indicators(self):
        """
        ì‹¤ì—…ë¥ ê³¼ ERCI(USSLIND) ì§€í‘œ ë°œí‘œ ì§€ì—°ì„ ê³ ë ¤í•˜ì—¬ ì¡°ê±´ ì¶©ì¡± ì‹œì ì„ ì°¾ëŠ” í•¨ìˆ˜

        ë§¤ìˆ˜ ì¡°ê±´: ì‹¤ì—…ë¥  > í‰ê· , ECRI < 95
        ë§¤ë„ ì¡°ê±´: ì‹¤ì—…ë¥  < í‰ê· , ECRI >= 110

        Returns:
            signal_df : ë§¤ìˆ˜/ë§¤ë„ ì‹œì ê³¼ ì¡°ê±´ ì •ë³´ë¥¼ í¬í•¨í•œ DataFrame
        """
        from pandas.tseries.offsets import MonthBegin
        import pandas as pd

        # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
        ecri_df = self.get_USSLIND()  # 'LI_index' ë˜ëŠ” 'value', 'date' í¬í•¨
        unemp_df = self.get_unemployment_rate()  # 'unemployment_rate' ë˜ëŠ” 'value', 'date' í¬í•¨

        # date ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì¸ë±ìŠ¤ë¡œ ì§€ì • + datetime ë³€í™˜
        if "date" in ecri_df.columns:
            ecri_df["date"] = pd.to_datetime(ecri_df["date"])
            ecri_df = ecri_df.set_index("date")

        if "date" in unemp_df.columns:
            unemp_df["date"] = pd.to_datetime(unemp_df["date"])
            unemp_df = unemp_df.set_index("date")

        # í•„ìš”í•œ ì»¬ëŸ¼ ì„ íƒ ë° ì´ë¦„ ì§€ì •
        ecri_series = ecri_df["LI_index"] if "LI_index" in ecri_df.columns else ecri_df["value"]
        ecri_series.name = "ECRI"

        unemp_series = unemp_df["unemployment_rate"] if "unemployment_rate" in unemp_df.columns else unemp_df["value"]
        unemp_series.name = "Unemployment"

        # 1ê°œì›” ë°œí‘œ ì§€ì—° ì ìš©
        ecri_shifted = ecri_series.shift(1)
        ecri_shifted.index = ecri_shifted.index + MonthBegin(1)

        unemp_shifted = unemp_series.shift(1)
        unemp_shifted.index = unemp_shifted.index + MonthBegin(1)


        # ë³‘í•© í›„ ì¡°ê±´ ì ìš©
        cond_df = pd.concat([ecri_shifted, unemp_shifted], axis=1).dropna()
        print("ğŸ“† ë³‘í•© cond_df ë§ˆì§€ë§‰ ë‚ ì§œ:", cond_df.index.max())

        unemp_mean = cond_df["Unemployment"].mean()
        print("ì‹¤ì—…ë¥  í‰ê· :", cond_df["Unemployment"].mean())

        buy_signals = cond_df[(cond_df["Unemployment"] > unemp_mean) & (cond_df["ECRI"] < 0.95)].copy()
        buy_signals["signal"] = "buy"

        sell_signals = cond_df[(cond_df["Unemployment"] < unemp_mean) & (cond_df["ECRI"] >= 1.10)].copy()
        sell_signals["signal"] = "sell"

        signal_df = pd.concat([buy_signals, sell_signals]).sort_index()
        return signal_df
    
    def plot_sp500_with_ERCI_signals(self):
        import matplotlib.pyplot as plt
        import seaborn as sns
        sns.set_style("whitegrid")

        sp500 = self.get_sp500().copy()
        # "date" ì»¬ëŸ¼ì´ ì¡´ì¬í•œë‹¤ë©´, ì´ê±¸ datetimeìœ¼ë¡œ ë³€í™˜ í›„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
        sp500["date"] = pd.to_datetime(sp500["date"])
        sp500 = sp500.set_index("date")
        sp500 = sp500.sort_index()

        # ì‹œê·¸ë„ ë°ì´í„° ì •ë ¬
        signal_df = self.find_signals_from_erci_indicators()
        signal_df = signal_df.sort_index()

        fig, ax = plt.subplots(figsize=(14, 6))
        ax.plot(sp500.index, sp500["sp500_close"], label="S&P500", color="black")

        # ê° ì‹œê·¸ë„ ë‚ ì§œì— ê°€ê¹Œìš´ S&P500 ì¢…ê°€ ìœ„ì— ë§ˆì»¤ í‘œì‹œ
        for date, row in signal_df.iterrows():
            # í•´ë‹¹ ë‚ ì§œ ì´í›„ì˜ ì²« S&P500 ì¢…ê°€ ì°¾ê¸°
            nearest = sp500[sp500.index >= date]
            if not nearest.empty:
                y = nearest.iloc[0]["sp500_close"]
                if row["signal"] == "buy":
                    ax.scatter(date, y, color="green", marker="^", s=100, label="Buy" if "Buy" not in ax.get_legend_handles_labels()[1] else "")
                elif row["signal"] == "sell":
                    ax.scatter(date, y, color="red", marker="v", s=100, label="Sell" if "Sell" not in ax.get_legend_handles_labels()[1] else "")

        ax.set_title("S&P500 with Buy/Sell Signals (Monthly signal date)", fontsize=14)
        ax.set_ylabel("S&P500 Index")
        ax.legend()
        plt.tight_layout()
        plt.show()



    def update_snp_forwardpe_data(self):
        '''
        ë¡œì»¬ì— ì €ì¥ëœ S&P500 forward pe íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
        '''
        try:
            snp_fp_df = self.snp_forwardpe_updater.update_forward_pe_csv()
            print("âœ… S&P500 Forward PE CSV ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        except Exception as e:
            print("ğŸ“› S&P500 Forward PE ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:", e)

        return snp_fp_df    


    def get_forward_pe(self):
            url = 'https://en.macromicro.me/series/20052/sp500-forward-pe-ratio'

            options = Options()
            # options.add_argument("--headless")
            options.add_argument("--no-sandbox")
            options.add_argument("--disable-gpu")
 

            driver = webdriver.Chrome(options=options)
            driver.get(url)


            try:
                # âœ… í•´ë‹¹ ìš”ì†Œê°€ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 10ì´ˆ)
                WebDriverWait(driver, 20).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "div.sidebar-sec.chart-stat-lastrows span.val"))
                )
            except:
                driver.quit()
                raise RuntimeError("ğŸ“› í˜ì´ì§€ ë¡œë”© ì¤‘ Forward PE ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            soup = BeautifulSoup(driver.page_source, 'html.parser')
            driver.quit()

            latest_val = soup.select_one("div.sidebar-sec.chart-stat-lastrows span.val")
            date = soup.select_one("div.sidebar-sec.chart-stat-lastrows .date-label")

            if latest_val and date:
                date_text = date.text.strip()
                pe_val = float(latest_val.text.strip())
                df = pd.DataFrame([{"date": date_text, "forward_pe": pe_val}])
                return {
                    "date": date_text,
                    "forward_pe": pe_val
                }
            else:
                raise ValueError("ğŸ“› Forward PE ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            

    def get_ttm_pe(self):
        url = "https://www.multpl.com/s-p-500-pe-ratio"

        # options = Options()
        # options.add_argument("--headless")
        # options.add_argument("--disable-gpu")
        # options.add_argument("--no-sandbox")

        # driver = webdriver.Chrome(options=options)
        # driver.get(url)
        # time.sleep(5)  # JS ë¡œë”© ëŒ€ê¸°

        response = requests.get(url)
        soup = BeautifulSoup(response.text, "html.parser")

        # ë‚ ì§œ ì¶”ì¶œ
        timestamp_tag = soup.select_one("#timestamp")
        date = timestamp_tag.get_text(strip=True)

        # PE ê°’ ì¶”ì¶œ
        current_div = soup.select_one("#current")
        
        # <div id="current"> ë‚´ì—ì„œ <b> íƒœê·¸ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” í…ìŠ¤íŠ¸ ë…¸ë“œê°€ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ìˆ«ì
        b_tag = current_div.find("b")
        ttm_pe = b_tag.next_sibling.strip()


        return {
            "date": date,
            "ttm_pe": ttm_pe
        }   

        # soup = BeautifulSoup(driver.page_source, "html.parser")
        # driver.quit()

        # "Last Value" í…ìŠ¤íŠ¸ê°€ ìˆëŠ” td ì°¾ê¸°
        # for td in soup.select("td.col-6"):
        #     if "Last Value" in td.get_text(strip=True):
        #         value_td = td.find_next_sibling("td")
        #         if value_td:
        #             return {
        #                 'date : '
        #             }# value_td.get_text(strip=True)

        return None

    def analyze_pe(self,
                fwd_buy_lt: float = 12.0,
                fwd_sell_gt: float = 22.0,
                ttm_sell_gt: float = 25.0):
        """
        Returns dict for Streamlit:
        - date, ttm_pe, forward_pe (ì†Œìˆ«ì  2ìë¦¬ ë°˜ì˜¬ë¦¼)
        - absolute(Forward ê¸°ì¤€), absolute_forward, absolute_ttm
        - forward_vs_ttm
        - signal: 'BUY' | 'SELL' | 'HOLD' | 'N/A'
        - signal_reason: íŠ¸ë¦¬ê±° ì‚¬ìœ  ìš”ì•½
        - signal_md: st.markdown()/st.write()ë¡œ ë°”ë¡œ ì“¸ ìˆ˜ ìˆëŠ” ì„¤ëª… ë¸”ëŸ­
        - message: ì „ì²´ ìš”ì•½ í…ìŠ¤íŠ¸
        """

        # --- ë°ì´í„° ì·¨ë“ ---
        ttm_pe_raw = self.get_ttm_pe().get("ttm_pe", "")
        try:
            ttm_pe = float(str(ttm_pe_raw).replace(",", "").strip())
        except Exception:
            ttm_pe = np.nan

        fwd_df = pd.read_csv("forward_pe_data.csv")
        fwd_df["forward_pe"] = pd.to_numeric(fwd_df["forward_pe"], errors="coerce")
        forward_pe = fwd_df["forward_pe"].dropna().iloc[-1] if not fwd_df["forward_pe"].dropna().empty else np.nan

        # --- ì ˆëŒ€í‰ê°€ ---
        if pd.notna(forward_pe):
            if forward_pe > fwd_sell_gt:
                absolute_forward = "ê³ í‰ê°€"
            elif forward_pe < fwd_buy_lt:
                absolute_forward = "ì €í‰ê°€"
            else:
                absolute_forward = "í‰ê· "
        else:
            absolute_forward = "N/A"

        if pd.notna(ttm_pe):
            if ttm_pe > ttm_sell_gt:
                absolute_ttm = "ê³ í‰ê°€"
            elif ttm_pe < 13:
                absolute_ttm = "ì €í‰ê°€"
            else:
                absolute_ttm = "í‰ê· "
        else:
            absolute_ttm = "N/A"

        if pd.notna(ttm_pe) and pd.notna(forward_pe):
            if ttm_pe > forward_pe:
                forward_vs_ttm = "í–¥í›„ ì‹¤ì  ê°œì„  ê¸°ëŒ€(ë‚™ê´€ì )"
            elif ttm_pe < forward_pe:
                forward_vs_ttm = "ì‹¤ì  ë‘”í™” ë°˜ì˜(ë³´ìˆ˜ì )"
            else:
                forward_vs_ttm = "í˜„ì¬ ìˆ˜ì¤€ ìœ ì§€ ì˜ˆìƒ"
        else:
            forward_vs_ttm = "N/A"

        # --- ì‹œê·¸ë„ ë¡œì§ ---
        # ê¸°ë³¸ ê·œì¹™:
        # - BUY: Forward P/E < fwd_buy_lt
        # - SELL: Forward P/E > fwd_sell_gt OR TTM P/E > ttm_sell_gt
        # - ê·¸ ì™¸: HOLD
        triggers = []
        if pd.notna(forward_pe) and forward_pe < fwd_buy_lt:
            signal = "BUY"
            triggers.append(f"Forward P/E < {fwd_buy_lt:.2f}")
        elif (pd.notna(forward_pe) and forward_pe > fwd_sell_gt) or (pd.notna(ttm_pe) and ttm_pe > ttm_sell_gt):
            signal = "SELL"
            if pd.notna(forward_pe) and forward_pe > fwd_sell_gt:
                triggers.append(f"Forward P/E > {fwd_sell_gt:.2f}")
            if pd.notna(ttm_pe) and ttm_pe > ttm_sell_gt:
                triggers.append(f"TTM P/E > {ttm_sell_gt:.2f}")
        elif pd.notna(forward_pe) or pd.notna(ttm_pe):
            signal = "HOLD"
            triggers.append("ì„ê³„ì¹˜ ë²”ìœ„ ë‚´")
        else:
            signal = "N/A"
            triggers.append("ìœ íš¨í•œ P/E ë°ì´í„° ì—†ìŒ")

        signal_reason = " & ".join(triggers)

        # --- ë‚ ì§œ/ì¶œë ¥ í¬ë§· ---
        today_kst = datetime.now(ZoneInfo("Asia/Seoul")).date().isoformat()

        # ë‘ ìë¦¬ ë°˜ì˜¬ë¦¼ ê°’
        ttm_pe_2 = float(f"{ttm_pe:.2f}") if pd.notna(ttm_pe) else np.nan
        forward_pe_2 = float(f"{forward_pe:.2f}") if pd.notna(forward_pe) else np.nan

        # ìš”ì•½ ë©”ì‹œì§€
        message = (
            f"ğŸ“… ê¸°ì¤€ì¼: {today_kst}\n\n"
            f"ğŸ“Š S&P 500 Forward PER: {forward_pe_2:.2f}\n"
            f"ğŸ“Š S&P 500 TTM PER: {ttm_pe_2:.2f}\n\n"
            f"ğŸ§­ ì ˆëŒ€í‰ê°€(Forward ê¸°ì¤€): {absolute_forward}\n"
            f"ğŸ§­ ì ˆëŒ€í‰ê°€(TTM ê¸°ì¤€): {absolute_ttm}\n"
            f"ğŸ” Forward vs TTM: {forward_vs_ttm}\n\n"
            f"ğŸš¦ Signal: {signal}  ({signal_reason})"
        )

        # Streamlit í‘œê¸°ìš© ì„¤ëª… ë¸”ëŸ­ (Markdown)
        signal_md = (
            "### ğŸš¦ PER ê¸°ë°˜ ìë™ ì‹œê·¸ë„\n"
            f"- **ê·œì¹™**  \n"
            f"  - ë§¤ìˆ˜(BUY): Forward P/E **< {fwd_buy_lt:.2f}**  \n"
            f"  - ë§¤ë„(SELL): Forward P/E **> {fwd_sell_gt:.2f}** ë˜ëŠ” TTM P/E **> {ttm_sell_gt:.2f}**  \n"
            f"  - ê·¸ ì™¸: **HOLD**  \n\n"
            f"- **í˜„ì¬ ìˆ˜ì¹˜**  \n"
            f"  - Forward P/E: **{forward_pe_2:.2f}**  \n"
            f"  - TTM P/E: **{ttm_pe_2:.2f}**  \n\n"
            f"- **íŒë‹¨ ê²°ê³¼**  \n"
            f"  - **Signal: {signal}**  \n"
            f"  - íŠ¸ë¦¬ê±°: {signal_reason}  \n"
        )

        return {
            "date": today_kst,
            "ttm_pe": ttm_pe_2,
            "forward_pe": forward_pe_2,
            "absolute": absolute_forward,
            "absolute_forward": absolute_forward,
            "absolute_ttm": absolute_ttm,
            "forward_vs_ttm": forward_vs_ttm,
            "signal": signal,
            "signal_reason": signal_reason,
            "signal_md": signal_md,
            "message": message,
        }

    # def analyze_pe(self):

    #     ttm_pe_result = self.get_ttm_pe()
    #     ttm_pe = ttm_pe_result["ttm_pe"]  # ë¬¸ìì—´

    #     forward_pe_result = pd.read_csv("forward_pe_data.csv")
    #     forward_pe = forward_pe_result["forward_pe"].iloc[-1]

    #     # âœ… ë¬¸ìì—´ì¼ ìˆ˜ ìˆëŠ” ttm_peë¥¼ floatë¡œ ë³€í™˜
    #     ttm_pe = float(ttm_pe) #.replace(",", "").strip()
    #     forward_pe = float(forward_pe)

    #     message = f"ğŸ“Š S&P 500 Forward PER: {forward_pe:.2f}\n"
    #     message += f"ğŸ“Š S&P 500 TTM PER: {ttm_pe:.2f}\n\n"

    #     # ì ˆëŒ€ì  ê³ í‰ê°€/ì €í‰ê°€ íŒë‹¨
    #     if forward_pe > 21:
    #         message += "âš ï¸ Forward PER ê¸°ì¤€ìœ¼ë¡œ **ê³ í‰ê°€** êµ¬ê°„ì…ë‹ˆë‹¤.\n"
    #     elif forward_pe < 17:
    #         message += "âœ… Forward PER ê¸°ì¤€ìœ¼ë¡œ **ì €í‰ê°€** êµ¬ê°„ì…ë‹ˆë‹¤.\n"
    #     else:
    #         message += "âš–ï¸ Forward PER ê¸°ì¤€ìœ¼ë¡œ **í‰ê·  ë²”ìœ„**ì…ë‹ˆë‹¤.\n"

    #     # TTM ê¸°ì¤€ ê³ í‰ê°€/ì €í‰ê°€ íŒë‹¨
    #     if ttm_pe > 20:
    #         message += "âš ï¸ TTM PER ê¸°ì¤€ìœ¼ë¡œ **ì—­ì‚¬ì  ê³ í‰ê°€** êµ¬ê°„ì…ë‹ˆë‹¤.\n"
    #     elif ttm_pe < 13:
    #         message += "âœ… TTM PER ê¸°ì¤€ìœ¼ë¡œ **ì €í‰ê°€** êµ¬ê°„ì…ë‹ˆë‹¤.\n"
    #     else:
    #         message += "âš–ï¸ TTM PER ê¸°ì¤€ìœ¼ë¡œ **í‰ê·  ìˆ˜ì¤€**ì…ë‹ˆë‹¤.\n"

    #     # TTM ëŒ€ë¹„ Forward ë¹„êµ
    #     if ttm_pe > forward_pe:
    #         message += "ğŸŸ¢ ì‹œì¥ì€ **í–¥í›„ ì‹¤ì  ê°œì„ **ì„ ê¸°ëŒ€í•˜ëŠ” ë‚™ê´€ì ì¸ íë¦„ì…ë‹ˆë‹¤."
    #     elif ttm_pe < forward_pe:
    #         message += "ğŸ”´ ì‹œì¥ì€ **ì‹¤ì  ë‘”í™”**ë¥¼ ë°˜ì˜í•˜ëŠ” ë³´ìˆ˜ì ì¸ íë¦„ì…ë‹ˆë‹¤."
    #     else:
    #         message += "âšª ì‹œì¥ì€ í˜„ì¬ ì‹¤ì  ìˆ˜ì¤€ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•  ê²ƒìœ¼ë¡œ ë³´ê³  ìˆìŠµë‹ˆë‹¤."

    #     return message
    
    def get_vix_index(self):
        '''
        VIX : VIXëŠ” S&P 500 ì§€ìˆ˜ì˜ ì˜µì…˜ ê°€ê²©ì— ê¸°ì´ˆí•˜ë©°, í–¥í›„ 30ì¼ê°„ ì§€ìˆ˜ì˜ í’‹ì˜µì…˜1ê³¼ ì½œì˜µì…˜2 ê°€ì¤‘ ê°€ê²©ì„ ê²°í•©í•˜ì—¬ ì‚°ì •
        í–¥í›„ S&P 500ì§€ìˆ˜ê°€ ì–¼ë§ˆë‚˜ ë³€ë™í•  ê²ƒìœ¼ë¡œ íˆ¬ììë“¤ì´ ìƒê°í•˜ëŠ”ì§€ë¥¼ ë°˜ì˜
        '''
        df = yf.download('^VIX', start="2000-01-01", interval="1d")
        if df.empty:
            print("âŒ VIX ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        # ë°ì´í„°í”„ë ˆì„ì˜ ë©€í‹°ë ˆë²¨ ì»¬ëŸ¼ì„ ë‹¨ì¼ ë ˆë²¨ë¡œ í‰íƒ„í™”
        df.columns = ['_'.join(col) if isinstance(col, tuple) else col for col in df.columns]
        
        df = df.reset_index()
        
        # í•„ìš”í•œ 'Date'ì™€ 'Close_^VIX' ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ê³  ì´ë¦„ì„ ë³€ê²½í•©ë‹ˆë‹¤.
        df = df[['Date', 'Close_^VIX']].rename(columns={'Date': 'date', 'Close_^VIX': 'vix_index'})
        
        df['date'] = pd.to_datetime(df['date'])

        return df
    
    def analyze_vix(self):
        df_vix = self.get_vix_index()
        df_vix = df_vix.sort_values('date')
        latest = df_vix.iloc[-1]

        date = latest['date']
        vix = float(latest['vix'])  # â† ì—¬ê¸°ì„œ float ë³€í™˜

        result = [f"ğŸ“… ê¸°ì¤€ì¼: {date}",
                f"ğŸ“Š VIX ì§€ìˆ˜ (S&P 500 ë³€ë™ì„±): {vix:.2f}"]

        if vix < 12:
            result.append("ğŸ“‰ ê³¼ë„í•œ ë‚™ê´€ ìƒíƒœ â†’ ì €ë³€ë™ì„± í™˜ê²½ (ê³ ì  ê²½ê³„ ê°€ëŠ¥ì„±)")
        elif vix < 20:
            result.append("ğŸŸ¢ ì‹œì¥ì´ ì•ˆì •ì ì¸ ìƒíƒœ (ë‚™ê´€ì  ì‹¬ë¦¬)")
        elif vix < 30:
            result.append("âš ï¸ ì‹œì¥ ë¶ˆí™•ì‹¤ì„± ì¦ê°€ â†’ íˆ¬ìì ì£¼ì˜ í•„ìš”")
        elif vix <40:
            result.append("ğŸŸ  ì‹œì¥ ìœ„í—˜ ìƒíƒœ â†’ ê³¼ë§¤ë„/ì €ì  ë°˜ë“± ê°€ëŠ¥ì„± (ì—­ë°œìƒ ë§¤ìˆ˜ ê³ ë ¤ êµ¬ê°„)")
        else:
            result.append("ğŸ”´ ì‹œì¥ ê·¹ë‹¨ì  ë¶ˆì•ˆ ìƒíƒœ â†’ ê³¼ë§¤ë„/ì €ì  ë°˜ë“± ê°€ëŠ¥ì„± (ì—­ë°œìƒ ë§¤ìˆ˜ ê³ ë ¤ êµ¬ê°„) ")

        return "\n".join(result)
    
    # M2/PER(Forward) ë°ì´í„° ë² ì´ìŠ¤ êµ¬í•  ìˆ˜ ìˆë‚˜?    

    def get_equity_put_call_ratio(self):
        url = 'https://ycharts.com/indicators/cboe_equity_put_call_ratio'

        options = Options()
        options.add_argument("--headless")
        options.add_argument("--disable-gpu")
        options.add_argument("--no-sandbox")

        driver = webdriver.Chrome(options=options)
        driver.get(url)
        time.sleep(5)  # JS ë¡œë”© ëŒ€ê¸°

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        driver.quit()

        # "Last Value" í…ìŠ¤íŠ¸ê°€ ìˆëŠ” td ì°¾ê¸°
        for td in soup.select("td.col-6"):
            if "Last Value" in td.get_text(strip=True):
                value_td = td.find_next_sibling("td")
                if value_td:
                    equity_value = value_td.get_text(strip=True)
                    break

        # âœ… Last Period (ë‚ ì§œ) ì¶”ì¶œ - tr ê¸°ë°˜ìœ¼ë¡œ ë”°ë¡œ íƒìƒ‰
        for row in soup.find_all("tr"):
            tds = row.find_all("td")
            if len(tds) == 2 and "Latest Period" in tds[0].get_text(strip=True):
                date = tds[1].get_text(strip=True)
                break

        if equity_value and date:
            return {
                "date": date,
                "equity_value": equity_value
            }
        else:
            raise ValueError("âŒ Last Value ë˜ëŠ” Last Periodë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


    def get_index_put_call_ratio(self):
        url = 'https://ycharts.com/indicators/cboe_index_put_call_ratio'

        options = Options()
        options.add_argument("--headless")
        options.add_argument("--disable-gpu")
        options.add_argument("--no-sandbox")

        driver = webdriver.Chrome(options=options)
        driver.get(url)
        time.sleep(5)  # JS ë¡œë”© ëŒ€ê¸°

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        driver.quit()

        # "Last Value" í…ìŠ¤íŠ¸ê°€ ìˆëŠ” td ì°¾ê¸°
        for td in soup.select("td.col-6"):
            if "Last Value" in td.get_text(strip=True):
                value_td = td.find_next_sibling("td")
                if value_td:
                    index_value = value_td.get_text(strip=True)
                    break

        # âœ… Last Period (ë‚ ì§œ) ì¶”ì¶œ - tr ê¸°ë°˜ìœ¼ë¡œ ë”°ë¡œ íƒìƒ‰
        for row in soup.find_all("tr"):
            tds = row.find_all("td")
            if len(tds) == 2 and "Latest Period" in tds[0].get_text(strip=True):
                date = tds[1].get_text(strip=True)
                break

        if index_value and date:
            return {
                "date": date,
                "equity_value": index_value
            }
        else:
            raise ValueError("âŒ Last Value ë˜ëŠ” Last Periodë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def update_putcall_ratio(self):
        '''
        ë¡œì»¬ì— ì €ì¥ëœ PUT CALL RATIO íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
        '''
        putcall_df = None  # âœ… ì•ˆì „í•œ ì´ˆê¹ƒê°’

        try:
            putcall_df = self.put_call_ratio_updater.update_csv()
            print("âœ… PutCall Ratio CSV ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        except Exception as e:
            print("ğŸ“› PutCall Ratio ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:", e)

        return putcall_df  
    
    def plot_sp500_with_pcr_signals(self, save_to: str | None = None):
        """
        Put/Call Ratio (equity_value) ê¸°ì¤€ìœ¼ë¡œ S&P500 ì¢…ê°€ ìœ„ì— ë§¤ìˆ˜/ë§¤ë„ ì‹ í˜¸ë¥¼ í‘œê¸°.
        ë™ì‹œì— ì‹ í˜¸ í…Œì´ë¸”(DataFrame)ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

        Parameters
        ----------
        pcr_csv : str
            'date, equity_value, index_value' ì»¬ëŸ¼ì„ ê°–ëŠ” CSV ê²½ë¡œ
        buy_thr : float
            ë§¤ìˆ˜ ì„ê³„ê°’ (equity_value > buy_thr)
        sell_thr : float
            ë§¤ë„ ì„ê³„ê°’ (equity_value < sell_thr)
        save_to : str | None
            ê·¸ë˜í”„ ì €ì¥ ê²½ë¡œ. Noneì´ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ.

        Returns
        -------
        fig : matplotlib.figure.Figure
        signals_df : pandas.DataFrame  # ['date','sp500_close','equity_value','signal']
        """

        buy_thr = 1.5
        sell_thr = 0.4

        # ---------- 1) S&P500 ì¼ë³„ ë¼ì¸ êµ¬ì„± ----------
        sp_daily = self.get_sp500().copy()  # ë°˜ë“œì‹œ ì¼ë³„ ë°ì´í„° ë°˜í™˜
        sp_daily["date"] = pd.to_datetime(sp_daily["date"])

        # ì»¬ëŸ¼ í‘œì¤€í™”
        if "close" in sp_daily.columns:
            sp_daily = sp_daily.rename(columns={"close": "sp500_close"})
        elif "Close" in sp_daily.columns:
            sp_daily = sp_daily.rename(columns={"Close": "sp500_close"})
        # ì´ë¯¸ 'sp500_close'ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©

        sp_line = (
            sp_daily[["date", "sp500_close"]]
            .dropna()
            .drop_duplicates(subset=["date"])
            .sort_values("date")
            .reset_index(drop=True)
        )

        # ---------- 2) PCR ë¡œë“œ (í˜•ì‹ ê³ ì •) ----------
        pcr = pd.read_csv('put_call_ratio.csv')
        expected_cols = {"date", "equity_value", "index_value"}
        if set(pcr.columns) != expected_cols:
            raise ValueError(
                f"PCR ì»¬ëŸ¼ì€ ì •í™•íˆ {expected_cols} ì´ì–´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {list(pcr.columns)}"
            )

        pcr["date"] = pd.to_datetime(pcr["date"])
        # ìˆ«ìí˜• ë³´ì •
        pcr["equity_value"] = pd.to_numeric(pcr["equity_value"], errors="coerce")

        # ---------- 3) ë³‘í•© & ì‹ í˜¸ ê³„ì‚° ----------
        df = sp_line.merge(pcr[["date", "equity_value"]], on="date", how="left")

        buy_mask = df["equity_value"] > buy_thr
        sell_mask = df["equity_value"] < sell_thr

        signals_df = df.loc[buy_mask | sell_mask, ["date", "sp500_close", "equity_value"]].copy()
        signals_df["signal"] = np.where(signals_df["equity_value"] > 1.5, "BUY", "SELL")
        signals_df = signals_df.sort_values("date").reset_index(drop=True)

        # ---------- 4) ì‹œê°í™” ----------
        fig, ax = plt.subplots(figsize=(12, 6))
        ax.plot(df["date"], df["sp500_close"], label="S&P 500")
        ax.scatter(df.loc[buy_mask, "date"], df.loc[buy_mask, "sp500_close"],
                   marker="^", s=64, label=f"BUY (PCR>{buy_thr})")
        ax.scatter(df.loc[sell_mask, "date"], df.loc[sell_mask, "sp500_close"],
                   marker="v", s=64, label=f"SELL (PCR<{sell_thr})")

        ax.set_title("S&P 500 with Put/Call Ratio (Equity) Signals")
        ax.set_xlabel("Date")
        ax.set_ylabel("S&P 500 Close")
        ax.legend()
        ax.grid(True)
        fig.tight_layout()

        if save_to:
            fig.savefig(save_to, dpi=160)

        return fig, signals_df

    def decide_equity_pcr_today(self):
        """
        put_call_ratio.csvì˜ ê°€ì¥ ìµœì‹  ê´€ì¸¡ì¹˜ë¥¼ ì‚¬ìš©í•´
        ì˜¤ëŠ˜(ìµœê·¼ì¼) ë§¤ìˆ˜/ë§¤ë„/HOLD ì‹œê·¸ë„ì„ ê²°ì •í•˜ì—¬ DataFrameìœ¼ë¡œ ë°˜í™˜.

        Returns
        -------
        pandas.DataFrame
            columns = ['date', 'equity_value', 'signal'] (1í–‰)
        """
        
        
        buy_thr: float = 1.5
        sell_thr: float = 0.4

        df = pd.read_csv("put_call_ratio.csv")
        required = {"date", "equity_value", "index_value"}
        if not required.issubset(df.columns):
            raise ValueError(f"put_call_ratio.csv must contain columns: {required}. Got: {list(df.columns)}")

        # ì •ë¦¬
        df = df.copy()
        df["date"] = pd.to_datetime(df["date"], errors="coerce")
        df["equity_value"] = pd.to_numeric(df["equity_value"], errors="coerce")
        df = df.dropna(subset=["date", "equity_value"]).sort_values("date").reset_index(drop=True)

        if df.empty:
            # ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ DF ë°˜í™˜
            return pd.DataFrame(columns=["date", "equity_value", "signal"])

        last = df.iloc[-1]
        val = float(last["equity_value"])

        if val > buy_thr:
            signal = "BUY"
        elif val < sell_thr:
            signal = "SELL"
        else:
            signal = "HOLD"

        out = pd.DataFrame(
            {
                "date": [last["date"].normalize()],   # ë‚ ì§œë§Œ ë³´ê¸° ì¢‹ê²Œ
                "equity_value": [round(val, 2)],
                "signal": [signal],
            }
        )
        return out

    def check_put_call_ratio_warning(self):
        """
        í’‹ì½œ ë ˆì´í‹°ì˜¤ ë°ì´í„°ë¥¼ ë°›ì•„ì™€ì„œì„œ
        ë§¤ìˆ˜ í˜¹ì€ ë§¤ë„ ì‹œì ì„ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜

        ratio_type : equity, index ë‘˜ ì¤‘ í•˜ë‚˜ ì…ë ¥
        """

        put_call_ratio = pd.read_csv('put_call_ratio.csv')
        putcall_data_today = put_call_ratio.iloc[-1]
        print("data : ", putcall_data_today)
        date = putcall_data_today['date']
        value = putcall_data_today['equity_value']

        # ê°„ë‹¨í•œ ì‹œê·¸ë„ íŒë‹¨

        result = [f"ğŸ“… ê¸°ì¤€ì¼: {date}",
                f"ğŸ“Š Equity_putcall_ratio ì§€ìˆ˜ : {value:.2f}"]
    
        if value > 1.5:
            result.append("ğŸ“‰ Equity: ê³µí¬ì‹¬ ê³¼ë‹¤ â†’ ë°˜ë“± ê°€ëŠ¥ì„± (ë§¤ìˆ˜ ì‹œì  íƒìƒ‰)")
        elif value < 0.4:
            result.append("ğŸš¨ Equity: ê³¼ì—´ íƒìš• ìƒíƒœ â†’ ë§¤ë„ ê²½ê³  ë˜ëŠ” ì¡°ì • ê°€ëŠ¥ì„±")
        else:
            result.append("âš–ï¸ Equity: ì¤‘ë¦½ êµ¬ê°„")

        return "\n".join(result)

    def get_nfci(self):
        '''
        FEDê°€ ë°œí‘œí•˜ëŠ” ì§€í‘œë¥¼ ê³µì‹ì ìœ¼ë¡œ FREDì— ì œê³µí•˜ëŠ” í˜•íƒœ
        ìƒìŠ¹ì‹œ ê²½ê¸°íšŒë³µ/í™•ì¥ ì˜ë¯¸, í•˜ë½ì‹œ ê²½ê¸° ë‘”í™”/ì¹¨ì²´ ì˜ë¯¸
        '''
        
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'NFCI',
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '2000-01-01'
        }
        response = requests.get(url, params=params)
        data = response.json()
        df = pd.DataFrame(data['observations'])
        df['date'] = pd.to_datetime(df['date'])
        df['NFCI_index'] = pd.to_numeric(df['value'], errors='coerce')
        
        return df

    def analyze_nfci(self):
        '''
        nfci < -0.5 ê¸ˆìœµì—¬ê±´ ì™„í™”
        nfci > 0.5 ê¸ˆìœµê¸´ì¶•
        '''
        df = self.get_nfci()

        date = df['date'].iloc[-1]
        nfci_value = df['NFCI_index'].iloc[-1] 

        result = []

        if nfci_value < -0.5:
            result.append("âœ… ìœ ë™ì„± í’ë¶€ êµ¬ê°„ìœ¼ë¡œ ê¾¸ì¤€í•œ ìƒìŠ¹ ê²½í–¥")
        elif nfci_value > 0.5:
            result.append("ğŸš¨ ê·¹ë‹¨ì  ê¸´ì¶• êµ¬ê°„, ì†ì‹¤ ë° ë†’ì€ ë³€ë™ì„±")
        else:
            result.append("âš–ï¸ ì¤‘ë¦½ êµ¬ê°„")

        return {
            "date" : date,
            "value" : nfci_value,
            "comment" : result
        }


    def get_dollar_index(self):   #period="26y"
        '''
        FRED API : ë‹¬ëŸ¬ ì¸ë±ìŠ¤
        '''

        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id' : 'DTWEXBGS', # ë‹¬ëŸ¬ì¸ë±ìŠ¤
            'api_key' : self.fred_api_key,
            'file_type' : 'json',
            'observation_start' : '2000-01-01' # ì‹œì‘ì¼(ì›í•˜ëŠ” ë‚ ì§œì§œ)
        }

        try:
            response = requests.get(url, params= params, timeout=10)
            response.raise_for_status() # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
            data = response.json()

            if 'observations' not in data:
                raise ValueError(F"'observations' í‚¤ê°€ ì—†ìŒ : {data}")

            # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
            df = pd.DataFrame(data['observations'])
            df['date'] = pd.to_datetime(df['date'])
            df['value'] = pd.to_numeric(df['value'], errors= 'coerce')

            return df
        
        except Exception as e:
            print(f"[ERROR] FRED API í˜¸ì¶œ ì‹¤íŒ¨ : {e}")
            return pd.DataFrame()
      
        # """
        # ë‹¬ëŸ¬ ì¸ë±ìŠ¤ (DXY) ë°ì´í„°ë¥¼ yfinanceì—ì„œ ê°€ì ¸ì™€ì„œ DataFrameìœ¼ë¡œ ë°˜í™˜
        # period: '1d', '5d', '1mo', '3mo', '6mo', '1y', etc.
        # """
        # ticker = "DX-Y.NYB"  # yfinance ìƒ DXY ì‹¬ë³¼ (ICE ì„ ë¬¼ì‹œì¥ìš©)
        # df = yf.download(ticker, start='2020-01-01', interval="1d", progress=False)
        # df = df.reset_index()

        # # ì»¬ëŸ¼ ì •ë¦¬ : ì»¬ëŸ¼ ì´ë¦„ì„ í‘œì¤€í™”
        # df = df[['Date', 'Close']].rename(columns={'Date': 'date', 'Close': 'dxy'})
        # df['date'] = pd.to_datetime(df['date'])
        # return df
    
    # Clear - ì‹¤ì‹œê°„ ë°ì´í„°
    def get_euro_index(self):
        '''
        FRED API : ìœ ë¡œ ì¸ë±ìŠ¤
        '''

        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id' : 'DEXUSEU', # 10ë…„ë¬¼ êµ­ì±„ ê¸ˆë¦¬
            'api_key' : self.fred_api_key,
            'file_type' : 'json',
            'observation_start' : '2000-01-01' # ì‹œì‘ì¼(ì›í•˜ëŠ” ë‚ ì§œì§œ)
        }

        try:
            response = requests.get(url, params= params, timeout=10)
            response.raise_for_status() # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
            data = response.json()

            if 'observations' not in data:
                raise ValueError(F"'observations' í‚¤ê°€ ì—†ìŒ : {data}")

            # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
            df = pd.DataFrame(data['observations'])
            df['date'] = pd.to_datetime(df['date'])
            df['value'] = pd.to_numeric(df['value'], errors= 'coerce')

            return df
        
        except Exception as e:
            print(f"[ERROR] FRED API í˜¸ì¶œ ì‹¤íŒ¨ : {e}")
            return pd.DataFrame()
        
    # Clear - ì‹¤ì‹œê°„ ë°ì´í„°
    def get_yen_index(self):
        '''
        FRED API : ì—”í™” ì¸ë±ìŠ¤
        '''

        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id' : 'DEXJPUS', # 10ë…„ë¬¼ êµ­ì±„ ê¸ˆë¦¬
            'api_key' : self.fred_api_key,
            'file_type' : 'json',
            'observation_start' : '2000-01-01' # ì‹œì‘ì¼(ì›í•˜ëŠ” ë‚ ì§œì§œ)
        }

        try:
            response = requests.get(url, params= params, timeout=10)
            response.raise_for_status() # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
            data = response.json()

            if 'observations' not in data:
                raise ValueError(F"'observations' í‚¤ê°€ ì—†ìŒ : {data}")

            # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
            df = pd.DataFrame(data['observations'])
            df['date'] = pd.to_datetime(df['date'])
            df['value'] = pd.to_numeric(df['value'], errors= 'coerce')

            return df
        
        except Exception as e:
            print(f"[ERROR] FRED API í˜¸ì¶œ ì‹¤íŒ¨ : {e}")
            return pd.DataFrame()
    

    # Clear - ì›”ë³„ ë°ì´í„° - 1ì›” ë”œë ˆì´
    def get_copper_price_F(self):
        # HG=F: High Grade Copper Futures (êµ¬ë¦¬ ì„ ë¬¼)
        df = yf.download("HG=F", start="2000-01-01", interval="1d", group_by="ticker")

        # 1) MultiIndex â†’ ë‹¨ì¼ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        if isinstance(df.columns, pd.MultiIndex):
            df.columns = df.columns.droplevel(0)  # 'CL=F' ë ˆë²¨ ì œê±° â†’ Price, Close, High...
            # ë˜ëŠ” df.columns = df.columns.droplevel(0) í•˜ë©´ 'Close', 'High' ë“±ë§Œ ë‚¨ê¹€
            # ì›í•˜ëŠ” ë ˆë²¨ ì„ íƒ

        # 2) ì¸ë±ìŠ¤(Date)ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ
        df = df.reset_index()
        
        return df



        # '''
        # FRED API : êµ¬ë¦¬ ì¸ë±ìŠ¤
        # '''

        # url = 'https://api.stlouisfed.org/fred/series/observations'
        # params = {
        #     'series_id' : 'PCOPPUSDM', # 10ë…„ë¬¼ êµ­ì±„ ê¸ˆë¦¬
        #     'api_key' : self.fred_api_key,
        #     'file_type' : 'json',
        #     'observation_start' : '2000-01-01' # ì‹œì‘ì¼(ì›í•˜ëŠ” ë‚ ì§œì§œ)
        # }

        # try:
        #     response = requests.get(url, params= params, timeout=10)
        #     response.raise_for_status() # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
        #     data = response.json()

        #     if 'observations' not in data:
        #         raise ValueError(F"'observations' í‚¤ê°€ ì—†ìŒ : {data}")

        #     # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
        #     df = pd.DataFrame(data['observations'])
        #     df['date'] = pd.to_datetime(df['date'])
        #     df['value'] = pd.to_numeric(df['value'], errors= 'coerce')

        #     return df
        
        # except Exception as e:
        #     print(f"[ERROR] FRED API í˜¸ì¶œ ì‹¤íŒ¨ : {e}")
        #     return pd.DataFrame()
    

    def get_gold_price_F(self):
        '''
        FRED API : ê¸ˆ ì¸ë±ìŠ¤
        '''

        df = yf.download("GC=F", start="2000-01-01", interval="1d", group_by="ticker")

        # 1) MultiIndex â†’ ë‹¨ì¼ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        if isinstance(df.columns, pd.MultiIndex):
            df.columns = df.columns.droplevel(0)  # 'CL=F' ë ˆë²¨ ì œê±° â†’ Price, Close, High...
            # ë˜ëŠ” df.columns = df.columns.droplevel(0) í•˜ë©´ 'Close', 'High' ë“±ë§Œ ë‚¨ê¹€
            # ì›í•˜ëŠ” ë ˆë²¨ ì„ íƒ

        # 2) ì¸ë±ìŠ¤(Date)ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ
        df = df.reset_index()
        
        return df


        # url = 'https://api.stlouisfed.org/fred/series/observations'
        # params = {
        #     'series_id' : 'IR14270', # ë‰´ìš• ê¸°ì¤€ ê¸ˆê°€ê²©
        #     'api_key' : self.fred_api_key,
        #     'file_type' : 'json',
        #     'observation_start' : '2000-01-01' # ì‹œì‘ì¼(ì›í•˜ëŠ” ë‚ ì§œì§œ)
        # }

        # try:
        #     response = requests.get(url, params= params, timeout=10)
        #     response.raise_for_status() # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
        #     data = response.json()

        #     if 'observations' not in data:
        #         raise ValueError(F"'observations' í‚¤ê°€ ì—†ìŒ : {data}")

        #     # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
        #     df = pd.DataFrame(data['observations'])
        #     df['date'] = pd.to_datetime(df['date'])
        #     df['value'] = pd.to_numeric(df['value'], errors= 'coerce')

        #     return df
        
        # except Exception as e:
        #     print(f"[ERROR] FRED API í˜¸ì¶œ ì‹¤íŒ¨ : {e}")
        #     return pd.DataFrame()


    def get_oil_price_F(self):
        '''
        FRED API : ë¯¸êµ­ ì„œë¶€í…ì‚¬ìŠ¤ì‚° ì›ìœ  ì„ ë¬¼
        '''

        df = yf.download("CL=F", start="2000-01-01", interval="1d", group_by="ticker")

        # 1) MultiIndex â†’ ë‹¨ì¼ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        if isinstance(df.columns, pd.MultiIndex):
            df.columns = df.columns.droplevel(0)  # 'CL=F' ë ˆë²¨ ì œê±° â†’ Price, Close, High...
            # ë˜ëŠ” df.columns = df.columns.droplevel(0) í•˜ë©´ 'Close', 'High' ë“±ë§Œ ë‚¨ê¹€
            # ì›í•˜ëŠ” ë ˆë²¨ ì„ íƒ

        # 2) ì¸ë±ìŠ¤(Date)ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ
        df = df.reset_index()
        
        return df

    def get_high_yield_spread(self):
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'BAMLH0A0HYM2',  # í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œ
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '2000-01-01'
        }
        response = requests.get(url, params=params)
        data = response.json()
        df = pd.DataFrame(data['observations'])
        df['date'] = pd.to_datetime(df['date'])
        df['value'] = pd.to_numeric(df['value'], errors='coerce')
        return df
    

    def check_high_yield_spread_warning(self):
        """
        í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œ ë°ì´í„°í”„ë ˆì„ì„ ë°›ì•„
        ìµœì‹ ê°’ê³¼ ì „ì¼ ëŒ€ë¹„ ë³€í™”ìœ¨ì„ ì²´í¬í•´ ê²½ê³ ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
        """
        df = self.get_high_yield_spread()
        df = df.dropna(subset=['value'])  # NaN ì œê±°
        df = df.sort_values('date')       # ë‚ ì§œìˆœ ì •ë ¬
        
        today_row = df.iloc[-1]
        date = today_row["date"]
        yesterday_row = df.iloc[-2]
        
        today_value = today_row['value']
        yesterday_value = yesterday_row['value']
        
        change = today_value - yesterday_value  # ë³€í™”ëŸ‰ (í¬ì¸íŠ¸)

        messages = []
        messages.append(f"ğŸ” í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œ ì˜¤ëŠ˜({today_row['date'].date()}) ê°’: {today_value:.2f}%")
        messages.append(f"ğŸ” ì–´ì œ({yesterday_row['date'].date()}) ëŒ€ë¹„ ë³€í™”: {change:+.2f}p")
        
        if today_value >= 7:
            messages.append("ğŸš¨ í•˜ë½ì¥ ê²½ê³ : í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œê°€ 7%ë¥¼ ë„˜ì—ˆìŠµë‹ˆë‹¤!")
        elif today_value >= 5:
            messages.append("âš ï¸ ì¡°ì •ì¥ ê²½ê³ : í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œê°€ 5%ë¥¼ ë„˜ì—ˆìŠµë‹ˆë‹¤!")
        
        if change >= 0.5:
            messages.append("âš¡ ê¸‰ë“± ê²½ê³ : í•˜ë£¨ ë§Œì— ìŠ¤í”„ë ˆë“œê°€ 0.5%p ì´ìƒ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤!")
        
        if (today_value < yesterday_value) and (today_value >= 5):
            messages.append("ğŸ“ˆ ì €ì  ë§¤ìˆ˜ ê°€ëŠ¥ì„± ì‹ í˜¸: ìŠ¤í”„ë ˆë“œê°€ êº¾ì´ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤!")

        return {
            "date" : date,
            'value' : today_value,
            'message' : messages
        }


    def get_ma_above_ratio(self):

        url = "https://www.barchart.com/stocks/momentum"
    
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        
        try:
            response = requests.get(url, headers=headers)
            response.raise_for_status() # HTTP ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì˜ˆì™¸ ë°œìƒ

            soup = BeautifulSoup(response.text, 'html.parser')

            ma_50_day = None
            ma_200_day = None

            # 'Market Average'ë¼ëŠ” í…ìŠ¤íŠ¸ë¥¼ ê°€ì§„ <h5> íƒœê·¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            h5_market_average = soup.find('h5', string='Market Average')
            
            market_average_table = None
            if h5_market_average:
                # <h5> íƒœê·¸ì˜ ë¶€ëª¨ (class="block-title"ì¸ div)ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
                block_title_div = h5_market_average.find_parent('div', class_='block-title')
                
                if block_title_div:
                    # 'block-title' divì˜ ë°”ë¡œ ë‹¤ìŒ í˜•ì œ ìš”ì†Œ ì¤‘ì—ì„œ 'table-wrapper' í´ë˜ìŠ¤ë¥¼ ê°€ì§„ divë¥¼ ì°¾ìŠµë‹ˆë‹¤.
                    table_wrapper = block_title_div.find_next_sibling('div', class_='table-wrapper')
                    
                    if table_wrapper:
                        # 'table-wrapper' ì•ˆì—ì„œ 'table' íƒœê·¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
                        market_average_table = table_wrapper.find('table')
                    else:
                        print("ERROR: 'table-wrapper' divë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    print("ERROR: 'Market Average' <h5> íƒœê·¸ì˜ ë¶€ëª¨ 'block-title' divë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print("ERROR: 'Market Average' <h5> íƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


            if market_average_table:
                # í…Œì´ë¸” í—¤ë” ì¶”ì¶œ (ì²« ë²ˆì§¸ í–‰ì˜ th íƒœê·¸ë“¤)
                header_row = market_average_table.find('tr') # í…Œì´ë¸”ì˜ ì²« ë²ˆì§¸ tr
                if header_row:
                    headers = [th.get_text(strip=True) for th in header_row.find_all('th')]
                    # print(f"ì¶”ì¶œëœ í—¤ë”: {headers}") # ë””ë²„ê¹…ìš©

                    # í…Œì´ë¸”ì˜ ëª¨ë“  í–‰(<tr>)ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. tbodyê°€ ìˆë“  ì—†ë“  ë™ì‘í•˜ë„ë¡ í•©ë‹ˆë‹¤.
                    rows_in_table = market_average_table.find_all('tr')
                    
                    today_row = None
                    # ê°€ì ¸ì˜¨ í–‰ë“¤ì„ ìˆœíšŒí•˜ë©° 'Today' í–‰ì„ ì°¾ìŠµë‹ˆë‹¤.
                    for row in rows_in_table:
                        # ì²« ë²ˆì§¸ tdê°€ 'Today'ì¸ ê²½ìš°ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
                        first_cell = row.find('td', class_='text-left') 
                        if first_cell and first_cell.get_text(strip=True) == 'Today':
                            today_row = row
                            break
                    
                    if today_row:
                        # 'Today' í–‰ì˜ ëª¨ë“  ë°ì´í„° ì…€(td íƒœê·¸ë“¤) ì¶”ì¶œ
                        # ì²« ë²ˆì§¸ td(Today)ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ td ê°’ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
                        data_cells = [td.get_text(strip=True) for td in today_row.find_all('td')[1:]] # [1:]ë¡œ 'Today' ì…€ ì œì™¸
                        # print(f"Today í–‰ì˜ ë°ì´í„°: {data_cells}") # ë””ë²„ê¹…ìš©

                        # í—¤ë” ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ 50-Day MAì™€ 200-Day MA ê°’ ì¶”ì¶œ
                        try:
                            index_50_day_ma_header = headers.index("50-Day MA")
                            ma_50_day = data_cells[index_50_day_ma_header -1] 

                        except ValueError:
                            print("í—¤ë”ì—ì„œ '50-Day MA'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        except IndexError:
                            print("50-Day MAì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¸ë±ìŠ¤ ì˜¤ë¥˜.")

                        try:
                            index_200_day_ma_header = headers.index("200-Day MA")
                            ma_200_day = data_cells[index_200_day_ma_header -1]
                        except ValueError:
                            print("í—¤ë”ì—ì„œ '200-Day MA'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        except IndexError:
                            print("200-Day MAì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¸ë±ìŠ¤ ì˜¤ë¥˜.")

                    else:
                        print("MARKET AVERAGE í…Œì´ë¸”ì—ì„œ 'Today' í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    print("MARKET AVERAGE í…Œì´ë¸”ì—ì„œ í—¤ë” í–‰(<tr>)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print("MARKET AVERAGE í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            return {
                "date": datetime.today().strftime("%Y-%m-%d"),
                "50-day MA": ma_50_day,
                "200-day MA": ma_200_day
            }

        except requests.exceptions.RequestException as e:
            print(f"ì›¹ í˜ì´ì§€ì— ì ‘ì†í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None, None
        except Exception as e:
            print(f"ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None, None


    def interpret_ma_above_ratio(self):
        """
        ì´í‰ì„  ìƒíšŒ ë¹„ìœ¨ í•´ì„:
        - 30% ë¯¸ë§Œ: ë§¤ìˆ˜ ì¶”ì²œ
        - 70% ì´ìƒ: ë§¤ë„ ì¶”ì²œ
        - ë‹¨ê¸°ì : 50ì¼ / ì¥ê¸°ì : 200ì¼

        Parameters:
            result (dict): {'date': 'YYYY-MM-DD', '50-day MA': '62.72%', '200-day MA': '52.33%'}

        Returns:
            list: ì¶”ì²œ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ (í˜„ì¬ ìˆ˜ì¹˜ í¬í•¨)
        """

        data = self.get_ma_above_ratio()

        date = data['date']


        # 50-day MA í•´ì„
        ma_50 = float(data.get("50-day MA", "0%").replace("%", ""))
        if ma_50 < 30:
            signal_50 = "BUY"
            icon_50 = "âœ…"
            commnet_50 = f"âœ… ë‹¨ê¸°ì  ë§¤ìˆ˜ ì¶”ì²œ: 50ì¼ ì´í‰ì„  ìƒíšŒ ë¹„ìœ¨ì´ {ma_50:.2f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤."
        elif ma_50 >= 70:
            signal_50 = "SELL"
            icon_50 = "ğŸš¨"
            comment_50 = f"ğŸš¨ ë‹¨ê¸°ì  ë§¤ë„ ì‹ í˜¸: 50ì¼ ì´í‰ì„  ìƒíšŒ ë¹„ìœ¨ì´ {ma_50:.2f}%ë¡œ ê³¼ì—´ êµ¬ê°„ì…ë‹ˆë‹¤."
        else:
            signal_50 = "HOLD"
            icon_50 = "âš–ï¸"
            comment_50 = f"âš–ï¸ í˜„ì¬ëŠ” ëšœë ·í•œ ë§¤ìˆ˜/ë§¤ë„ ì‹ í˜¸ê°€ ì—†ìŠµë‹ˆë‹¤. (50ì¼: {ma_50:.2f}%"

        # 200-day MA í•´ì„
        ma_200 = float(data.get("200-day MA", "0%").replace("%", ""))
        if ma_200 < 30:
            signal_200 = "BUY"
            icon_200 = "âœ…"
            comment_200 = f"âœ… ì¥ê¸°ì  ë§¤ìˆ˜ ì¶”ì²œ: 200ì¼ ì´í‰ì„  ìƒíšŒ ë¹„ìœ¨ì´ {ma_200:.2f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤."
        elif ma_200 >= 70:
            signal_200 = "SELL"
            icon_200 = "ğŸš¨"
            comment_200 = f"ğŸš¨ ì¥ê¸°ì  ë§¤ë„ ì‹ í˜¸: 200ì¼ ì´í‰ì„  ìƒíšŒ ë¹„ìœ¨ì´ {ma_200:.2f}%ë¡œ ê³¼ì—´ êµ¬ê°„ì…ë‹ˆë‹¤."
        else:
            signal_200 = "HOLD"
            icon_200 = "âš–ï¸"
            comment_200 = f"âš–ï¸ í˜„ì¬ëŠ” ëšœë ·í•œ ë§¤ìˆ˜/ë§¤ë„ ì‹ í˜¸ê°€ ì—†ìŠµë‹ˆë‹¤. 200ì¼: {ma_200:.2f}%)"

        # ë”•ì…”ë„ˆë¦¬ë¥¼ í™œìš©í•˜ì—¬ ë‹¨ì¼ í–‰ì˜ DataFrame ìƒì„±
        ma_result = pd.DataFrame([{
            'date': date,
            'signal_50': signal_50,
            '50_ma': ma_50,
            'comment_50': comment_50,
            'signal_200': signal_200,
            '200_ma': ma_200,
            'comment_200': comment_200
        }])

        return ma_result
    

    def analyze_disparity_with_ma(self):
        """
        50ì¼, 200ì¼ ì´ë™í‰ê·  ê¸°ì¤€ ì´ê²©ë„ ê³„ì‚° ë° í•´ì„

        Returns:
            dict : {
                'date': latest_date,
                'sp500_close': latest_price,
                '50-day MA': latest_ma_50,
                '200-day MA': latest_ma_200,
                '50-day disparity (%)': value,
                '200-day disparity (%)': value,
                'short_term_status': í•´ì„ í…ìŠ¤íŠ¸,
                'long_term_status': í•´ì„ í…ìŠ¤íŠ¸
            }
        """
        df = self.get_sp500()
        df = df.copy()
        df['MA_50'] = df['sp500_close'].rolling(window=50).mean()
        df['MA_200'] = df['sp500_close'].rolling(window=200).mean()
        df.dropna(inplace=True)

        latest = df.iloc[-1]
        date = latest['date']
        close = latest['sp500_close']
        ma_50 = latest['MA_50']
        ma_200 = latest['MA_200']

        disparity_50 = ((close - ma_50) / ma_50) * 100
        disparity_200 = ((close - ma_200) / ma_200) * 100

        def interpret_disparity_50(val):
            if val <= -5:
                return "ğŸ“‰ ë‹¨ê¸° ì¹¨ì²´ êµ¬ê°„"
            elif val <= 5:
                return "âš–ï¸ ì¤‘ë¦½ êµ¬ê°„"
            elif val <= 10:
                return "âš ï¸ ë‹¨ê¸° ê³¼ì—´"
            else:
                return "ğŸš¨ ê·¹ë‹¨ì  ë‹¨ê¸° ê³¼ì—´"

        def interpret_disparity_200(val):
            if val <= -10:
                return "ğŸ“‰ ì¥ê¸° ì¹¨ì²´ êµ¬ê°„"
            elif val <= 0:
                return "âš–ï¸ ì¥ê¸° ì¤‘ë¦½(ì•½ì„¸)"
            elif val <= 10:
                return "âš–ï¸ ì¥ê¸° ì¤‘ë¦½(ê°•ì„¸)"
            elif val <= 20:
                return "âš ï¸ ì¥ê¸° ê³¼ì—´"
            else:
                return "ğŸ”¥ ê´‘ê¸° êµ¬ê°„"
        

        ma_disparity_result = pd.DataFrame([{
            'date': date,
            'sp500' : close,
            '50-day MA': round(ma_50, 2),
            '50-day disparity (%)': round(disparity_50, 2),
            'comment_50': interpret_disparity_50(disparity_50),
            '200-day MA': round(ma_200, 2),
            '200-day disparity (%)': round(disparity_200, 2),
            'comment_200': interpret_disparity_200(disparity_200)
        }])


        return ma_disparity_result


      # Clear ì£¼ë³„ ë°ì´í„° - 1ì£¼ì¼ ë”œë ˆì´
    def update_bull_bear_spread(self):
        '''
        ë¡œì»¬ì— ì €ì¥ëœ bull_bear_spread íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
        '''
        bb_spread = None  # âœ… ë³€ìˆ˜ ì´ˆê¸°í™”
        try:
            bb_spread = self.bull_bear_spread_updater.update_csv()
            print("âœ… Bull Bear Spread CSV ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        except Exception as e:
            print("ğŸ“› Bull Bear Spread ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:", e)
        return bb_spread


    def get_bull_bear_spread(self):

        url = "https://ycharts.com/indicators/us_investor_sentiment_bull_bear_spread"

        options = Options()
        # options.add_argument("--headless")
        options.add_argument("--disable-gpu")
        options.add_argument("--no-sandbox")

        driver = webdriver.Chrome(options=options)
        driver.get(url)
        time.sleep(5)  # JS ë¡œë”© ëŒ€ê¸°

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        driver.quit()

        # "Last Value" í…ìŠ¤íŠ¸ê°€ ìˆëŠ” td ì°¾ê¸°
        for td in soup.select("td.col-6"):
            if "Last Value" in td.get_text(strip=True):
                value_td = td.find_next_sibling("td")
                if value_td:
                    bull_bear_spread = value_td.get_text(strip=True)
                    break

        # âœ… Last Period (ë‚ ì§œ) ì¶”ì¶œ - tr ê¸°ë°˜ìœ¼ë¡œ ë”°ë¡œ íƒìƒ‰
        for row in soup.find_all("tr"):
            tds = row.find_all("td")
            if len(tds) == 2 and "Latest Period" in tds[0].get_text(strip=True):
                date = tds[1].get_text(strip=True)
                break

        if bull_bear_spread and date:
            return {
                "date": date,
                "spread": bull_bear_spread
            }
        else:
            raise ValueError("âŒ Last Value ë˜ëŠ” Last Periodë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
    def plot_snp_with_bull_bear_signals_from_crawler(
        self,
        buy_th: float = -0.2,
        sell_th: float = 0.4,
        nearest_tolerance_days: int = 3,
        align_direction: str = "nearest",  # "nearest" | "backward" | "forward"
        show: bool = True,
        buy_color: str = "green",
        sell_color: str = "red",
        save_csv_path: str | None = None,
    ):
        """
        MacroCrawler.update_bull_bear_spread() + MacroCrawler.get_sp500() ì‚¬ìš©.
        - Bull-Bear spread < buy_th  â†’ Buy ì‹ í˜¸
        - Bull-Bear spread > sell_th â†’ Sell ì‹ í˜¸
        - ì‹ í˜¸ ë‚ ì§œë¥¼ S&P500 ìµœê·¼ì ‘ ê±°ë˜ì¼ë¡œ ì •ë ¬(merge_asof)
        - ë°˜í™˜: ì‹ í˜¸ë³„ ì´ë²¤íŠ¸ DataFrame
        """
        # 1) ë°ì´í„° ë¡œë“œ
        bb = pd.read_csv('bull_bear_spread.csv')  # í•„ìš”: ['date','spread']
        snp = self.get_sp500()                # í•„ìš”: ['date','sp500_close']

        # 2) ì „ì²˜ë¦¬
        for df in (bb, snp):
            if "date" not in df.columns:
                raise ValueError("ì…ë ¥ ë°ì´í„°ì— 'date' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            df["date"] = pd.to_datetime(df["date"])
            df.sort_values("date", inplace=True)
            df.drop_duplicates(subset=["date"], keep="last", inplace=True)

        if "spread" not in bb.columns:
            cand = [c for c in bb.columns if "spread" in c.lower()]
            if not cand:
                raise ValueError("Bull-Bear ë°ì´í„°ì— 'spread' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            bb = bb.rename(columns={cand[0]: "spread"})

        if "sp500_close" not in snp.columns:
            raise ValueError("S&P500 ë°ì´í„°ì— 'sp500_close' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        # 3) ì‹ í˜¸ ìƒì„±
        buy_df  = bb[bb["spread"] < buy_th].copy()
        sell_df = bb[bb["spread"] > sell_th].copy()

        # 4) ìµœê·¼ì ‘ ê±°ë˜ì¼ ë§¤ì¹­
        snp_slim = snp[["date", "sp500_close"]].rename(columns={"sp500_close": "snp"})
        buy_aligned = pd.merge_asof(
            buy_df.sort_values("date"),
            snp_slim.sort_values("date"),
            on="date",
            direction=align_direction,
            tolerance=pd.Timedelta(days=nearest_tolerance_days),
        ).dropna(subset=["snp"])
        buy_aligned["signal"] = "buy"

        sell_aligned = pd.merge_asof(
            sell_df.sort_values("date"),
            snp_slim.sort_values("date"),
            on="date",
            direction=align_direction,
            tolerance=pd.Timedelta(days=nearest_tolerance_days),
        ).dropna(subset=["snp"])
        sell_aligned["signal"] = "sell"

        # 5) ì´ë²¤íŠ¸ DataFrameìœ¼ë¡œ ê²°í•© & ì •ë ¬
        events_df = pd.concat([buy_aligned, sell_aligned], ignore_index=True)
        events_df["threshold_buy"] = buy_th
        events_df["threshold_sell"] = sell_th
        events_df = events_df[["date", "signal", "snp", "spread", "threshold_buy", "threshold_sell"]]
        events_df.sort_values("date", inplace=True)

        # (ì„ íƒ) CSV ì €ì¥
        # if save_csv_path:
        #     events_df.to_csv(save_csv_path, index=False)

        # 6) ì‹œê°í™”
        fig, ax = plt.subplots(figsize=(14, 7))
        ax.plot(snp["date"], snp["sp500_close"], label="S&P500")

        # ìƒ‰ìƒ: ë§¤ìˆ˜=ì´ˆë¡, ë§¤ë„=ë¹¨ê°•
        if not events_df.empty:
            buys  = events_df[events_df["signal"] == "buy"]
            sells = events_df[events_df["signal"] == "sell"]
            if not buys.empty:
                ax.scatter(buys["date"], buys["snp"], marker="^", s=90,
                        color=buy_color, edgecolor="k", linewidths=0.5,
                        label=f"Buy (spread < {buy_th})", zorder=5)
            if not sells.empty:
                ax.scatter(sells["date"], sells["snp"], marker="v", s=90,
                        color=sell_color, edgecolor="k", linewidths=0.5,
                        label=f"Sell (spread > {sell_th})", zorder=5)

        ax.set_title("S&P500 with Bullâ€“Bear Spread Signals")
        ax.set_xlabel("Date"); ax.set_ylabel("S&P500 Close")
        ax.grid(True, alpha=0.3); ax.legend()

        if show:
            plt.show()

        # âœ… dict ëŒ€ì‹  DataFrame ë°˜í™˜
        return fig, ax, events_df


    def generate_bull_bear_signals(self):
        """
        Bull-Bear Spread ê¸°ì¤€ íˆ¬ì ì „ëµ

        ë§¤ìˆ˜: spread < -0.2
        ë§¤ë„: spread > 0.4
        """

        buy_th = float(-0.2)
        sell_th = float(0.4)

        df = pd.read_csv("bull_bear_spread.csv")
    
        if df is None or df.empty:
            raise ValueError("bull_bear_spread.csvê°€ ë¹„ì–´ ìˆê±°ë‚˜ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        if "date" not in df.columns or "spread" not in df.columns:
            raise ValueError("bull_bear_spread.csvëŠ” 'date', 'spread' ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.")
        
        df = df.dropna(subset=["date", "spread"]).copy()
        df["date"] = pd.to_datetime(df["date"])
        df = df.sort_values("date").reset_index(drop=True)

        df_latest = df.iloc[-1]
        spread_val = float(df_latest["spread"])
        
        buy_signal  = spread_val < buy_th
        sell_signal = spread_val > sell_th

        if sell_signal:
            signal = "SELL"
            icon = "ğŸ”´"
            comment = "ğŸ”¥ ê´‘ê¸° êµ¬ê°„(íˆ¬ìì ê³¼ë„í•œ ë‚™ê´€) â†’ ì°¨ìµì‹¤í˜„/ë¦¬ìŠ¤í¬ ê´€ë¦¬ ê³ ë ¤"
        elif buy_signal:
            signal = "BUY"
            icon = "ğŸŸ¢"
            comment = "âœ… ì—­ë°œìƒ ë§¤ìˆ˜ êµ¬ê°„(íˆ¬ìì ê³µí¬ ì‹¬í™”) â†’ ë¶„í•  ë§¤ìˆ˜ ê³ ë ¤"
        else:
            signal = "HOLD"
            icon = "âšª"
            comment = "âš–ï¸ íŒë‹¨ ìœ ë³´(í˜¼ì¡°/ì¤‘ë¦½) â†’ ê´€ë§ ë˜ëŠ” ë³´ìœ  ìœ ì§€"

        return {
            "date": pd.to_datetime(df_latest["date"]).strftime("%Y-%m-%d"),
            "spread": spread_val,
            "buy_signal": bool(buy_signal),
            "sell_signal": bool(sell_signal),
            "signal": signal,
            "icon": icon,
            "comment": comment,
            "thresholds": {"buy_th": buy_th, "sell_th": sell_th},
        }
        # 40ì˜ ë²•ì¹™

if __name__ == "__main__":
    crawler = MacroCrawler()

    # md_data = crawler.update_margin_debt_data()
    # pmi_data = crawler.update_ism_pmi_data()
    # fp_data = crawler.update_snp_forwardpe_data()
    # pc_data = crawler.update_putcall_ratio()
    # bb_data = crawler.update_bull_bear_spread()
    # lei_data = crawler.update_lei_data()

    data = crawler.get_sp500()
    print(data)

