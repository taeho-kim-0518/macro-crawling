import os
import time
from dateutil.relativedelta import relativedelta
import pandas as pd
import numpy as np
from datetime import datetime
import requests
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns
import yfinance as yf
from bs4 import BeautifulSoup
from scipy.stats import linregress
from io import StringIO
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC


from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.core.os_manager import ChromeType

from md_updater import MarginDebtUpdater
from ism_pmi_updater import ISMPMIUpdater
from SNP_forward_pe_updater import forwardpe_updater
from putcall_ratio_updater import PutCallRatioUpdater
from bullbear_spread_updater import BullBearSpreadUpdater

# í•œê¸€ í°íŠ¸ ì„¤ì • (Windowsì—ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ 'Malgun Gothic' ê°€ëŠ¥)
mpl.rcParams['font.family'] = 'Malgun Gothic'  # ë˜ëŠ” 'NanumGothic', 'AppleGothic' (Mac)
mpl.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤(-) ê¹¨ì§ ë°©ì§€

# ğŸ”‘ í™˜ê²½ë³€ìˆ˜ ë¡œë”©ìš© (í•„ìš” ì‹œ pip install python-dotenv)
from dotenv import load_dotenv
load_dotenv()  # .env íŒŒì¼ ì½ì–´ì„œ os.environì— ìë™ìœ¼ë¡œ ë“±ë¡


class MacroCrawler:
    def __init__(self):
        self.fred_api_key = os.environ.get("FRED_API_KEY")
        self.eia_api_key = os.environ.get("EIA_API_KEY")
        
        if not self.fred_api_key:
            raise ValueError("FRED_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        if not self.eia_api_key:
            raise ValueError("EIA_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        print("âœ… FRED & EIA API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸° ì„±ê³µ")

        # ë§ˆì§„ ë¶€ì±„ ì—…ë°ì´íŠ¸ê¸° ì—°ê²°
        self.margin_updater = MarginDebtUpdater("md_df.csv")
        # ISM PMI ì—…ë°ì´íŠ¸ê¸° ì—°ê²°
        self.pmi_updater = ISMPMIUpdater("pmi_data.csv")
        # Forward PE ì—…ë°ì´íŠ¸ê¸° ì—°ê²°
        self.snp_forwardpe_updater = forwardpe_updater("forward_pe_data.csv")
        # PUT CALL Ratio ì—…ë°ì´íŠ¸ê¸° ì—°ê²°
        self.put_call_ratio_updater = PutCallRatioUpdater("put_call_ratio.csv")
        # Bull Bear Spread ì—…ë°ì´íŠ¸ê¸° ì—°ê²°
        self.bull_bear_spread_updater = BullBearSpreadUpdater("bull_bear_spread.csv")

    # Clear 1ê°œì›” ë”œë ˆì´ ë°ì´í„°
    def get_10years_treasury_yeild(self):
        '''
        FRED API : ë¯¸êµ­ 10ë…„ë¬¼ êµ­ì±„ ìˆ˜ìµë¥ 
        '''

        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id' : 'GS10', # 10ë…„ë¬¼ êµ­ì±„ ê¸ˆë¦¬
            'api_key' : self.fred_api_key,
            'file_type' : 'json',
            'observation_start' : '2000-01-01' # ì‹œì‘ì¼(ì›í•˜ëŠ” ë‚ ì§œì§œ)
        }

        try:
            response = requests.get(url, params= params, timeout=10)
            response.raise_for_status() # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
            data = response.json()

            if 'observations' not in data:
                raise ValueError(F"'observations' í‚¤ê°€ ì—†ìŒ : {data}")

            # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
            df = pd.DataFrame(data['observations'])
            df['date'] = pd.to_datetime(df['date'])
            df['value'] = pd.to_numeric(df['value'], errors= 'coerce')

            return df
        
        except Exception as e:
            print(f"[ERROR] FRED API í˜¸ì¶œ ì‹¤íŒ¨ : {e}")
            return pd.DataFrame()

    # Clear - 1ê°œì›” ë”œë ˆì´ ë°ì´í„°    
    def get_2years_treasury_yeild(self):
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id' : 'GS2', # 2ë…„ë¬¼ êµ­ì±„ ê¸ˆë¦¬
            'api_key' : self.fred_api_key,
            'file_type' : 'json',
            'observation_start' : '2000-01-01' # ì‹œì‘ì¼(ì›í•˜ëŠ” ë‚ ì§œì§œ)
        }

        try:
            response = requests.get(url, params= params, timeout=10)
            response.raise_for_status() # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
            data = response.json()

            if 'observations' not in data:
                raise ValueError(F"'observations' í‚¤ê°€ ì—†ìŒ : {data}") 

            # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
            df = pd.DataFrame(data['observations'])
            df['date'] = pd.to_datetime(df['date'])
            df['value'] = pd.to_numeric(df['value'], errors= 'coerce')

            return df
        
        except Exception as e:
            print(f"[ERROR] FRED API í˜¸ì¶œ ì‹¤íŒ¨ : {e}")
            return pd.DataFrame()

    # Clear - 1ê°œì›” ë”œë ˆì´ ë°ì´í„°     
    def get_cpi(self):
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'CPIAUCSL',  # CPI
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '1999-01-01'
        }
        
        try:
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
        except Exception as e:
            print("âŒ API ìš”ì²­ ë˜ëŠ” JSON íŒŒì‹± ì‹¤íŒ¨:", e)
            print("ğŸ“¦ ì‘ë‹µ ë‚´ìš©:", response.text)
            return pd.DataFrame()

        if 'observations' not in data:
            print("âŒ 'observations' í‚¤ ì—†ìŒ. ì‘ë‹µ ë‚´ìš©:", data)
            return pd.DataFrame()

        if not data['observations']:
            print("âŒ observations ë¦¬ìŠ¤íŠ¸ ë¹„ì–´ìˆìŒ:", data)
            return pd.DataFrame()

        df = pd.DataFrame(data['observations'])

        if 'date' not in df.columns:
            print("âŒ 'date' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ. df.columns:", df.columns)
            return pd.DataFrame()

        df['date'] = pd.to_datetime(df['date'])
        df['value'] = pd.to_numeric(df['value'], errors='coerce')
        return df
    
    def get_cpi_yoy(self):
        df = self.get_cpi() # ì›ë˜ CPIAUCSL ì§€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
        df = df.sort_values('date').dropna()

        df['CPI YOY(%)'] = df['value'].pct_change(periods=12)*100 # 12ê°œì›” ì „ ëŒ€ë¹„ ë³€í™”ìœ¨
        return df
    
    # Clear - 1ê°œì›” ë”œë ˆì´ ë°ì´í„°  
    def get_m2(self) : 
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'M2SL',  # M2 í†µí™”ëŸ‰
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '2000-01-01'
        }
        try:
            response = requests.get(url, params=params)
            data = response.json()
        except Exception as e:
            print("âŒ API ìš”ì²­ ë˜ëŠ” JSON íŒŒì‹± ì‹¤íŒ¨:", e)
            print("ğŸ“¦ ì‘ë‹µ ë‚´ìš©:", response.text)
            return pd.DataFrame()
        
        df = pd.DataFrame(data['observations'])
        df['date'] = pd.to_datetime(df['date'])
        df['value'] = pd.to_numeric(df['value'], errors='coerce')
        return df
    
  
    def get_m2_yoy(self):
        df = self.get_m2()
        df = df.sort_values('date')
        df['m2_yoy'] = df['value'].pct_change(periods=12) * 100
        return df[['date', 'm2_yoy']]

    # Clear 1ê°œì›” ë”œë ˆì´ ë°ì´í„°
    def update_margin_debt_data(self):
        '''
        ë¡œì»¬ì— ì €ì¥ëœ margin_debt íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
        '''
        try:
            md_df = self.margin_updater.update_csv()
            print("âœ… ë§ˆì§„ ë¶€ì±„ CSV ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        except Exception as e:
            print("ğŸ“› ë§ˆì§„ ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:", e)
        return md_df


    # def get_margin_debt_data(self):
    #     '''
    #     ë§ˆì§„ ë¶€ì±„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°(ê³ ì  íŒë‹¨)
    #     '''
    #     # 1ë…„ì¹˜ ë°ì´í„° í¬ë¡¤ë§
    #     url = "https://www.finra.org/rules-guidance/key-topics/margin-accounts/margin-statistics"

    #     try:
    #         response = requests.get(url, timeout=20)
    #         response.raise_for_status()
    #         soup = BeautifulSoup(response.text, "html.parser")

    #     except Exception as e:
    #         print("âŒ API ìš”ì²­ ë˜ëŠ” JSON íŒŒì‹± ì‹¤íŒ¨:", e)
    #         print("ğŸ“¦ ì‘ë‹µ ë‚´ìš©:", response.text)
    #         return pd.DataFrame()
        
    #     table = soup.select_one("table")  # ê°€ì¥ ì²« ë²ˆì§¸ í…Œì´ë¸” ì„ íƒ
    #     rows = table.find_all("tr")
        
    #     data = []
    #     headers = [th.get_text(strip=True) for th in rows[0].find_all("th")]

    #     for row in rows[1:]:
    #         cols = [td.get_text(strip=True).replace(",", "") for td in row.find_all("td")]
    #         if len(cols) == len(headers):
    #             data.append(cols)

    #     df = pd.DataFrame(data, columns=headers)
    #     df['Month/Year'] = pd.to_datetime(df['Month/Year'], format='%b-%y')
    #     # df = df.rename(columns={"Debit Balances in Customers' Securities Margin Accounts" : "margin_debt"})
    #     for col in df.columns[1:]:
    #         df[col] = pd.to_numeric(df[col], errors='coerce')
    #     return df
    
      # ì „ì²´ ë°ì´í„° ì—‘ì…€ë¡œ ë‹¤ìš´ë¡œë“œ í›„ ë¶ˆëŸ¬ì˜¤ê¸°
        # try:
        #     df = pd.read_excel('margin-statistics001.xlsx')

        #     # ì»¬ëŸ¼ëª… ì •ë¦¬
        #     df = df.rename(columns={
        #         'Year-Month': 'date',
        #         "Debit Balances in Customers' Securities Margin Accounts": 'margin_debt'
        #     })

        #     # ë‚ ì§œ íƒ€ì… ë³€í™˜
        #     df['date'] = pd.to_datetime(df['date'], format='%Y-%m')
        #     df['margin_debt'] = pd.to_numeric(df['margin_debt'].astype(str).str.replace(',', ''), errors='coerce')

        #     # 2000ë…„ ì´í›„ ë°ì´í„°ë§Œ í•„í„°ë§
        #     df = df[df['date'] >= '2000-01-01'].dropna(subset=['margin_debt'])

        #     # í•„ìš” ì»¬ëŸ¼ë§Œ ë°˜í™˜
        #     return df[['date', 'margin_debt']]

        # except Exception as e:
        #     print("âŒ Excel íŒŒì¼ ì½ê¸° ë˜ëŠ” ì²˜ë¦¬ ì˜¤ë¥˜:", e)
        #     return pd.DataFrame()

    
    # Clear  
    def get_margin_yoy_change(self):
        '''
        ë§ˆì§„ ë¶€ì±„ì˜ ì „ë…„ ëŒ€ë¹„ YOY (%) ë³€í™”ìœ¨ ê³„ì‚°
        '''
        df = self.update_margin_debt_data()
        if df.empty:
            return pd.DataFrame()

        df = df.sort_values("Month/Year")
        df["margin_debt"] = df["Debit Balances in Customers' Securities Margin Accounts"]
        df["margin_debt_clean"] = df["margin_debt"].astype(str).str.replace(',', '', regex=False)
        df["margin_debt"] = pd.to_numeric(df["margin_debt_clean"], errors="coerce").fillna(0).astype(int)
        df = df.drop(columns=["margin_debt_clean"])
        df["Margin YoY (%)"] = df["margin_debt"].pct_change(periods=12) * 100
        return df[["Month/Year", "margin_debt", "Margin YoY (%)"]]


    ## ìœ ë™ì„± ê´€ë ¨
    # Clear
    def generate_zscore_trend_signals(self):
        """
        Margin Debt / M2 ë¹„ìœ¨ì˜ z-score ë° ì¶”ì„¸ ì¡°ê±´ ê¸°ë°˜ ì „ëµ

        ë§¤ìˆ˜ ì¡°ê±´:
            - margin_debt / m2 ë¹„ìœ¨ì˜ z-score < -1.5
            - ë¹„ìœ¨ì´ ì „ì›” ëŒ€ë¹„ ìƒìŠ¹ (ë°˜ë“± ì‹œì‘)

        ë§¤ë„ ì¡°ê±´:
            - z-score > 1.5
            - ë¹„ìœ¨ì´ ì „ì›” ëŒ€ë¹„ -5% ì´ìƒ ê¸‰ë½

        ì‹¤ì œ ë§¤ë§¤ëŠ” ì‹ í˜¸ì¼ ê¸°ì¤€ +2ê°œì›” í›„ ì§„ì…
        ìˆ˜ìµë¥ ì€ ì§„ì…ì¼ë¶€í„° 3ê°œì›” í›„ê¹Œì§€ì˜ S&P500 ì¢…ê°€ ê¸°ì¤€

        Parameters:
            df : DataFrame with 'date', 'm2', 'margin_debt', 'sp500_close' columns

        Returns:
            DataFrame with signal type, signal date, action date, and 3-month return
        """
        df = self.merge_m2_margin_sp500_abs()
        df = df.sort_values("date").copy()
        df["ratio"] = df["margin_debt"] / df["m2"]
        df["ratio_z"] = (df["ratio"] - df["ratio"].rolling(window=36, min_periods=12).mean()) / \
                        df["ratio"].rolling(window=36, min_periods=12).std()
        df["ratio_change_pct"] = df["ratio"].pct_change() * 100

        # ì‹ í˜¸ ì •ì˜
        df["buy_signal"] = (df["ratio_z"] < -1.2) & (df["ratio_change_pct"] > 0)
        df["sell_signal"] = (df["ratio_z"] > 1.5) & (df["ratio_change_pct"] < -5)

        results = []
        for idx, row in df.iterrows():
            if row["buy_signal"] or row["sell_signal"]:
                signal = "BUY" if row["buy_signal"] else "SELL"
                signal_date = row["date"]
                action_date = signal_date + relativedelta(months=2)

                future_df = df[df["date"] >= action_date].reset_index(drop=True)
                if len(future_df) < 3:
                    continue

                entry_price = future_df.loc[0, "sp500_close"]
                exit_price = future_df.loc[2, "sp500_close"]
                return_pct = (exit_price - entry_price) / entry_price

                results.append({
                    "signal": signal,
                    "original_signal_date": signal_date,
                    "action_date": future_df.loc[0, "date"],
                    "return_3m": return_pct
                })

        return pd.DataFrame(results)
    
    # Clear
    def generate_mdyoy_signals(self):
        '''
        Margin Debt YoY ì „ëµ ê¸°ë°˜ ë§¤ìˆ˜/ë§¤ë„ ì‹ í˜¸ ìƒì„± í•¨ìˆ˜ (2ê°œì›” ë°œí‘œ ì§€ì—° ë°˜ì˜)
        df : ë³‘í•©ëœ ë°ì´í„°í”„ë ˆì„(merge_m2_margin_sp500_abs)
        '''

        df = self.merge_m2_margin_sp500_abs()
        df = df.copy()
        df["margin_yoy"] = df["margin_debt"].pct_change(periods=12) * 100

        # ì‹ í˜¸ ì¡°ê±´
        df["buy_signal"] = (df["margin_yoy"] > 0) & (df["margin_yoy"].shift(1) <= 0)
        df["sell_signal"] = (df["margin_yoy"] < -10) & (df["margin_yoy"].shift(1) >= -10)

        # ë°œí‘œ ì§€ì—° ê°ì•ˆí•œ ì§„ì… ì‹œì  ê³„ì‚°
        df["signal_date"] = df["date"]
        df["action_date"] = df["signal_date"] + pd.DateOffset(months=2)

        return df

    # Clear - ì‹¤ì‹œê°„ ë°ì´í„°
    def get_sp500(self):
        '''
        S&P500 ì§€ìˆ˜ ì¡°íšŒ
        '''
        ticker = '^GSPC'
        df = yf.download(ticker, start='2000-01-01', interval="1d", progress=False )
        # ì¸ë±ìŠ¤ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
        df = df.reset_index()

        # ë©€í‹°ì¸ë±ìŠ¤ ì»¬ëŸ¼ --> ë‹¨ì¼ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
        df.columns = [col[0] if isinstance(col,tuple) else col for col in df.columns]

        # ì»¬ëŸ¼ëª… ì •ë¦¬
        df = df.rename(columns={'Date': 'date', 'Close': 'sp500_close'})
        
        # ì›” ë‹¨ìœ„ë¡œ ë§ì¶°ì£¼ê¸° (Period â†’ Timestamp)
        df['date'] = pd.to_datetime(df['date']) #dt.to_period('M').dt.to_timestamp()

        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë°˜í™˜
        df = df[['date', 'sp500_close']]
        df.to_csv("sp500.csv", encoding='utf-8-sig')
        return df
    
    # Clear
    def merge_m2_margin_sp500_abs(self):
        '''
        M2, margin_debt, S&P500 ì§€ìˆ˜ ë°ì´í„°í”„ë ˆì„ ë³‘í•©
        '''
        df_m2 = self.get_m2().copy()
        df_m2['date'] = df_m2['date'].dt.to_period('M').dt.to_timestamp()
        df_m2 = df_m2.rename(columns={'value' : 'm2'})

        df_margin = self.get_margin_yoy_change().copy()
        df_margin['date'] = df_margin['Month/Year'].dt.to_period('M').dt.to_timestamp()
        #df_margin["margin_debt"] = df_margin["Debit Balances in Customers' Securities Margin Accounts"]
        #df_margin["margin_debt"] = df_margin["margin_debt"].str.replace(',','').astype(int)

        df_sp500 = self.get_sp500().copy()
        df_sp500['date'] = pd.to_datetime(df_sp500['date'])  # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ì•ˆì „í•˜ê²Œ
        df_sp500['month'] =  df_sp500['date'].dt.to_period('M').dt.to_timestamp()

        # ê° ì›”ì˜ ì²« ë²ˆì§¸ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” S&P500 ê°’ë§Œ ì¶”ì¶œ
        sp_monthly_first = df_sp500.sort_values('date').groupby('month').first().reset_index()

        # âœ… ê¸°ì¡´ 'date' ì»¬ëŸ¼ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        sp_monthly_first = sp_monthly_first.drop(columns=['date'])
        
        # âœ… ë‚ ì§œë¥¼ í•´ë‹¹ ì›”ì˜ 1ì¼ë¡œ ë°”ê¿”ì¤Œ
        sp_monthly_first = sp_monthly_first.rename(columns={'month': 'date'})
        sp_monthly_first = sp_monthly_first[["date", "sp500_close"]]

        df = pd.merge(df_m2, df_margin[['date', 'margin_debt']], on='date', how='inner')
        df = pd.merge(df, sp_monthly_first, on='date', how='inner')
        df["ratio"] = df["margin_debt"] / df["m2"]   # â† ì´ ì¤„ ì¶”ê°€
        return df
 
    # Clear
    def plot_sp500_with_signals_and_graph(self, save_to=None):
        """
        S&P500 ì¢…ê°€ì™€ margin_debt/m2 ë¹„ìœ¨ ë° ë§¤ìˆ˜/ë§¤ë„ ì‹ í˜¸ë¥¼ í•¨ê»˜ ì‹œê°í™”
        df : ë³‘í•©ëœ ë°ì´í„°í”„ë ˆì„(merge_m2_margin_sp500_abs)
        - ì¢Œì¸¡ yì¶•: S&P500
        - ìš°ì¸¡ yì¶•: margin_debt / m2 ë¹„ìœ¨
        - ë§¤ìˆ˜ ì‹œì : ì´ˆë¡ìƒ‰ â–²
        - ë§¤ë„ ì‹œì : ë¹¨ê°„ìƒ‰ â–¼
        """

        df = self.merge_m2_margin_sp500_abs()
        # ë¹„ìœ¨ ë° ì‹ í˜¸ ê³„ì‚°
        df = df.copy()
        df["ratio"] = df["margin_debt"] / df["m2"]
        df["ratio_z"] = (df["ratio"] - df["ratio"].rolling(window=36, min_periods=12).mean()) / \
                        df["ratio"].rolling(window=36, min_periods=12).std()
        df["ratio_change_pct"] = df["ratio"].pct_change() * 100

        # ì™„í™”ëœ ì¡°ê±´
        df["buy_signal"] = (df["ratio_z"] < -1.2) & (df["ratio_change_pct"] > 0)
        df["sell_signal"] = (df["ratio_z"] > 1.5) & (df["ratio_change_pct"] < -5)

        # ì‹œê°í™”
        fig, ax1 = plt.subplots(figsize=(14, 6))

        # S&P500 ì§€ìˆ˜ (ì¢Œì¸¡ yì¶•)
        ax1.plot(df["date"], df["sp500_close"], color="blue", label="S&P500 ì§€ìˆ˜", linewidth=2)
        ax1.scatter(
            df[df["buy_signal"]]["date"],
            df[df["buy_signal"]]["sp500_close"],
            color="green", marker="^", s=100, label="ë§¤ìˆ˜ ì‹ í˜¸"
        )
        ax1.scatter(
            df[df["sell_signal"]]["date"],
            df[df["sell_signal"]]["sp500_close"],
            color="red", marker="v", s=100, label="ë§¤ë„ ì‹ í˜¸"
        )
        ax1.set_ylabel("S&P500 ì¢…ê°€", color="blue")
        ax1.tick_params(axis='y', labelcolor="blue")

        # margin_debt / m2 ë¹„ìœ¨ (ìš°ì¸¡ yì¶•)
        ax2 = ax1.twinx()
        ax2.plot(df["date"], df["ratio"], color="gray", linestyle="--", label="Margin Debt / M2 ë¹„ìœ¨")
        ax2.set_ylabel("Margin Debt / M2 ë¹„ìœ¨", color="gray")
        ax2.tick_params(axis='y', labelcolor="gray")

        # ì œëª© ë° ë²”ë¡€
        fig.suptitle("S&P500 + ë§¤ìˆ˜/ë§¤ë„ ì‹ í˜¸ + Margin Debt / M2 ë¹„ìœ¨", fontsize=14)
        fig.legend(loc="upper left", bbox_to_anchor=(0.1, 0.9))
        fig.tight_layout()
        if save_to:
            fig.savefig(save_to, format='png')
            plt.close(fig)
        else:
            plt.show()
    

    # Clear
    def plot_sp500_with_mdyoy_signals_and_graph(self, save_to=None):
        '''
        S&P500, Margin Debt / M2, YoY ì „ëµ ê¸°ë°˜ ë§¤ìˆ˜/ë§¤ë„ ì‹œì  ì‹œê°í™”
        df : ë³‘í•©ëœ ë°ì´í„°í”„ë ˆì„(generate_mdyoy_signals)
        '''
        df = self.generate_mdyoy_signals()

        fig, ax1 = plt.subplots(figsize=(14, 6))

        # S&P500
        ax1.plot(df["date"], df["sp500_close"], label="S&P500", color="black")
        ax1.set_ylabel("S&P500 ì§€ìˆ˜", fontsize=12)
        ax1.set_xlabel("ë‚ ì§œ", fontsize=12)
        ax1.tick_params(axis='y')
        ax1.legend(loc="upper left")

        # ë§¤ìˆ˜/ë§¤ë„ ì‹œì 
        buy_dates = df[df["buy_signal"]]["action_date"]
        buy_prices = df[df["buy_signal"]]["sp500_close"]
        sell_dates = df[df["sell_signal"]]["action_date"]
        sell_prices = df[df["sell_signal"]]["sp500_close"]

        ax1.scatter(buy_dates, buy_prices, color='blue', label='ë§¤ìˆ˜ ì‹œì ', marker='^', s=100, zorder=5)
        ax1.scatter(sell_dates, sell_prices, color='red', label='ë§¤ë„ ì‹œì ', marker='v', s=100, zorder=5)

        # ì˜¤ë¥¸ìª½ yì¶•: Margin Debt / M2 ë¹„ìœ¨
        ax2 = ax1.twinx()
        ax2.plot(df["date"], df["ratio"], label="Margin Debt / M2", color="green", alpha=0.4)
        ax2.set_ylabel("Margin Debt / M2", fontsize=12)
        ax2.tick_params(axis='y')

        fig.suptitle("ğŸ“‰ Margin Debt YoY ì „ëµ: S&P500 ë° Margin Debt / M2 ë¹„ìœ¨", fontsize=14)
        fig.legend(loc="upper center", bbox_to_anchor=(0.5, -0.05), ncol=3)
        plt.tight_layout()
        if save_to:
            fig.savefig(save_to, format='png')
            plt.close(fig)
        else:
            plt.show()

    # Clear
    def check_today_md_signal(self):
        """
        ì˜¤ëŠ˜ì´ generate_zscore_trend_signals ë˜ëŠ” generate_mdyoy_signals ê¸°ì¤€
        ë§¤ìˆ˜/ë§¤ë„ ìœ íš¨ì›”(month)ì— ì†í•˜ëŠ”ì§€ í™•ì¸

        - todayê°€ action_dateì™€ ê°™ì€ ë‹¬(Month)ì´ë©´ ìœ íš¨
        - ê·¸ ë‹¬ ì „ì²´ë¥¼ ë§¤ë§¤ ìœ íš¨ ì‹œì ìœ¼ë¡œ ê°„ì£¼
        """

        today = pd.Timestamp.today().normalize()  
        # today = pd.Timestamp("2023-03-15").normalize()  # í…ŒìŠ¤íŠ¸ìš© ë‚ ì§œ ê°•ì œ ì„¤ì • 
        today_month = today.to_period("M")  # ì›” ë‹¨ìœ„ ë¹„êµìš©

        print(f"ğŸ“… ì˜¤ëŠ˜ ë‚ ì§œ (í™•ì¸ ê¸°ì¤€): {today.date()}")

        # ë°ì´í„° ë³‘í•©
        df = self.merge_m2_margin_sp500_abs()

        # --- ì „ëµ 1: z-score ê¸°ë°˜
        zscore_signal_df = self.generate_zscore_trend_signals()
        zscore_signal_df["action_month"] = zscore_signal_df["action_date"].dt.to_period("M")
        zscore_today = zscore_signal_df[zscore_signal_df["action_month"] == today_month]

        # --- ì „ëµ 2: margin YoY ê¸°ë°˜
        mdyoy_df = self.generate_mdyoy_signals()
        mdyoy_df["action_month"] = mdyoy_df["action_date"].dt.to_period("M")
        mdyoy_today = mdyoy_df[mdyoy_df["action_month"] == today_month]

        signal_found = False

        if not zscore_today.empty:
            print("\nğŸ“Œ [Z-Score ì „ëµ] ì´ë²ˆ ë‹¬ ë§¤ë§¤ ì‹ í˜¸ ìˆìŒ!")
            for _, row in zscore_today.iterrows():
                print(f"ğŸ‘‰ {row['action_date'].date()} : {row['signal']} ì‹ í˜¸ (ë°œìƒì¼: {row['original_signal_date'].date()})")
            signal_found = True

        mdyoy_filtered = mdyoy_today[mdyoy_today["buy_signal"] | mdyoy_today["sell_signal"]]
        if not mdyoy_filtered.empty:
            print("\nğŸ“Œ [Margin YoY ì „ëµ] ì´ë²ˆ ë‹¬ ë§¤ë§¤ ì‹ í˜¸ ìˆìŒ!")
            for _, row in mdyoy_filtered.iterrows():
                if row["buy_signal"]:
                    print(f"ğŸ‘‰ {row['action_date'].date()} : BUY ì‹ í˜¸ (ë°œìƒì¼: {row['signal_date'].date()})")
                elif row["sell_signal"]:
                    print(f"ğŸ‘‰ {row['action_date'].date()} : SELL ì‹ í˜¸ (ë°œìƒì¼: {row['signal_date'].date()})")
            signal_found = True

        if not signal_found:
            print("\nâœ… ì´ë²ˆ ë‹¬ì€ ë§¤ìˆ˜/ë§¤ë„ ì§„ì… ì‹œì ì´ ì•„ë‹™ë‹ˆë‹¤.")

    # Clear - ì›”ë³„ë°ì´í„° - 1ê°œì›” ì§€ì—°
    def get_fed_funds_rate(self):
        '''
        ë¯¸êµ­ ê¸°ì¤€ ê¸ˆë¦¬ ê³„ì‚°
        '''
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'FEDFUNDS',
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '2000-01-01'
        }
        response = requests.get(url, params=params)
        data = response.json()
        df = pd.DataFrame(data['observations'])
        df['date'] = pd.to_datetime(df['date'])
        df['fed_funds_rate'] = pd.to_numeric(df['value'], errors='coerce')
        return df

    # Clear    
    def generate_fed_rate_turning_points(self):
        """
        ê¸°ì¤€ê¸ˆë¦¬ ë³€í™”ì—ì„œ ì¸í•˜ ì‹œì‘ì  (rate_cut=True), ì¸ìƒ ì‹œì‘ì  (rate_hike=True)ë§Œ ì¡ëŠ” í•¨ìˆ˜
        """
        fed_rate_df = self.get_fed_funds_rate()
        df = fed_rate_df.copy()
        df["date"] = pd.to_datetime(df["date"])
        df = df.sort_values("date")

        df["prev_rate"] = df["fed_funds_rate"].shift(1)
        df["rate_diff"] = df["fed_funds_rate"] - df["prev_rate"]

        # ê¸°ì¤€ê¸ˆë¦¬ ë³€í™” ë°©í–¥
        df["trend"] = df["rate_diff"].apply(lambda x: "up" if x > 0 else ("down" if x < 0 else "flat"))
        df["prev_trend"] = df["trend"].shift(1)

        # ì „í™˜ì : flat â†’ ì œì™¸
        df["rate_cut"] = (df["prev_trend"] != "down") & (df["trend"] == "down")
        df["rate_hike"] = (df["prev_trend"] != "up") & (df["trend"] == "up")

        return df[["date", "fed_funds_rate", "rate_cut", "rate_hike"]]

    # Clear
    def get_rate_signal(self):
        '''
        ê¸ˆë¦¬ ê¸°ë°˜ ë³´ì¡° ì§€í‘œ ì‹œê·¸ë„ ê³„ì‚°

        Parameters:
            latest_10y (float): ìµœì‹  10ë…„ë¬¼ êµ­ì±„ ìˆ˜ìµë¥  (%)
            latest_2y (float): ìµœì‹  2ë…„ë¬¼ êµ­ì±„ ìˆ˜ìµë¥  (%)
            latest_fed_rate (float): ìµœì‹  ë¯¸êµ­ ê¸°ì¤€ê¸ˆë¦¬ (%)
            latest_cpi_yoy (float): ìµœì‹  CPI YoY (%)
            prev_cpi_yoy (float): ì§ì „ì›” CPI YoY (%)

        Returns:
            signal (int): -1 (ë§¤ë„), 0 (ì¤‘ë¦½), +1 ì´ìƒ (ë§¤ìˆ˜ ìš°í˜¸ì )
            comments (list): íŒë‹¨ ê·¼ê±° ì„¤ëª…
        '''
        signal = 0
        comments = []

        latest_10y = self.get_10years_treasury_yeild()['value'].iloc[-1]
        latest_2y = self.get_2years_treasury_yeild()['value'].iloc[-1]
        prev_10y = self.get_10years_treasury_yeild()['value'].iloc[-2]
        prev_2y = self.get_2years_treasury_yeild()['value'].iloc[-2]
        latest_cpi_yoy = self.get_cpi_yoy()['CPI YOY(%)'].iloc[-1]
        latest_fed_rate = self.get_fed_funds_rate()['fed_funds_rate'].iloc[-1]
        prev_cpi_yoy = self.get_cpi_yoy()['CPI YOY(%)'].iloc[-2]

        # ì‹¤ì§ˆê¸ˆë¦¬ ê³„ì‚°
        real_10y = latest_10y - latest_cpi_yoy
        real_2y = latest_2y - latest_cpi_yoy

        # ì‹¤ì§ˆê¸ˆë¦¬ ì¡°ê±´ (CPI ì¶”ì„¸ ë°˜ì˜)
        if real_10y < 0:
            print("10ë…„ë¬¼ ê¸ˆë¦¬ : ", latest_10y, "CPI_YoY : ", latest_cpi_yoy)
            if latest_cpi_yoy < prev_cpi_yoy:
                signal += 1
                comments.append("ğŸ”¼ ì‹¤ì§ˆê¸ˆë¦¬ < 0 & CPI YoY í•˜ë½ â†’ ì™„í™” ì‹ í˜¸")
            else:
                signal -= 1
                comments.append("âš ï¸ ì‹¤ì§ˆê¸ˆë¦¬ < 0 but CPI YoY ìƒìŠ¹ â†’ ì¸í”Œë ˆ ì••ë ¥")
        else:
            comments.append("â„¹ï¸ ì‹¤ì§ˆê¸ˆë¦¬ ì–‘í˜¸ (10Y > CPI YoY)")

        if real_2y > 2:
            print("2ë…„ë¬¼ ê¸ˆë¦¬ : ", latest_2y, "CPI_YoY : ", latest_cpi_yoy)
            signal -= 1
            comments.append("ğŸ“‰ ë‹¨ê¸° ì‹¤ì§ˆê¸ˆë¦¬ > 2% â†’ ê¸´ì¶• ìš°ë ¤")

        # ê¸ˆë¦¬ì°¨ (ì¥ë‹¨ê¸° ìŠ¤í”„ë ˆë“œ)
        spread = latest_10y - latest_2y
        prev_spread = prev_10y - prev_2y

        # ë³€í™”ëŸ‰
        delta_spread = spread - prev_spread

        # íŒë‹¨
        if spread < -0.5:
            if delta_spread > 0:
                signal += 1
                comments.append("ğŸ”¼ ì¥ë‹¨ê¸° ê¸ˆë¦¬ì—­ì „ ìƒíƒœì§€ë§Œ ì •ìƒí™” ì¶”ì„¸ â†’ ê¸ì •ì  ë³€í™”")
            else:
                signal -= 1
                comments.append("âš ï¸ ì¥ë‹¨ê¸° ê¸ˆë¦¬ì—­ì „ + ì¶”ê°€ ì•…í™” â†’ ì¹¨ì²´ ì‹ í˜¸")
        elif spread > 0:
            if delta_spread < 0:
                signal -= 1
                comments.append("âš ï¸ ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨ ì–‘ìˆ˜ì§€ë§Œ ì—­ì „ ë°©í–¥ìœ¼ë¡œ ì¶•ì†Œ ì¤‘ â†’ ì£¼ì˜")
            else:
                signal += 1
                comments.append("ğŸ”¼ ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨ ì •ìƒ + í™•ì¥ ì¶”ì„¸ â†’ íšŒë³µ ê¸°ëŒ€")
        else:
            comments.append("â¸ï¸ ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨ ì¤‘ë¦½ êµ¬ê°„")

        # # ê¸°ì¤€ê¸ˆë¦¬ vs 2ë…„ë¬¼ (ë¯¸ë˜ ê¸ˆë¦¬ ì¸í•˜ ê¸°ëŒ€ ì—¬ë¶€)
        # if latest_2y < latest_fed_rate:
        #     signal += 1
        #     comments.append("ğŸ”½ 2Y < ê¸°ì¤€ê¸ˆë¦¬ â†’ ê¸ˆë¦¬ ì¸í•˜ ê¸°ëŒ€ (ì™„í™” ì‹œê·¸ë„)")
        # else:
        #     comments.append("â¸ 2Y â‰¥ ê¸°ì¤€ê¸ˆë¦¬ â†’ ê¸´ì¶• ì§€ì† ë˜ëŠ” ë¶ˆí™•ì‹¤ì„±")

        return signal, comments

    # Clear
    def plot_rate_indicators_vs_sp500(self):
        # ë°ì´í„° ì¤€ë¹„
        sp500 = self.get_sp500()
        df_10y = self.get_10years_treasury_yeild()
        df_2y = self.get_2years_treasury_yeild()
        cpi_yoy = self.get_cpi_yoy()
        fed = self.get_fed_funds_rate()

        # ì›” ë‹¨ìœ„ ì •ë ¬
      
        sp500['date'] = pd.to_datetime(sp500['date'])  # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ì•ˆì „í•˜ê²Œ
        sp500['month'] = pd.to_datetime(sp500['date']).dt.to_period('M').dt.to_timestamp()

        # ê° ì›”ì˜ ì²« ë²ˆì§¸ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” S&P500 ê°’ë§Œ ì¶”ì¶œ
        sp_monthly_first = sp500.sort_values('date').groupby('month').first().reset_index()

        # âœ… ê¸°ì¡´ 'date' ì»¬ëŸ¼ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        sp_monthly_first = sp_monthly_first.drop(columns=['date'])
        
        # âœ… ë‚ ì§œë¥¼ í•´ë‹¹ ì›”ì˜ 1ì¼ë¡œ ë°”ê¿”ì¤Œ
        sp_monthly_first = sp_monthly_first.rename(columns={'month': 'date'})
        sp_monthly_first = sp_monthly_first[["date", "sp500_close"]]


        df_10y['date'] = df_10y['date'].dt.to_period('M').dt.to_timestamp()
        df_2y['date'] = df_2y['date'].dt.to_period('M').dt.to_timestamp()
        cpi_yoy['date'] = cpi_yoy['date'].dt.to_period('M').dt.to_timestamp()
        fed['date'] = fed['date'].dt.to_period('M').dt.to_timestamp()

        # ë³‘í•©
        df = sp_monthly_first.copy()
        df = df.merge(df_10y[['date', 'value']], on='date', how='inner').rename(columns={'value': '10y'})
        df = df.merge(df_2y[['date', 'value']], on='date', how='inner').rename(columns={'value': '2y'})
        df = df.merge(cpi_yoy[['date', 'CPI YOY(%)']], on='date', how='inner').rename(columns={'CPI YOY(%)': 'cpi_yoy'})
        df = df.merge(fed[['date', 'fed_funds_rate']], on='date', how='inner')

        # ì§€í‘œ ê³„ì‚°
        df['real_10y'] = df['10y'] - df['cpi_yoy']
        df['spread'] = df['10y'] - df['2y']
        # df['ffr_vs_2y'] = df['fed_funds_rate'] - df['2y']

        # ì‹œê°í™”
        fig, axs = plt.subplots(3, 1, figsize=(14, 12), sharex=True)

        # 1. S&P500
        axs[0].plot(df['date'], df['sp500_close'], label='S&P500', color='black')
        axs[0].set_ylabel('S&P500')
        axs[0].legend(loc='upper left')
        axs[0].grid(True)

        # 2. ì‹¤ì§ˆê¸ˆë¦¬ (10Y - CPI YoY)
        axs[1].plot(df['date'], df['real_10y'], label='ì‹¤ì§ˆ 10Y ê¸ˆë¦¬', color='green')
        axs[1].axhline(0, color='gray', linestyle='--')
        axs[1].set_ylabel('10Y - CPI YoY (%)')
        axs[1].legend(loc='upper left')
        axs[1].grid(True)

        # 3. ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨ (10Y - 2Y)
        axs[2].plot(df['date'], df['spread'], label='10Y - 2Y', color='blue')
        axs[2].axhline(0, color='gray', linestyle='--')
        axs[2].fill_between(df['date'], df['spread'], 0, where=(df['spread'] < 0), color='red', alpha=0.2, label='ì—­ì „ êµ¬ê°„')
        axs[2].set_ylabel('10Y - 2Y (%)')
        axs[2].legend(loc='upper left')
        axs[2].grid(True)

        # # 4. ê¸°ì¤€ê¸ˆë¦¬ - 2Y
        # axs[3].plot(df['date'], df['ffr_vs_2y'], label='ê¸°ì¤€ê¸ˆë¦¬ - 2Y', color='orange')
        # axs[3].axhline(0, color='gray', linestyle='--')
        # axs[3].set_ylabel('FFR - 2Y (%)')
        # axs[3].legend(loc='upper left')
        # axs[3].grid(True)

        fig.suptitle("ğŸ“Š ê¸ˆë¦¬ ê¸°ë°˜ ì£¼ìš” ì§€í‘œ vs S&P500", fontsize=16)
        plt.tight_layout()
        plt.show()

    # Clear
    def plot_rate_indicators_vs_sp500_with_signal(self):
        # ë°ì´í„° ì¤€ë¹„
        sp500 = self.get_sp500()
        df_10y = self.get_10years_treasury_yeild()
        df_2y = self.get_2years_treasury_yeild()
        cpi_yoy = self.get_cpi_yoy()
        fed = self.get_fed_funds_rate()

        # ì›” ë‹¨ìœ„ ì •ë ¬
      
        sp500['date'] = pd.to_datetime(sp500['date'])  # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ì•ˆì „í•˜ê²Œ
        sp500['month'] = pd.to_datetime(sp500['date']).dt.to_period('M').dt.to_timestamp()

        # ê° ì›”ì˜ ì²« ë²ˆì§¸ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” S&P500 ê°’ë§Œ ì¶”ì¶œ
        sp_monthly_first = sp500.sort_values('date').groupby('month').first().reset_index()

        # âœ… ê¸°ì¡´ 'date' ì»¬ëŸ¼ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        sp_monthly_first = sp_monthly_first.drop(columns=['date'])
        
        # âœ… ë‚ ì§œë¥¼ í•´ë‹¹ ì›”ì˜ 1ì¼ë¡œ ë°”ê¿”ì¤Œ
        sp_monthly_first = sp_monthly_first.rename(columns={'month': 'date'})
        sp_monthly_first = sp_monthly_first[["date", "sp500_close"]]


        # ë‚ ì§œ ì²˜ë¦¬
        for df in [df_10y, df_2y, cpi_yoy, fed]:
            df['date'] = pd.to_datetime(df['date']).dt.to_period('M').dt.to_timestamp()

        # ë³‘í•©
        df = sp_monthly_first.copy()
        df = df.merge(df_10y[['date', 'value']], on='date').rename(columns={'value': '10y'})
        df = df.merge(df_2y[['date', 'value']], on='date').rename(columns={'value': '2y'})
        df = df.merge(cpi_yoy[['date', 'CPI YOY(%)']], on='date').rename(columns={'CPI YOY(%)': 'cpi_yoy'})
        df = df.merge(fed[['date', 'fed_funds_rate']], on='date')

        # ì§€í‘œ ê³„ì‚°
        df['real_10y'] = df['10y'] - df['cpi_yoy']
        df['spread'] = df['10y'] - df['2y']
        # df['ffr_vs_2y'] = df['fed_funds_rate'] - df['2y']

        # ğŸ“Œ ê³¼ê±° ì‹œì ë³„ rate_signal ê³„ì‚°
        signal_list = []
        for i in range(1, len(df)):
            try:
                latest_10y = df.iloc[i]['10y']
                latest_2y = df.iloc[i]['2y']
                prev_10y = df.iloc[i-1]['10y']
                prev_2y = df.iloc[i-1]['2y']
                latest_cpi_yoy = df.iloc[i]['cpi_yoy']
                prev_cpi_yoy = df.iloc[i-1]['cpi_yoy']
                latest_fed_rate = df.iloc[i]['fed_funds_rate']

                # ì¬í˜„í•œ rate_signal ë¡œì§
                signal = 0
                real_10y = latest_10y - latest_cpi_yoy
                real_2y = latest_2y - latest_cpi_yoy
                spread = latest_10y - latest_2y
                prev_spread = prev_10y - prev_2y
                delta_spread = spread - prev_spread

                if real_10y < 0:
                    if latest_cpi_yoy < prev_cpi_yoy:
                        signal += 1
                    else:
                        signal -= 1
                if real_2y > 2:
                    signal -= 1
                if spread < -0.5:
                    signal += 1 if delta_spread > 0 else -1
                elif spread > 0:
                    signal += 1 if delta_spread >= 0 else -1
                if latest_2y < latest_fed_rate:
                    signal += 1

                signal_list.append(signal)
            except:
                signal_list.append(None)

        df = df.iloc[1:].copy()
        df['rate_signal'] = signal_list

        # ì‹œê°í™”
        fig, axs = plt.subplots(3, 1, figsize=(14, 12), sharex=True)

        # 1. S&P500
        axs[0].plot(df['date'], df['sp500_close'], label='S&P500', color='black')
        axs[0].scatter(df[df['rate_signal'] >= 2]['date'], df[df['rate_signal'] >= 2]['sp500_close'], marker='^', color='green', label='ğŸ“ˆ ë§¤ìˆ˜ ì‹ í˜¸', s=80)
        axs[0].scatter(df[df['rate_signal'] <= -2]['date'], df[df['rate_signal'] <= -2]['sp500_close'], marker='v', color='red', label='ğŸ“‰ ë§¤ë„ ì‹ í˜¸', s=80)
        axs[0].set_ylabel('S&P500')
        axs[0].legend(loc='upper left')
        axs[0].grid(True)

        # 2. ì‹¤ì§ˆê¸ˆë¦¬ (10Y - CPI YoY)
        axs[1].plot(df['date'], df['real_10y'], label='ì‹¤ì§ˆ 10Y ê¸ˆë¦¬', color='green')
        axs[1].axhline(0, color='gray', linestyle='--')
        axs[1].set_ylabel('10Y - CPI YoY (%)')
        axs[1].legend(loc='upper left')
        axs[1].grid(True)

        # 3. ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨ (10Y - 2Y)
        axs[2].plot(df['date'], df['spread'], label='10Y - 2Y', color='blue')
        axs[2].axhline(0, color='gray', linestyle='--')
        axs[2].fill_between(df['date'], df['spread'], 0, where=(df['spread'] < 0), color='red', alpha=0.2)
        axs[2].set_ylabel('10Y - 2Y (%)')
        axs[2].legend(loc='upper left')
        axs[2].grid(True)

        # 4. ê¸°ì¤€ê¸ˆë¦¬ - 2Y
        # axs[3].plot(df['date'], df['ffr_vs_2y'], label='ê¸°ì¤€ê¸ˆë¦¬ - 2Y', color='orange')
        # axs[3].axhline(0, color='gray', linestyle='--')
        # axs[3].set_ylabel('FFR - 2Y (%)')
        # axs[3].legend(loc='upper left')
        # axs[3].grid(True)

        fig.suptitle("ğŸ“Š ê¸ˆë¦¬ ê¸°ë°˜ ì£¼ìš” ì§€í‘œ vs S&P500 + ì‹œê·¸ë„ ë§ˆí‚¹", fontsize=16)
        plt.tight_layout()
        plt.show()

    def analyze_rate_correlations(self, show_plot: bool = True):
        """
        S&P500 ì¢…ê°€ì™€ ê¸ˆë¦¬ ê´€ë ¨ ì£¼ìš” ì§€í‘œ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„ ë° ì‹œê°í™”
        - ì‹¤ì§ˆ 10ë…„ ê¸ˆë¦¬ (10Y - CPI YoY)
        - ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨ (10Y - 2Y)
        - ê¸°ì¤€ê¸ˆë¦¬ - 2ë…„ë¬¼

        Returns:
            dict: ê° ì§€í‘œì™€ S&P500 ê°„ì˜ í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜
        """
        # 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
        sp500 = self.get_sp500()
        df_10y = self.get_10years_treasury_yeild()
        df_2y = self.get_2years_treasury_yeild()
        cpi_yoy = self.get_cpi_yoy()
        fed = self.get_fed_funds_rate()

        # 2. ë‚ ì§œ í†µì¼ (ì›” ë‹¨ìœ„)
        for df in [sp500, df_10y, df_2y, cpi_yoy, fed]:
            df['date'] = pd.to_datetime(df['date']).dt.to_period('M').dt.to_timestamp()

        # 3. ë³‘í•©
        df = sp500.copy()
        df = df.merge(df_10y[['date', 'value']], on='date').rename(columns={'value': '10y'})
        df = df.merge(df_2y[['date', 'value']], on='date').rename(columns={'value': '2y'})
        df = df.merge(cpi_yoy[['date', 'CPI YOY(%)']], on='date').rename(columns={'CPI YOY(%)': 'cpi_yoy'})
        df = df.merge(fed[['date', 'fed_funds_rate']], on='date')

        # 4. ì§€í‘œ ê³„ì‚°
        df['real_10y'] = df['10y'] - df['cpi_yoy']
        df['spread'] = df['10y'] - df['2y']
        # df['ffr_vs_2y'] = df['fed_funds_rate'] - df['2y']

        # 5. ìƒê´€ê´€ê³„ ê³„ì‚°
        corr_matrix = df[['sp500_close', 'real_10y', 'spread']].corr()
        result = {
            'S&P500 vs ì‹¤ì§ˆ 10Y ê¸ˆë¦¬': round(corr_matrix.loc['sp500_close', 'real_10y'], 3),
            'S&P500 vs ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨': round(corr_matrix.loc['sp500_close', 'spread'], 3)
            #'S&P500 vs ê¸°ì¤€ê¸ˆë¦¬ - 2Y': round(corr_matrix.loc['sp500_close', 'ffr_vs_2y'], 3)
        }
        
        print(result)

        # 6. ì‹œê°í™” (ì„ íƒì )
        if show_plot:
            import matplotlib.pyplot as plt
            import seaborn as sns
            plt.figure(figsize=(8, 6))
            sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', square=True)
            plt.title("S&P500ê³¼ ê¸ˆë¦¬ ê´€ë ¨ ì§€í‘œ ê°„ ìƒê´€ê´€ê³„", fontsize=13)
            plt.tight_layout()
            plt.show()

        return result    

    # Clear - ì›”ë³„ë°ì´í„° - 1ê°œì›” ì§€ì—°
    def get_unemployment_rate(self):
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'UNRATE',
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '2000-01-01'
        }
        response = requests.get(url, params=params)
        data = response.json()
        df = pd.DataFrame(data['observations'])
        df['date'] = pd.to_datetime(df['date'])
        df['unemployment_rate'] = pd.to_numeric(df['value'], errors='coerce')
    
        return df
    
    def get_ism_pmi(self):
        """
        TradingEconomics í•œêµ­ì–´ ì‚¬ì´íŠ¸ì—ì„œ ISM ì œì¡°ì—… PMI ì§€í‘œë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
        """
        url = "https://ko.tradingeconomics.com/united-states/manufacturing-pmi"

        options = Options()
        # options.add_argument('--headless')  # â† ì¼ë‹¨ êº¼ë‘ì„¸ìš”
        options.add_argument('--disable-gpu')
        options.add_argument('--no-sandbox')
        options.add_argument(
            "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
        )

        driver = webdriver.Chrome(options=options)
        driver.get(url)

        try:
            WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "table.table"))
            )
            soup = BeautifulSoup(driver.page_source, 'html.parser')
        except Exception as e:
            driver.quit()
            raise Exception("âŒ í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨: table ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.") from e
        finally:
            driver.quit()

        table = soup.find('table', class_='table table-hover')
        if not table:
            raise Exception("âŒ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        rows = table.find('tbody').find_all('tr')
        for row in rows:
            columns = row.find_all('td')
            if len(columns) >= 5:
                name = columns[0].get_text(strip=True)
                if "ISM ì œì¡°ì—… PMI" in name:
                    value = columns[1].get_text(strip=True)
                    date = columns[4].get_text(strip=True)
                    return {
                        "ì§€í‘œëª…": name,
                        "ê°’": value,
                        "ë°œí‘œì¼": date
                    }

        raise Exception("âŒ 'ISM ì œì¡°ì—… PMI' í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # Clear - ì›”ë³„ ë°ì´í„° - 1ê°œì›” ì§€ì—°
    def update_ism_pmi_data(self):
        '''
        ë¡œì»¬ì— ì €ì¥ëœ ism_pmi íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
        '''
        try:
            pmi_df = self.pmi_updater.update_csv()
            print("âœ… ISM PMI data CSV ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        except Exception as e:
            print("ğŸ“› ISM PMI data ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:", e)
        return pmi_df

    # Clear - ì›”ë³„ë°ì´í„° - 2ê°œì›” ì§€ì—°
    def get_UMCSENT_index(self):
        '''
        ë¯¸ì‹œê°„ ì†Œë¹„ì ì‹¬ë¦¬ì§€ìˆ˜
        100ì´ìƒ : ë‚™ê´€ì  ë¶„ìœ„ê¸°
        80~100 : ì–‘í˜¸í•œ ì‹¬ë¦¬, ê±´ì „í•œ ì†Œë¹„ ì˜ˆìƒ
        60~80 : ì†Œë¹„ì ë¶ˆì•ˆì •, ì†Œë¹„ ìœ„ì¶• ê°€ëŠ¥ì„±
        60 ì´í•˜ : ê²½ê¸° ì¹¨ì²´ ì‹ í˜¸ ê°€ëŠ¥ì„±(ì†Œë¹„ ê¸‰ê° ìš°ë ¤ë ¤)
        '''

        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'UMCSENT',
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '2000-01-01'
        }
        response = requests.get(url, params=params)
        data = response.json()
        df = pd.DataFrame(data['observations'])
        df['date'] = pd.to_datetime(df['date'])
        df['umcsent_index'] = pd.to_numeric(df['value'], errors='coerce')
  
        return df 

    # ë¯¸êµ­ ì„ í–‰ ì§€ìˆ˜ - ì›”ë³„ë°ì´í„°
    def get_us_leading_index_actual(self):
        """
        TradingEconomics ì›¹ í˜ì´ì§€ì—ì„œ ë¯¸êµ­ ì„ í–‰ ì§€ìˆ˜ì˜ ì‹¤ì œê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.

        Args:
            url (str): ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ TradingEconomics í˜ì´ì§€ì˜ URL.

        Returns:
            str: ì‹¤ì œê°’ (ì˜ˆ: '98.80') ë˜ëŠ” ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° None.
        """

        url = "https://ko.tradingeconomics.com/united-states/leading-economic-index"
    
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        
        extracted_data = []

        try:
            # ì›¹ í˜ì´ì§€ì— GET ìš”ì²­ ë³´ë‚´ê¸°
            print(f"URLì— ì ‘ì† ì¤‘: {url}")
            response = requests.get(url, headers=headers)
            response.raise_for_status() # HTTP ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì˜ˆì™¸ ë°œìƒ

            # BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±
            soup = BeautifulSoup(response.text, 'html.parser')

            # 'ctl00_ContentPlaceHolder1_ctl00_ctl00_PanelPeers' IDë¥¼ ê°€ì§„ divë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            panel_peers_div = soup.find('div', id='ctl00_ContentPlaceHolder1_ctl00_ctl00_PanelPeers')
            
            if panel_peers_div:
                # í•´ë‹¹ div ì•ˆì—ì„œ 'table-responsive' í´ë˜ìŠ¤ë¥¼ ê°€ì§„ divë¥¼ ì°¾ê³  ê·¸ ì•ˆì˜ 'table table-hover' í…Œì´ë¸”ì„ ì°¾ìŠµë‹ˆë‹¤.
                table_responsive_div = panel_peers_div.find('div', class_='table-responsive')
                if table_responsive_div:
                    data_table = table_responsive_div.find('table', class_='table table-hover')
                    
                    if data_table:
                        # í…Œì´ë¸” í—¤ë” ì¶”ì¶œ
                        header_row = data_table.find('thead').find('tr')
                        if header_row:
                            headers = [th.get_text(strip=True) for th in header_row.find_all('th')]
                            # ì²« ë²ˆì§¸ ë¹ˆ í—¤ë” ì œê±°
                            if headers and headers[0] == '':
                                headers = headers[1:]
                            print(f"ì¶”ì¶œëœ í—¤ë”: {headers}") # ë””ë²„ê¹…ìš©

                            # 'ë§ˆì§€ë§‰'ê³¼ 'ì°¸ê³ ' ì—´ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
                            try:
                                last_index = headers.index("ë§ˆì§€ë§‰")
                                ref_date_index = headers.index("ì°¸ê³ ")
                            except ValueError as e:
                                print(f"ERROR: í•„ìš”í•œ í—¤ë”('ë§ˆì§€ë§‰' ë˜ëŠ” 'ì°¸ê³ ')ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                                return []

                            # ë°ì´í„° í–‰ ìˆœíšŒ: tbody ìœ ë¬´ì™€ ìƒê´€ì—†ì´ í…Œì´ë¸” ë‚´ì˜ ëª¨ë“  <tr>ì„ ì°¾ê³ , í—¤ë” ë‹¤ìŒ í–‰ë¶€í„° ë°ì´í„°ë¡œ ì²˜ë¦¬
                            all_table_rows = data_table.find_all('tr')
                            
                            # í—¤ë” í–‰ ë‹¤ìŒë¶€í„° ì‹¤ì œ ë°ì´í„° í–‰ìœ¼ë¡œ ê°„ì£¼
                            # í—¤ë”ê°€ <thead> ì•ˆì— ìˆê³ , ë°ì´í„°ëŠ” <tbody> ì•ˆì— ëª…ì‹œë  ìˆ˜ë„ ìˆì§€ë§Œ,
                            # <tbody>ê°€ ì—†ëŠ” ê²½ìš° <tr>ì´ <table> ë°”ë¡œ ì•„ë˜ì— ì˜¬ ìˆ˜ ìˆìŒ.
                            # ë”°ë¼ì„œ thead ì•ˆì˜ trì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ trì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
                            data_rows = [row for row in all_table_rows if row.find_parent('thead') is None]

                            if data_rows:
                                for row in data_rows:
                                    # ì²« ë²ˆì§¸ tdëŠ” ì§€í‘œ ì´ë¦„ì´ë¯€ë¡œ ë”°ë¡œ ì²˜ë¦¬
                                    indicator_name_tag = row.find('td', style="padding-left: 10px; text-align: left;")
                                    indicator_name = indicator_name_tag.get_text(strip=True) if indicator_name_tag else "N/A"

                                    # ì§€í‘œ ì´ë¦„ ì…€ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì…€ì—ì„œ ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
                                    data_cells_excluding_indicator_name = row.find_all('td')[1:] 
                                    processed_data_cells = [cell.get_text(strip=True) for cell in data_cells_excluding_indicator_name]

                                    last_value = None
                                    ref_date = None

                                    # ì¶”ì¶œëœ í—¤ë”ì˜ ì¸ë±ìŠ¤ì— ë”°ë¼ ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
                                    if last_index < len(processed_data_cells):
                                        last_value = processed_data_cells[last_index]
                                    if ref_date_index < len(processed_data_cells):
                                        ref_date = processed_data_cells[ref_date_index]
                                    
                                    extracted_data.append({
                                        "indicator": indicator_name,
                                        "value": last_value,
                                        "date": ref_date
                                    })
                            else:
                                print("ERROR: í…Œì´ë¸”ì—ì„œ ë°ì´í„° í–‰(<tr>)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            print("ERROR: í…Œì´ë¸” í—¤ë” í–‰(<thead><tr>)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        print("ERROR: 'table table-hover' í´ë˜ìŠ¤ë¥¼ ê°€ì§„ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    print("ERROR: 'table-responsive' divë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print("ERROR: 'ctl00_ContentPlaceHolder1_ctl00_ctl00_PanelPeers' IDë¥¼ ê°€ì§„ divë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        except requests.exceptions.RequestException as e:
            print(f"ì›¹ í˜ì´ì§€ì— ì ‘ì†í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        except Exception as e:
            print(f"ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        return extracted_data[0]

   # Clear - ì›”ë³„ë°ì´í„°(ECRI)
    def get_USSLIND(self):
        '''
        St. Louis Fedê°€ ë°œí‘œí•˜ëŠ” ì§€í‘œë¥¼ ê³µì‹ì ìœ¼ë¡œ FREDì— ì œê³µí•˜ëŠ” í˜•íƒœ
        ìƒìŠ¹ì‹œ ê²½ê¸°íšŒë³µ/í™•ì¥ ì˜ë¯¸, í•˜ë½ì‹œ ê²½ê¸° ë‘”í™”/ì¹¨ì²´ ì˜ë¯¸
        '''
        
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'USSLIND',
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '2000-01-01'
        }
        response = requests.get(url, params=params)
        data = response.json()
        df = pd.DataFrame(data['observations'])
        df['date'] = pd.to_datetime(df['date'])
        df['LI_index'] = pd.to_numeric(df['value'], errors='coerce')
        
        return df
    
    # Clear - ì›”ë³„ë°ì´í„°
    def get_CLI(self):
        '''
        CLIê°€ ë°œí‘œí•˜ëŠ” ì§€í‘œë¥¼ ê³µì‹ì ìœ¼ë¡œ FREDì— ì œê³µí•˜ëŠ” í˜•íƒœ
        ìƒìŠ¹ì‹œ ê²½ê¸°íšŒë³µ/í™•ì¥ ì˜ë¯¸, í•˜ë½ì‹œ ê²½ê¸° ë‘”í™”/ì¹¨ì²´ ì˜ë¯¸
        '''
        
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'USALOLITONOSTSAM',
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '2000-01-01'
        }
        response = requests.get(url, params=params)
        data = response.json()
        df = pd.DataFrame(data['observations'])
        df['date'] = pd.to_datetime(df['date'])
        df['CLI_index'] = pd.to_numeric(df['value'], errors='coerce')
        
        return df

    def analyze_ecri_trend(self):

        df = self.get_CLI()
        x = np.arange(len(df))
        y = df['CLI_index'].values
        slope, _, r_value, _, _ = linregress(x, y)

        if slope > 0.05:
            return "ğŸ“ˆ ìƒìŠ¹ ì¶”ì„¸ (ê²½ê¸° íšŒë³µ ê¸°ëŒ€)"
        elif slope < -0.05:
            return "ğŸ“‰ í•˜ë½ ì¶”ì„¸ (ê²½ê¸° ë‘”í™” ìœ„í—˜)"
        else:
            return "â– íš¡ë³´ ì¶”ì„¸ (ë¶ˆí™•ì‹¤ì„± ì§€ì†)"

    
    def generate_rate_cut_signals(self):
        """
        ê¸°ì¤€ê¸ˆë¦¬ ì¸í•˜ ì‹œì ë¶€í„° 6ê°œì›” ì´ë‚´ì— CLI < 130 ê·¸ë¦¬ê³  PMI < 50ì¸ ê²½ìš° ë§¤ë„ ì‹œê·¸ë„ í‘œì‹œ

        Returns:
            signal_df: ë§¤ë„ ì‹œê·¸ë„ í¬í•¨ëœ DataFrame (date, sp500_close, cli, pmi, rate_cut, signal)
        """
        # 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
        sp500_df = self.get_sp500()
        fed_df = self.generate_fed_rate_turning_points()  # ì „í™˜ì ë§Œ True
        cli_df = self.get_CLI()
        pmi_df = ISMPMIUpdater().preprocess_raw_csv()

        # 2. ë‚ ì§œ ì •ì œ
        sp500_df["date"] = pd.to_datetime(sp500_df["date"])
        sp500_df['month'] = pd.to_datetime(sp500_df['date']).dt.to_period('M').dt.to_timestamp()

        # ê° ì›”ì˜ ì²« ë²ˆì§¸ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” S&P500 ê°’ë§Œ ì¶”ì¶œ
        sp_monthly_first = sp500_df.sort_values('date').groupby('month').first().reset_index()

        # âœ… ê¸°ì¡´ 'date' ì»¬ëŸ¼ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        sp_monthly_first = sp_monthly_first.drop(columns=['date'])
        
        # âœ… ë‚ ì§œë¥¼ í•´ë‹¹ ì›”ì˜ 1ì¼ë¡œ ë°”ê¿”ì¤Œ
        sp_monthly_first = sp_monthly_first.rename(columns={'month': 'date'})
        sp_monthly_first = sp_monthly_first[["date", "sp500_close"]]


        fed_df["date"] = pd.to_datetime(fed_df["date"])
        cli_df["date"] = pd.to_datetime(cli_df["date"])
        pmi_df.rename(columns={"Month/Year": "date"}, inplace=True)
        pmi_df["date"] = pd.to_datetime(pmi_df["date"])

        # 3. ëª¨ë“  ë°ì´í„° ë³‘í•© (outer merge â†’ date ê¸°ì¤€)
        df = sp_monthly_first.merge(cli_df, on="date", how="outer")
        df = df.merge(pmi_df, on="date", how="outer")
        df = df.merge(fed_df[["date", "rate_cut"]], on="date", how="left")

        df = df.sort_values("date").reset_index(drop=True)

        # 4. ë§¤ë„ ì‹œê·¸ë„ ì´ˆê¸°í™”
        df["signal"] = False

        # 5. ê¸°ì¤€ê¸ˆë¦¬ ì¸í•˜ ì‹œì ë¶€í„° 6ê°œì›” ë™ì•ˆ ì¡°ê±´ ì²´í¬
        cut_dates = df[df["rate_cut"] == True]["date"].tolist()

        for cut_date in cut_dates:
            end_date = cut_date + pd.DateOffset(months=6)
            mask = (df["date"] > cut_date) & (df["date"] <= end_date)
            condition = (df["CLI_index"] < 130) & (df["PMI"] < 50)
            df.loc[mask & condition, "signal"] = True

        return df

    # Clear
    def plot_sp500_with_sell_signals(self, save_to = None):

        signal_df = self.generate_rate_cut_signals()
        df = signal_df.copy()
        fig = plt.figure(figsize=(14, 6))
        plt.plot(df["date"], df["sp500_close"], label="S&P500", color="black")

        # ë§¤ë„ ì‹œê·¸ë„ ì‹œê°í™”
        sell_signals = df[df["signal"] == True]
        plt.scatter(sell_signals["date"], sell_signals["sp500_close"],
                    color="red", label="Sell Signal", zorder=5)

        plt.title("S&P500 with Sell Signals (CLI < 130 and PMI < 50 within 6 months of rate cut)")
        plt.xlabel("Date")
        plt.ylabel("S&P500")
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.show()
        if save_to:
            fig.savefig(save_to, format='png')
            plt.close(fig)
        else:
            plt.show()

    # Clear
    def generate_buy_signals_from_hike(self):

        """
        ê¸°ì¤€ê¸ˆë¦¬ ì¸ìƒ ì‹œì‘ ì‹œì  ì´í›„ 6ê°œì›” ì´ë‚´ì—
        CLII > 130 AND PMI > 50 ì¸ ê²½ìš° ë§¤ìˆ˜ ì‹œê·¸ë„ ìƒì„±

        Returns:
            buy_df: ['date', 'cli', 'pmi', 'sp500_close', 'rate_hike', 'buy_signal']
        """
        # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
        fed_df = self.generate_fed_rate_turning_points()  # includes 'rate_hike'
        cli_df = self.get_CLI()
        pmi_df = self.update_ism_pmi_data()
        pmi_df.rename(columns={"Month/Year": "date", "PMI": "pmi"}, inplace=True)
        sp_df = self.get_sp500()

        # âœ… ê° ë‹¬ì˜ ì²« ê±°ë˜ì¼ë§Œ ì¶”ì¶œ
        sp_df['year_month'] = sp_df['date'].dt.to_period('M')
        sp_monthly_first = sp_df.sort_values('date').groupby('year_month').first().reset_index()
        
        # âœ… ë‚ ì§œë¥¼ í•´ë‹¹ ì›”ì˜ 1ì¼ë¡œ ë°”ê¿”ì¤Œ
        sp_monthly_first["date"] = sp_monthly_first["year_month"].dt.to_timestamp()
        sp_monthly_first = sp_monthly_first[["date", "sp500_close"]]


        # ë³‘í•©
        df = fed_df.merge(cli_df, on="date", how="outer")
        df = df.merge(pmi_df, on="date", how="outer")
        df = df.merge(sp_monthly_first, on="date", how="outer")
        df = df.sort_values("date").reset_index(drop=True)

        # 1. rate_hike ë°œìƒ ì‹œì  ëª©ë¡
        hike_dates = df[df["rate_hike"] == True]["date"].tolist()

        # 2. ê° ê¸°ì¤€ê¸ˆë¦¬ ì¸ìƒ ì‹œì‘ ì´í›„ 6ê°œì›” ë™ì•ˆ ì¡°ê±´ ì¶©ì¡± ì—¬ë¶€ í™•ì¸
        df["buy_signal"] = False

        for hike_date in hike_dates:
            window_end = hike_date + pd.DateOffset(months=6)
            window_mask = (df["date"] > hike_date) & (df["date"] <= window_end)
            condition = (df["CLI_index"] > 130) & (df["pmi"] > 50)
            df.loc[window_mask & condition, "buy_signal"] = True

        return df[["date", "fed_funds_rate", "rate_hike", "CLI_index", "pmi", "sp500_close", "buy_signal"]]

    # Clear
    def plot_buy_signals_from_hike(self, save_to = None):
        """
        generate_buy_signals_from_hike() ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ
        S&P500 ì§€ìˆ˜ ê·¸ë˜í”„ ìœ„ì— ë§¤ìˆ˜ ì‹œê·¸ë„ ì‹œì ì„ í‘œì‹œí•˜ëŠ” ì‹œê°í™” í•¨ìˆ˜
        """
        df = self.generate_buy_signals_from_hike()

        fig = plt.figure(figsize=(14, 6))
        plt.plot(df["date"], df["sp500_close"], label="S&P500", color="blue")

        # ë§¤ìˆ˜ ì‹œê·¸ë„ í‘œì‹œ
        buy_signals = df[df["buy_signal"] == True]
        plt.scatter(buy_signals["date"], buy_signals["sp500_close"], color="green", label="Buy Signal", marker="^", s=100)

        plt.title("Buy Signals After Fed Rate Hike Start (CLI > 130 & PMI > 50)")
        plt.xlabel("Date")
        plt.ylabel("S&P500 Index")
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.show()
        if save_to:
            fig.savefig(save_to, format='png')
            plt.close(fig)
        else:
            plt.show()


    def find_signals_from_erci_indicators(self):
        """
        ì‹¤ì—…ë¥ ê³¼ ERCI(USSLIND) ì§€í‘œ ë°œí‘œ ì§€ì—°ì„ ê³ ë ¤í•˜ì—¬ ì¡°ê±´ ì¶©ì¡± ì‹œì ì„ ì°¾ëŠ” í•¨ìˆ˜

        ë§¤ìˆ˜ ì¡°ê±´: ì‹¤ì—…ë¥  > í‰ê· , ECRI < 95
        ë§¤ë„ ì¡°ê±´: ì‹¤ì—…ë¥  < í‰ê· , ECRI >= 110

        Returns:
            signal_df : ë§¤ìˆ˜/ë§¤ë„ ì‹œì ê³¼ ì¡°ê±´ ì •ë³´ë¥¼ í¬í•¨í•œ DataFrame
        """
        from pandas.tseries.offsets import MonthBegin
        import pandas as pd

        # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
        ecri_df = self.get_USSLIND()  # 'LI_index' ë˜ëŠ” 'value', 'date' í¬í•¨
        unemp_df = self.get_unemployment_rate()  # 'unemployment_rate' ë˜ëŠ” 'value', 'date' í¬í•¨

        # date ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì¸ë±ìŠ¤ë¡œ ì§€ì • + datetime ë³€í™˜
        if "date" in ecri_df.columns:
            ecri_df["date"] = pd.to_datetime(ecri_df["date"])
            ecri_df = ecri_df.set_index("date")

        if "date" in unemp_df.columns:
            unemp_df["date"] = pd.to_datetime(unemp_df["date"])
            unemp_df = unemp_df.set_index("date")

        # í•„ìš”í•œ ì»¬ëŸ¼ ì„ íƒ ë° ì´ë¦„ ì§€ì •
        ecri_series = ecri_df["LI_index"] if "LI_index" in ecri_df.columns else ecri_df["value"]
        ecri_series.name = "ECRI"

        unemp_series = unemp_df["unemployment_rate"] if "unemployment_rate" in unemp_df.columns else unemp_df["value"]
        unemp_series.name = "Unemployment"

        # 1ê°œì›” ë°œí‘œ ì§€ì—° ì ìš©
        ecri_shifted = ecri_series.shift(1)
        ecri_shifted.index = ecri_shifted.index + MonthBegin(1)

        unemp_shifted = unemp_series.shift(1)
        unemp_shifted.index = unemp_shifted.index + MonthBegin(1)


        # ë³‘í•© í›„ ì¡°ê±´ ì ìš©
        cond_df = pd.concat([ecri_shifted, unemp_shifted], axis=1).dropna()
        print("ğŸ“† ë³‘í•© cond_df ë§ˆì§€ë§‰ ë‚ ì§œ:", cond_df.index.max())

        unemp_mean = cond_df["Unemployment"].mean()
        print("ì‹¤ì—…ë¥  í‰ê· :", cond_df["Unemployment"].mean())

        buy_signals = cond_df[(cond_df["Unemployment"] > unemp_mean) & (cond_df["ECRI"] < 0.95)].copy()
        buy_signals["signal"] = "buy"

        sell_signals = cond_df[(cond_df["Unemployment"] < unemp_mean) & (cond_df["ECRI"] >= 1.10)].copy()
        sell_signals["signal"] = "sell"

        signal_df = pd.concat([buy_signals, sell_signals]).sort_index()
        return signal_df
    
    def plot_sp500_with_ERCI_signals(self):
        import matplotlib.pyplot as plt
        import seaborn as sns
        sns.set_style("whitegrid")

        sp500 = self.get_sp500().copy()
        # "date" ì»¬ëŸ¼ì´ ì¡´ì¬í•œë‹¤ë©´, ì´ê±¸ datetimeìœ¼ë¡œ ë³€í™˜ í›„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
        sp500["date"] = pd.to_datetime(sp500["date"])
        sp500 = sp500.set_index("date")
        sp500 = sp500.sort_index()

        # ì‹œê·¸ë„ ë°ì´í„° ì •ë ¬
        signal_df = self.find_signals_from_erci_indicators()
        signal_df = signal_df.sort_index()

        fig, ax = plt.subplots(figsize=(14, 6))
        ax.plot(sp500.index, sp500["sp500_close"], label="S&P500", color="black")

        # ê° ì‹œê·¸ë„ ë‚ ì§œì— ê°€ê¹Œìš´ S&P500 ì¢…ê°€ ìœ„ì— ë§ˆì»¤ í‘œì‹œ
        for date, row in signal_df.iterrows():
            # í•´ë‹¹ ë‚ ì§œ ì´í›„ì˜ ì²« S&P500 ì¢…ê°€ ì°¾ê¸°
            nearest = sp500[sp500.index >= date]
            if not nearest.empty:
                y = nearest.iloc[0]["sp500_close"]
                if row["signal"] == "buy":
                    ax.scatter(date, y, color="green", marker="^", s=100, label="Buy" if "Buy" not in ax.get_legend_handles_labels()[1] else "")
                elif row["signal"] == "sell":
                    ax.scatter(date, y, color="red", marker="v", s=100, label="Sell" if "Sell" not in ax.get_legend_handles_labels()[1] else "")

        ax.set_title("S&P500 with Buy/Sell Signals (Monthly signal date)", fontsize=14)
        ax.set_ylabel("S&P500 Index")
        ax.legend()
        plt.tight_layout()
        plt.show()



    def update_snp_forwardpe_data(self):
        '''
        ë¡œì»¬ì— ì €ì¥ëœ S&P500 forward pe íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
        '''
        try:
            snp_fp_df = self.snp_forwardpe_updater.update_forward_pe_csv()
            print("âœ… S&P500 Forward PE CSV ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        except Exception as e:
            print("ğŸ“› S&P500 Forward PE ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:", e)

        return snp_fp_df    


    def get_forward_pe(self):
            url = 'https://en.macromicro.me/series/20052/sp500-forward-pe-ratio'

            options = Options()
            # options.add_argument("--headless")
            options.add_argument("--no-sandbox")
            options.add_argument("--disable-gpu")
 

            driver = webdriver.Chrome(options=options)
            driver.get(url)


            try:
                # âœ… í•´ë‹¹ ìš”ì†Œê°€ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 10ì´ˆ)
                WebDriverWait(driver, 20).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "div.sidebar-sec.chart-stat-lastrows span.val"))
                )
            except:
                driver.quit()
                raise RuntimeError("ğŸ“› í˜ì´ì§€ ë¡œë”© ì¤‘ Forward PE ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            soup = BeautifulSoup(driver.page_source, 'html.parser')
            driver.quit()

            latest_val = soup.select_one("div.sidebar-sec.chart-stat-lastrows span.val")
            date = soup.select_one("div.sidebar-sec.chart-stat-lastrows .date-label")

            if latest_val and date:
                date_text = date.text.strip()
                pe_val = float(latest_val.text.strip())
                df = pd.DataFrame([{"date": date_text, "forward_pe": pe_val}])
                return {
                    "date": date_text,
                    "forward_pe": pe_val
                }
            else:
                raise ValueError("ğŸ“› Forward PE ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            

    def get_ttm_pe(self):
        url = "https://www.multpl.com/s-p-500-pe-ratio"

        # options = Options()
        # options.add_argument("--headless")
        # options.add_argument("--disable-gpu")
        # options.add_argument("--no-sandbox")

        # driver = webdriver.Chrome(options=options)
        # driver.get(url)
        # time.sleep(5)  # JS ë¡œë”© ëŒ€ê¸°

        response = requests.get(url)
        soup = BeautifulSoup(response.text, "html.parser")

        # ë‚ ì§œ ì¶”ì¶œ
        timestamp_tag = soup.select_one("#timestamp")
        date = timestamp_tag.get_text(strip=True)

        # PE ê°’ ì¶”ì¶œ
        current_div = soup.select_one("#current")
        
        # <div id="current"> ë‚´ì—ì„œ <b> íƒœê·¸ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” í…ìŠ¤íŠ¸ ë…¸ë“œê°€ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ìˆ«ì
        b_tag = current_div.find("b")
        ttm_pe = b_tag.next_sibling.strip()


        return {
            "date": date,
            "ttm_pe": ttm_pe
        }   

        # soup = BeautifulSoup(driver.page_source, "html.parser")
        # driver.quit()

        # "Last Value" í…ìŠ¤íŠ¸ê°€ ìˆëŠ” td ì°¾ê¸°
        # for td in soup.select("td.col-6"):
        #     if "Last Value" in td.get_text(strip=True):
        #         value_td = td.find_next_sibling("td")
        #         if value_td:
        #             return {
        #                 'date : '
        #             }# value_td.get_text(strip=True)

        return None


    def analyze_pe(self):

        ttm_pe_result = self.get_ttm_pe()
        ttm_pe = ttm_pe_result["ttm_pe"]  # ë¬¸ìì—´

        forward_pe_result = self.update_snp_forwardpe_data()
        forward_pe = forward_pe_result["forward_pe"].iloc[-1]

        # âœ… ë¬¸ìì—´ì¼ ìˆ˜ ìˆëŠ” ttm_peë¥¼ floatë¡œ ë³€í™˜
        ttm_pe = float(ttm_pe) #.replace(",", "").strip()
        forward_pe = float(forward_pe)

        message = f"ğŸ“Š S&P 500 Forward PER: {forward_pe:.2f}\n"
        message += f"ğŸ“Š S&P 500 TTM PER: {ttm_pe:.2f}\n\n"

        # ì ˆëŒ€ì  ê³ í‰ê°€/ì €í‰ê°€ íŒë‹¨
        if forward_pe > 21:
            message += "âš ï¸ Forward PER ê¸°ì¤€ìœ¼ë¡œ **ê³ í‰ê°€** êµ¬ê°„ì…ë‹ˆë‹¤.\n"
        elif forward_pe < 17:
            message += "âœ… Forward PER ê¸°ì¤€ìœ¼ë¡œ **ì €í‰ê°€** êµ¬ê°„ì…ë‹ˆë‹¤.\n"
        else:
            message += "âš–ï¸ Forward PER ê¸°ì¤€ìœ¼ë¡œ **í‰ê·  ë²”ìœ„**ì…ë‹ˆë‹¤.\n"

        # TTM ê¸°ì¤€ ê³ í‰ê°€/ì €í‰ê°€ íŒë‹¨
        if ttm_pe > 20:
            message += "âš ï¸ TTM PER ê¸°ì¤€ìœ¼ë¡œ **ì—­ì‚¬ì  ê³ í‰ê°€** êµ¬ê°„ì…ë‹ˆë‹¤.\n"
        elif ttm_pe < 13:
            message += "âœ… TTM PER ê¸°ì¤€ìœ¼ë¡œ **ì €í‰ê°€** êµ¬ê°„ì…ë‹ˆë‹¤.\n"
        else:
            message += "âš–ï¸ TTM PER ê¸°ì¤€ìœ¼ë¡œ **í‰ê·  ìˆ˜ì¤€**ì…ë‹ˆë‹¤.\n"

        # TTM ëŒ€ë¹„ Forward ë¹„êµ
        if ttm_pe > forward_pe:
            message += "ğŸŸ¢ ì‹œì¥ì€ **í–¥í›„ ì‹¤ì  ê°œì„ **ì„ ê¸°ëŒ€í•˜ëŠ” ë‚™ê´€ì ì¸ íë¦„ì…ë‹ˆë‹¤."
        elif ttm_pe < forward_pe:
            message += "ğŸ”´ ì‹œì¥ì€ **ì‹¤ì  ë‘”í™”**ë¥¼ ë°˜ì˜í•˜ëŠ” ë³´ìˆ˜ì ì¸ íë¦„ì…ë‹ˆë‹¤."
        else:
            message += "âšª ì‹œì¥ì€ í˜„ì¬ ì‹¤ì  ìˆ˜ì¤€ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•  ê²ƒìœ¼ë¡œ ë³´ê³  ìˆìŠµë‹ˆë‹¤."

        return message
    
    def get_vix_index(self):
        '''
        VIX : VIXëŠ” S&P 500 ì§€ìˆ˜ì˜ ì˜µì…˜ ê°€ê²©ì— ê¸°ì´ˆí•˜ë©°, í–¥í›„ 30ì¼ê°„ ì§€ìˆ˜ì˜ í’‹ì˜µì…˜1ê³¼ ì½œì˜µì…˜2 ê°€ì¤‘ ê°€ê²©ì„ ê²°í•©í•˜ì—¬ ì‚°ì •
        í–¥í›„ S&P 500ì§€ìˆ˜ê°€ ì–¼ë§ˆë‚˜ ë³€ë™í•  ê²ƒìœ¼ë¡œ íˆ¬ììë“¤ì´ ìƒê°í•˜ëŠ”ì§€ë¥¼ ë°˜ì˜
        '''
        df = yf.download('^VIX', start="2000-01-01", interval="1d")
        if df.empty:
            print("âŒ VIX ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        # ë°ì´í„°í”„ë ˆì„ì˜ ë©€í‹°ë ˆë²¨ ì»¬ëŸ¼ì„ ë‹¨ì¼ ë ˆë²¨ë¡œ í‰íƒ„í™”
        df.columns = ['_'.join(col) if isinstance(col, tuple) else col for col in df.columns]
        
        df = df.reset_index()
        
        # í•„ìš”í•œ 'Date'ì™€ 'Close_^VIX' ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ê³  ì´ë¦„ì„ ë³€ê²½í•©ë‹ˆë‹¤.
        df = df[['Date', 'Close_^VIX']].rename(columns={'Date': 'date', 'Close_^VIX': 'vix_index'})
        
        df['date'] = pd.to_datetime(df['date'])

        return df
    
    def analyze_vix(self):
        df_vix = self.get_vix_index()
        df_vix = df_vix.sort_values('date')
        latest = df_vix.iloc[-1]

        date = latest['date']
        vix = float(latest['vix'])  # â† ì—¬ê¸°ì„œ float ë³€í™˜

        result = [f"ğŸ“… ê¸°ì¤€ì¼: {date}",
                f"ğŸ“Š VIX ì§€ìˆ˜ (S&P 500 ë³€ë™ì„±): {vix:.2f}"]

        if vix < 12:
            result.append("ğŸ“‰ ê³¼ë„í•œ ë‚™ê´€ ìƒíƒœ â†’ ì €ë³€ë™ì„± í™˜ê²½ (ê³ ì  ê²½ê³„ ê°€ëŠ¥ì„±)")
        elif vix < 20:
            result.append("ğŸŸ¢ ì‹œì¥ì´ ì•ˆì •ì ì¸ ìƒíƒœ (ë‚™ê´€ì  ì‹¬ë¦¬)")
        elif vix < 30:
            result.append("âš ï¸ ì‹œì¥ ë¶ˆí™•ì‹¤ì„± ì¦ê°€ â†’ íˆ¬ìì ì£¼ì˜ í•„ìš”")
        elif vix <40:
            result.append("ğŸŸ  ì‹œì¥ ìœ„í—˜ ìƒíƒœ â†’ ê³¼ë§¤ë„/ì €ì  ë°˜ë“± ê°€ëŠ¥ì„± (ì—­ë°œìƒ ë§¤ìˆ˜ ê³ ë ¤ êµ¬ê°„)")
        else:
            result.append("ğŸ”´ ì‹œì¥ ê·¹ë‹¨ì  ë¶ˆì•ˆ ìƒíƒœ â†’ ê³¼ë§¤ë„/ì €ì  ë°˜ë“± ê°€ëŠ¥ì„± (ì—­ë°œìƒ ë§¤ìˆ˜ ê³ ë ¤ êµ¬ê°„) ")

        return "\n".join(result)
    
    # M2/PER(Forward) ë°ì´í„° ë² ì´ìŠ¤ êµ¬í•  ìˆ˜ ìˆë‚˜?    

    def get_equity_put_call_ratio(self):
        url = 'https://ycharts.com/indicators/cboe_equity_put_call_ratio'

        options = Options()
        options.add_argument("--headless")
        options.add_argument("--disable-gpu")
        options.add_argument("--no-sandbox")

        driver = webdriver.Chrome(options=options)
        driver.get(url)
        time.sleep(5)  # JS ë¡œë”© ëŒ€ê¸°

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        driver.quit()

        # "Last Value" í…ìŠ¤íŠ¸ê°€ ìˆëŠ” td ì°¾ê¸°
        for td in soup.select("td.col-6"):
            if "Last Value" in td.get_text(strip=True):
                value_td = td.find_next_sibling("td")
                if value_td:
                    equity_value = value_td.get_text(strip=True)
                    break

        # âœ… Last Period (ë‚ ì§œ) ì¶”ì¶œ - tr ê¸°ë°˜ìœ¼ë¡œ ë”°ë¡œ íƒìƒ‰
        for row in soup.find_all("tr"):
            tds = row.find_all("td")
            if len(tds) == 2 and "Latest Period" in tds[0].get_text(strip=True):
                date = tds[1].get_text(strip=True)
                break

        if equity_value and date:
            return {
                "date": date,
                "equity_value": equity_value
            }
        else:
            raise ValueError("âŒ Last Value ë˜ëŠ” Last Periodë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


    def get_index_put_call_ratio(self):
        url = 'https://ycharts.com/indicators/cboe_index_put_call_ratio'

        options = Options()
        options.add_argument("--headless")
        options.add_argument("--disable-gpu")
        options.add_argument("--no-sandbox")

        driver = webdriver.Chrome(options=options)
        driver.get(url)
        time.sleep(5)  # JS ë¡œë”© ëŒ€ê¸°

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        driver.quit()

        # "Last Value" í…ìŠ¤íŠ¸ê°€ ìˆëŠ” td ì°¾ê¸°
        for td in soup.select("td.col-6"):
            if "Last Value" in td.get_text(strip=True):
                value_td = td.find_next_sibling("td")
                if value_td:
                    index_value = value_td.get_text(strip=True)
                    break

        # âœ… Last Period (ë‚ ì§œ) ì¶”ì¶œ - tr ê¸°ë°˜ìœ¼ë¡œ ë”°ë¡œ íƒìƒ‰
        for row in soup.find_all("tr"):
            tds = row.find_all("td")
            if len(tds) == 2 and "Latest Period" in tds[0].get_text(strip=True):
                date = tds[1].get_text(strip=True)
                break

        if index_value and date:
            return {
                "date": date,
                "equity_value": index_value
            }
        else:
            raise ValueError("âŒ Last Value ë˜ëŠ” Last Periodë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def update_putcall_ratio(self):
        '''
        ë¡œì»¬ì— ì €ì¥ëœ PUT CALL RATIO íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
        '''
        try:
            putcall_df = self.put_call_ratio_updater.update_csv()
            print("âœ… PutCall Ratio CSV ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        except Exception as e:
            print("ğŸ“› PutCall Ratio ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:", e)

        return putcall_df  


    def check_put_call_ratio_warning(self):
        """
        í’‹ì½œ ë ˆì´í‹°ì˜¤ ë°ì´í„°ë¥¼ ë°›ì•„ì™€ì„œì„œ
        ë§¤ìˆ˜ í˜¹ì€ ë§¤ë„ ì‹œì ì„ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜

        ratio_type : equity, index ë‘˜ ì¤‘ í•˜ë‚˜ ì…ë ¥
        """

        put_call_ratio = self.update_putcall_ratio()
        putcall_data_today = put_call_ratio.iloc[-1]
        print("data : ", putcall_data_today)
        date = putcall_data_today['date']
        value = putcall_data_today['equity_value']

        # ê°„ë‹¨í•œ ì‹œê·¸ë„ íŒë‹¨

        result = [f"ğŸ“… ê¸°ì¤€ì¼: {date}",
                f"ğŸ“Š Equity_putcall_ratio ì§€ìˆ˜ : {value:.2f}"]
    
        if value > 1.5:
            result.append("ğŸ“‰ Equity: ê³µí¬ì‹¬ ê³¼ë‹¤ â†’ ë°˜ë“± ê°€ëŠ¥ì„± (ë§¤ìˆ˜ ì‹œì  íƒìƒ‰)")
        elif value < 0.5:
            result.append("ğŸš¨ Equity: ê³¼ì—´ íƒìš• ìƒíƒœ â†’ ë§¤ë„ ê²½ê³  ë˜ëŠ” ì¡°ì • ê°€ëŠ¥ì„±")
        else:
            result.append("âš–ï¸ Equity: ì¤‘ë¦½ êµ¬ê°„")

        return "\n".join(result)

    def get_nfci(self):
        '''
        FEDê°€ ë°œí‘œí•˜ëŠ” ì§€í‘œë¥¼ ê³µì‹ì ìœ¼ë¡œ FREDì— ì œê³µí•˜ëŠ” í˜•íƒœ
        ìƒìŠ¹ì‹œ ê²½ê¸°íšŒë³µ/í™•ì¥ ì˜ë¯¸, í•˜ë½ì‹œ ê²½ê¸° ë‘”í™”/ì¹¨ì²´ ì˜ë¯¸
        '''
        
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'NFCI',
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '2000-01-01'
        }
        response = requests.get(url, params=params)
        data = response.json()
        df = pd.DataFrame(data['observations'])
        df['date'] = pd.to_datetime(df['date'])
        df['NFCI_index'] = pd.to_numeric(df['value'], errors='coerce')
        
        return df

    def analyze_nfci(self):
        '''
        nfci < -0.5 ê¸ˆìœµì—¬ê±´ ì™„í™”
        nfci > 0.5 ê¸ˆìœµê¸´ì¶•
        '''
        df = self.get_nfci()

        date = df['date'].iloc[-1]
        nfci_value = df['NFCI_index'].iloc[-1] 

        result = []

        if nfci_value < -0.5:
            result.append("âœ… ìœ ë™ì„± í’ë¶€ êµ¬ê°„ìœ¼ë¡œ ê¾¸ì¤€í•œ ìƒìŠ¹ ê²½í–¥")
        elif nfci_value > 0.5:
            result.append("ğŸš¨ ê·¹ë‹¨ì  ê¸´ì¶• êµ¬ê°„, ì†ì‹¤ ë° ë†’ì€ ë³€ë™ì„±")
        else:
            result.append("âš–ï¸ ì¤‘ë¦½ êµ¬ê°„")

        return {
            "date" : date,
            "value" : nfci_value,
            "comment" : result
        }


    def get_dollar_index(self):   #period="26y"
        '''
        FRED API : ë‹¬ëŸ¬ ì¸ë±ìŠ¤
        '''

        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id' : 'DTWEXBGS', # ë‹¬ëŸ¬ì¸ë±ìŠ¤
            'api_key' : self.fred_api_key,
            'file_type' : 'json',
            'observation_start' : '2000-01-01' # ì‹œì‘ì¼(ì›í•˜ëŠ” ë‚ ì§œì§œ)
        }

        try:
            response = requests.get(url, params= params, timeout=10)
            response.raise_for_status() # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
            data = response.json()

            if 'observations' not in data:
                raise ValueError(F"'observations' í‚¤ê°€ ì—†ìŒ : {data}")

            # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
            df = pd.DataFrame(data['observations'])
            df['date'] = pd.to_datetime(df['date'])
            df['value'] = pd.to_numeric(df['value'], errors= 'coerce')

            return df
        
        except Exception as e:
            print(f"[ERROR] FRED API í˜¸ì¶œ ì‹¤íŒ¨ : {e}")
            return pd.DataFrame()
      
        # """
        # ë‹¬ëŸ¬ ì¸ë±ìŠ¤ (DXY) ë°ì´í„°ë¥¼ yfinanceì—ì„œ ê°€ì ¸ì™€ì„œ DataFrameìœ¼ë¡œ ë°˜í™˜
        # period: '1d', '5d', '1mo', '3mo', '6mo', '1y', etc.
        # """
        # ticker = "DX-Y.NYB"  # yfinance ìƒ DXY ì‹¬ë³¼ (ICE ì„ ë¬¼ì‹œì¥ìš©)
        # df = yf.download(ticker, start='2020-01-01', interval="1d", progress=False)
        # df = df.reset_index()

        # # ì»¬ëŸ¼ ì •ë¦¬ : ì»¬ëŸ¼ ì´ë¦„ì„ í‘œì¤€í™”
        # df = df[['Date', 'Close']].rename(columns={'Date': 'date', 'Close': 'dxy'})
        # df['date'] = pd.to_datetime(df['date'])
        # return df
    
    # Clear - ì‹¤ì‹œê°„ ë°ì´í„°
    def get_euro_index(self):
        '''
        FRED API : ìœ ë¡œ ì¸ë±ìŠ¤
        '''

        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id' : 'DEXUSEU', # 10ë…„ë¬¼ êµ­ì±„ ê¸ˆë¦¬
            'api_key' : self.fred_api_key,
            'file_type' : 'json',
            'observation_start' : '2000-01-01' # ì‹œì‘ì¼(ì›í•˜ëŠ” ë‚ ì§œì§œ)
        }

        try:
            response = requests.get(url, params= params, timeout=10)
            response.raise_for_status() # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
            data = response.json()

            if 'observations' not in data:
                raise ValueError(F"'observations' í‚¤ê°€ ì—†ìŒ : {data}")

            # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
            df = pd.DataFrame(data['observations'])
            df['date'] = pd.to_datetime(df['date'])
            df['value'] = pd.to_numeric(df['value'], errors= 'coerce')

            return df
        
        except Exception as e:
            print(f"[ERROR] FRED API í˜¸ì¶œ ì‹¤íŒ¨ : {e}")
            return pd.DataFrame()
        
    # Clear - ì‹¤ì‹œê°„ ë°ì´í„°
    def get_yen_index(self):
        '''
        FRED API : ì—”í™” ì¸ë±ìŠ¤
        '''

        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id' : 'DEXJPUS', # 10ë…„ë¬¼ êµ­ì±„ ê¸ˆë¦¬
            'api_key' : self.fred_api_key,
            'file_type' : 'json',
            'observation_start' : '2000-01-01' # ì‹œì‘ì¼(ì›í•˜ëŠ” ë‚ ì§œì§œ)
        }

        try:
            response = requests.get(url, params= params, timeout=10)
            response.raise_for_status() # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
            data = response.json()

            if 'observations' not in data:
                raise ValueError(F"'observations' í‚¤ê°€ ì—†ìŒ : {data}")

            # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
            df = pd.DataFrame(data['observations'])
            df['date'] = pd.to_datetime(df['date'])
            df['value'] = pd.to_numeric(df['value'], errors= 'coerce')

            return df
        
        except Exception as e:
            print(f"[ERROR] FRED API í˜¸ì¶œ ì‹¤íŒ¨ : {e}")
            return pd.DataFrame()
    

    # Clear - ì›”ë³„ ë°ì´í„° - 1ì›” ë”œë ˆì´
    def get_copper_price_F(self):
        # HG=F: High Grade Copper Futures (êµ¬ë¦¬ ì„ ë¬¼)
        df = yf.download("HG=F", start="2000-01-01", interval="1d", group_by="ticker")

        # 1) MultiIndex â†’ ë‹¨ì¼ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        if isinstance(df.columns, pd.MultiIndex):
            df.columns = df.columns.droplevel(0)  # 'CL=F' ë ˆë²¨ ì œê±° â†’ Price, Close, High...
            # ë˜ëŠ” df.columns = df.columns.droplevel(0) í•˜ë©´ 'Close', 'High' ë“±ë§Œ ë‚¨ê¹€
            # ì›í•˜ëŠ” ë ˆë²¨ ì„ íƒ

        # 2) ì¸ë±ìŠ¤(Date)ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ
        df = df.reset_index()
        
        return df



        # '''
        # FRED API : êµ¬ë¦¬ ì¸ë±ìŠ¤
        # '''

        # url = 'https://api.stlouisfed.org/fred/series/observations'
        # params = {
        #     'series_id' : 'PCOPPUSDM', # 10ë…„ë¬¼ êµ­ì±„ ê¸ˆë¦¬
        #     'api_key' : self.fred_api_key,
        #     'file_type' : 'json',
        #     'observation_start' : '2000-01-01' # ì‹œì‘ì¼(ì›í•˜ëŠ” ë‚ ì§œì§œ)
        # }

        # try:
        #     response = requests.get(url, params= params, timeout=10)
        #     response.raise_for_status() # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
        #     data = response.json()

        #     if 'observations' not in data:
        #         raise ValueError(F"'observations' í‚¤ê°€ ì—†ìŒ : {data}")

        #     # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
        #     df = pd.DataFrame(data['observations'])
        #     df['date'] = pd.to_datetime(df['date'])
        #     df['value'] = pd.to_numeric(df['value'], errors= 'coerce')

        #     return df
        
        # except Exception as e:
        #     print(f"[ERROR] FRED API í˜¸ì¶œ ì‹¤íŒ¨ : {e}")
        #     return pd.DataFrame()
    

    def get_gold_price_F(self):
        '''
        FRED API : ê¸ˆ ì¸ë±ìŠ¤
        '''

        df = yf.download("GC=F", start="2000-01-01", interval="1d", group_by="ticker")

        # 1) MultiIndex â†’ ë‹¨ì¼ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        if isinstance(df.columns, pd.MultiIndex):
            df.columns = df.columns.droplevel(0)  # 'CL=F' ë ˆë²¨ ì œê±° â†’ Price, Close, High...
            # ë˜ëŠ” df.columns = df.columns.droplevel(0) í•˜ë©´ 'Close', 'High' ë“±ë§Œ ë‚¨ê¹€
            # ì›í•˜ëŠ” ë ˆë²¨ ì„ íƒ

        # 2) ì¸ë±ìŠ¤(Date)ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ
        df = df.reset_index()
        
        return df


        # url = 'https://api.stlouisfed.org/fred/series/observations'
        # params = {
        #     'series_id' : 'IR14270', # ë‰´ìš• ê¸°ì¤€ ê¸ˆê°€ê²©
        #     'api_key' : self.fred_api_key,
        #     'file_type' : 'json',
        #     'observation_start' : '2000-01-01' # ì‹œì‘ì¼(ì›í•˜ëŠ” ë‚ ì§œì§œ)
        # }

        # try:
        #     response = requests.get(url, params= params, timeout=10)
        #     response.raise_for_status() # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
        #     data = response.json()

        #     if 'observations' not in data:
        #         raise ValueError(F"'observations' í‚¤ê°€ ì—†ìŒ : {data}")

        #     # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
        #     df = pd.DataFrame(data['observations'])
        #     df['date'] = pd.to_datetime(df['date'])
        #     df['value'] = pd.to_numeric(df['value'], errors= 'coerce')

        #     return df
        
        # except Exception as e:
        #     print(f"[ERROR] FRED API í˜¸ì¶œ ì‹¤íŒ¨ : {e}")
        #     return pd.DataFrame()


    def get_oil_price_F(self):
        '''
        FRED API : ë¯¸êµ­ ì„œë¶€í…ì‚¬ìŠ¤ì‚° ì›ìœ  ì„ ë¬¼
        '''

        df = yf.download("CL=F", start="2000-01-01", interval="1d", group_by="ticker")

        # 1) MultiIndex â†’ ë‹¨ì¼ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        if isinstance(df.columns, pd.MultiIndex):
            df.columns = df.columns.droplevel(0)  # 'CL=F' ë ˆë²¨ ì œê±° â†’ Price, Close, High...
            # ë˜ëŠ” df.columns = df.columns.droplevel(0) í•˜ë©´ 'Close', 'High' ë“±ë§Œ ë‚¨ê¹€
            # ì›í•˜ëŠ” ë ˆë²¨ ì„ íƒ

        # 2) ì¸ë±ìŠ¤(Date)ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ
        df = df.reset_index()
        
        return df

    def get_high_yield_spread(self):
        url = 'https://api.stlouisfed.org/fred/series/observations'
        params = {
            'series_id': 'BAMLH0A0HYM2',  # í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œ
            'api_key': self.fred_api_key,
            'file_type': 'json',
            'observation_start': '2000-01-01'
        }
        response = requests.get(url, params=params)
        data = response.json()
        df = pd.DataFrame(data['observations'])
        df['date'] = pd.to_datetime(df['date'])
        df['value'] = pd.to_numeric(df['value'], errors='coerce')
        return df
    

    def check_high_yield_spread_warning(self):
        """
        í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œ ë°ì´í„°í”„ë ˆì„ì„ ë°›ì•„
        ìµœì‹ ê°’ê³¼ ì „ì¼ ëŒ€ë¹„ ë³€í™”ìœ¨ì„ ì²´í¬í•´ ê²½ê³ ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
        """
        df = self.get_high_yield_spread()
        df = df.dropna(subset=['value'])  # NaN ì œê±°
        df = df.sort_values('date')       # ë‚ ì§œìˆœ ì •ë ¬
        
        today_row = df.iloc[-1]
        date = today_row["date"]
        yesterday_row = df.iloc[-2]
        
        today_value = today_row['value']
        yesterday_value = yesterday_row['value']
        
        change = today_value - yesterday_value  # ë³€í™”ëŸ‰ (í¬ì¸íŠ¸)

        messages = []
        messages.append(f"ğŸ” í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œ ì˜¤ëŠ˜({today_row['date'].date()}) ê°’: {today_value:.2f}%")
        messages.append(f"ğŸ” ì–´ì œ({yesterday_row['date'].date()}) ëŒ€ë¹„ ë³€í™”: {change:+.2f}p")
        
        if today_value >= 7:
            messages.append("ğŸš¨ í•˜ë½ì¥ ê²½ê³ : í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œê°€ 7%ë¥¼ ë„˜ì—ˆìŠµë‹ˆë‹¤!")
        elif today_value >= 5:
            messages.append("âš ï¸ ì¡°ì •ì¥ ê²½ê³ : í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œê°€ 5%ë¥¼ ë„˜ì—ˆìŠµë‹ˆë‹¤!")
        
        if change >= 0.5:
            messages.append("âš¡ ê¸‰ë“± ê²½ê³ : í•˜ë£¨ ë§Œì— ìŠ¤í”„ë ˆë“œê°€ 0.5%p ì´ìƒ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤!")
        
        if (today_value < yesterday_value) and (today_value >= 5):
            messages.append("ğŸ“ˆ ì €ì  ë§¤ìˆ˜ ê°€ëŠ¥ì„± ì‹ í˜¸: ìŠ¤í”„ë ˆë“œê°€ êº¾ì´ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤!")

        return {
            "date" : date,
            'value' : today_value,
            'message' : messages
        }


    def get_ma_above_ratio(self):

        url = "https://www.barchart.com/stocks/momentum"
    
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        
        try:
            response = requests.get(url, headers=headers)
            response.raise_for_status() # HTTP ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì˜ˆì™¸ ë°œìƒ

            soup = BeautifulSoup(response.text, 'html.parser')

            ma_50_day = None
            ma_200_day = None

            # 'Market Average'ë¼ëŠ” í…ìŠ¤íŠ¸ë¥¼ ê°€ì§„ <h5> íƒœê·¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            h5_market_average = soup.find('h5', string='Market Average')
            
            market_average_table = None
            if h5_market_average:
                # <h5> íƒœê·¸ì˜ ë¶€ëª¨ (class="block-title"ì¸ div)ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
                block_title_div = h5_market_average.find_parent('div', class_='block-title')
                
                if block_title_div:
                    # 'block-title' divì˜ ë°”ë¡œ ë‹¤ìŒ í˜•ì œ ìš”ì†Œ ì¤‘ì—ì„œ 'table-wrapper' í´ë˜ìŠ¤ë¥¼ ê°€ì§„ divë¥¼ ì°¾ìŠµë‹ˆë‹¤.
                    table_wrapper = block_title_div.find_next_sibling('div', class_='table-wrapper')
                    
                    if table_wrapper:
                        # 'table-wrapper' ì•ˆì—ì„œ 'table' íƒœê·¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
                        market_average_table = table_wrapper.find('table')
                    else:
                        print("ERROR: 'table-wrapper' divë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    print("ERROR: 'Market Average' <h5> íƒœê·¸ì˜ ë¶€ëª¨ 'block-title' divë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print("ERROR: 'Market Average' <h5> íƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


            if market_average_table:
                # í…Œì´ë¸” í—¤ë” ì¶”ì¶œ (ì²« ë²ˆì§¸ í–‰ì˜ th íƒœê·¸ë“¤)
                header_row = market_average_table.find('tr') # í…Œì´ë¸”ì˜ ì²« ë²ˆì§¸ tr
                if header_row:
                    headers = [th.get_text(strip=True) for th in header_row.find_all('th')]
                    # print(f"ì¶”ì¶œëœ í—¤ë”: {headers}") # ë””ë²„ê¹…ìš©

                    # í…Œì´ë¸”ì˜ ëª¨ë“  í–‰(<tr>)ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. tbodyê°€ ìˆë“  ì—†ë“  ë™ì‘í•˜ë„ë¡ í•©ë‹ˆë‹¤.
                    rows_in_table = market_average_table.find_all('tr')
                    
                    today_row = None
                    # ê°€ì ¸ì˜¨ í–‰ë“¤ì„ ìˆœíšŒí•˜ë©° 'Today' í–‰ì„ ì°¾ìŠµë‹ˆë‹¤.
                    for row in rows_in_table:
                        # ì²« ë²ˆì§¸ tdê°€ 'Today'ì¸ ê²½ìš°ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
                        first_cell = row.find('td', class_='text-left') 
                        if first_cell and first_cell.get_text(strip=True) == 'Today':
                            today_row = row
                            break
                    
                    if today_row:
                        # 'Today' í–‰ì˜ ëª¨ë“  ë°ì´í„° ì…€(td íƒœê·¸ë“¤) ì¶”ì¶œ
                        # ì²« ë²ˆì§¸ td(Today)ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ td ê°’ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
                        data_cells = [td.get_text(strip=True) for td in today_row.find_all('td')[1:]] # [1:]ë¡œ 'Today' ì…€ ì œì™¸
                        # print(f"Today í–‰ì˜ ë°ì´í„°: {data_cells}") # ë””ë²„ê¹…ìš©

                        # í—¤ë” ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ 50-Day MAì™€ 200-Day MA ê°’ ì¶”ì¶œ
                        try:
                            index_50_day_ma_header = headers.index("50-Day MA")
                            ma_50_day = data_cells[index_50_day_ma_header -1] 

                        except ValueError:
                            print("í—¤ë”ì—ì„œ '50-Day MA'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        except IndexError:
                            print("50-Day MAì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¸ë±ìŠ¤ ì˜¤ë¥˜.")

                        try:
                            index_200_day_ma_header = headers.index("200-Day MA")
                            ma_200_day = data_cells[index_200_day_ma_header -1]
                        except ValueError:
                            print("í—¤ë”ì—ì„œ '200-Day MA'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        except IndexError:
                            print("200-Day MAì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¸ë±ìŠ¤ ì˜¤ë¥˜.")

                    else:
                        print("MARKET AVERAGE í…Œì´ë¸”ì—ì„œ 'Today' í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    print("MARKET AVERAGE í…Œì´ë¸”ì—ì„œ í—¤ë” í–‰(<tr>)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print("MARKET AVERAGE í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            return {
                "date": datetime.today().strftime("%Y-%m-%d"),
                "50-day MA": ma_50_day,
                "200-day MA": ma_200_day
            }

        except requests.exceptions.RequestException as e:
            print(f"ì›¹ í˜ì´ì§€ì— ì ‘ì†í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None, None
        except Exception as e:
            print(f"ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None, None


    def interpret_ma_above_ratio(self):
        """
        ì´í‰ì„  ìƒíšŒ ë¹„ìœ¨ í•´ì„:
        - 30% ë¯¸ë§Œ: ë§¤ìˆ˜ ì¶”ì²œ
        - 70% ì´ìƒ: ë§¤ë„ ì¶”ì²œ
        - ë‹¨ê¸°ì : 50ì¼ / ì¥ê¸°ì : 200ì¼

        Parameters:
            result (dict): {'date': 'YYYY-MM-DD', '50-day MA': '62.72%', '200-day MA': '52.33%'}

        Returns:
            list: ì¶”ì²œ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ (í˜„ì¬ ìˆ˜ì¹˜ í¬í•¨)
        """

        data = self.get_ma_above_ratio()
        
        messages = []

        # 50-day MA í•´ì„
        ma_50 = float(data.get("50-day MA", "0%").replace("%", ""))
        if ma_50 < 30:
            messages.append(f"âœ… ë‹¨ê¸°ì  ë§¤ìˆ˜ ì¶”ì²œ: 50ì¼ ì´í‰ì„  ìƒíšŒ ë¹„ìœ¨ì´ {ma_50:.2f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤.")
        elif ma_50 >= 70:
            messages.append(f"ğŸš¨ ë‹¨ê¸°ì  ë§¤ë„ ì‹ í˜¸: 50ì¼ ì´í‰ì„  ìƒíšŒ ë¹„ìœ¨ì´ {ma_50:.2f}%ë¡œ ê³¼ì—´ êµ¬ê°„ì…ë‹ˆë‹¤.")

        # 200-day MA í•´ì„
        ma_200 = float(data.get("200-day MA", "0%").replace("%", ""))
        if ma_200 < 30:
            messages.append(f"âœ… ì¥ê¸°ì  ë§¤ìˆ˜ ì¶”ì²œ: 200ì¼ ì´í‰ì„  ìƒíšŒ ë¹„ìœ¨ì´ {ma_200:.2f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤.")
        elif ma_200 >= 70:
            messages.append(f"ğŸš¨ ì¥ê¸°ì  ë§¤ë„ ì‹ í˜¸: 200ì¼ ì´í‰ì„  ìƒíšŒ ë¹„ìœ¨ì´ {ma_200:.2f}%ë¡œ ê³¼ì—´ êµ¬ê°„ì…ë‹ˆë‹¤.")

        # ì‹ í˜¸ ì—†ì„ ë•Œ
        if not messages:
            messages.append(f"âš–ï¸ í˜„ì¬ëŠ” ëšœë ·í•œ ë§¤ìˆ˜/ë§¤ë„ ì‹ í˜¸ê°€ ì—†ìŠµë‹ˆë‹¤. (50ì¼: {ma_50:.2f}%, 200ì¼: {ma_200:.2f}%)")

        return messages
    

    def analyze_disparity_with_ma(self):
        """
        50ì¼, 200ì¼ ì´ë™í‰ê·  ê¸°ì¤€ ì´ê²©ë„ ê³„ì‚° ë° í•´ì„

        Returns:
            dict : {
                'date': latest_date,
                'sp500_close': latest_price,
                '50-day MA': latest_ma_50,
                '200-day MA': latest_ma_200,
                '50-day disparity (%)': value,
                '200-day disparity (%)': value,
                'short_term_status': í•´ì„ í…ìŠ¤íŠ¸,
                'long_term_status': í•´ì„ í…ìŠ¤íŠ¸
            }
        """
        df = self.get_sp500()
        df = df.copy()
        df['MA_50'] = df['sp500_close'].rolling(window=50).mean()
        df['MA_200'] = df['sp500_close'].rolling(window=200).mean()
        df.dropna(inplace=True)

        latest = df.iloc[-1]
        date = latest['date']
        close = latest['sp500_close']
        ma_50 = latest['MA_50']
        ma_200 = latest['MA_200']

        disparity_50 = ((close - ma_50) / ma_50) * 100
        disparity_200 = ((close - ma_200) / ma_200) * 100

        def interpret_disparity_50(val):
            if val <= -5:
                return "ğŸ“‰ ë‹¨ê¸° ì¹¨ì²´ êµ¬ê°„"
            elif val <= 5:
                return "âš–ï¸ ì¤‘ë¦½ êµ¬ê°„"
            elif val <= 10:
                return "âš ï¸ ë‹¨ê¸° ê³¼ì—´"
            else:
                return "ğŸš¨ ê·¹ë‹¨ì  ë‹¨ê¸° ê³¼ì—´"

        def interpret_disparity_200(val):
            if val <= -10:
                return "ğŸ“‰ ì¥ê¸° ì¹¨ì²´ êµ¬ê°„"
            elif val <= 0:
                return "âš–ï¸ ì¥ê¸° ì¤‘ë¦½(ì•½ì„¸)"
            elif val <= 10:
                return "âš–ï¸ ì¥ê¸° ì¤‘ë¦½(ê°•ì„¸)"
            elif val <= 20:
                return "âš ï¸ ì¥ê¸° ê³¼ì—´"
            else:
                return "ğŸ”¥ ê´‘ê¸° êµ¬ê°„"

        return {
            'date': date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date),
            'sp500_close': round(close, 2),
            '50-day MA': round(ma_50, 2),
            '200-day MA': round(ma_200, 2),
            '50-day disparity (%)': round(disparity_50, 2),
            '200-day disparity (%)': round(disparity_200, 2),
            'short_term_status': interpret_disparity_50(disparity_50),
            'long_term_status': interpret_disparity_200(disparity_200)
        }


      # Clear ì£¼ë³„ ë°ì´í„° - 1ì£¼ì¼ ë”œë ˆì´
    def update_bull_bear_spread(self):
        '''
        ë¡œì»¬ì— ì €ì¥ëœ bull_bear_spread íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
        '''
        try:
            bb_spread = self.bull_bear_spread_updater.update_csv()
            print("âœ… Bull Bear Spread CSV ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        except Exception as e:
            print("ğŸ“› Bull Bear Spread ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:", e)
        return bb_spread


    def get_bull_bear_spread(self):

        url = "https://ycharts.com/indicators/us_investor_sentiment_bull_bear_spread"

        options = Options()
        options.add_argument("--headless")
        options.add_argument("--disable-gpu")
        options.add_argument("--no-sandbox")

        driver = webdriver.Chrome(options=options)
        driver.get(url)
        time.sleep(5)  # JS ë¡œë”© ëŒ€ê¸°

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        driver.quit()

        # "Last Value" í…ìŠ¤íŠ¸ê°€ ìˆëŠ” td ì°¾ê¸°
        for td in soup.select("td.col-6"):
            if "Last Value" in td.get_text(strip=True):
                value_td = td.find_next_sibling("td")
                if value_td:
                    bull_bear_spread = value_td.get_text(strip=True)
                    break

        # âœ… Last Period (ë‚ ì§œ) ì¶”ì¶œ - tr ê¸°ë°˜ìœ¼ë¡œ ë”°ë¡œ íƒìƒ‰
        for row in soup.find_all("tr"):
            tds = row.find_all("td")
            if len(tds) == 2 and "Latest Period" in tds[0].get_text(strip=True):
                date = tds[1].get_text(strip=True)
                break

        if bull_bear_spread and date:
            return {
                "date": date,
                "spread": bull_bear_spread
            }
        else:
            raise ValueError("âŒ Last Value ë˜ëŠ” Last Periodë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        

    def generate_bull_bear_signals(self):
        """
        Bull-Bear Spread ê¸°ì¤€ íˆ¬ì ì „ëµ

        ë§¤ìˆ˜: spread < -20
        ë§¤ë„: spread > 40
        """
        df = self.update_bull_bear_spread()
        df = df.copy()
        df_latest = df.iloc[-1]
        df_latest["buy_signal"] = df_latest["spread"] < -0.2
        df_latest["sell_signal"] = df_latest["spread"] > 0.4

        result = []

        if df_latest['sell_signal'] == True:
            result.append("ğŸ”¥ ê´‘ê¸° êµ¬ê°„(íˆ¬ììë“¤ì´ ì§€ë‚˜ì¹˜ê²Œ ë‚™ê´€ì )")
        elif df_latest['buy_signal'] == True:
            result.append("âœ… ì—­ë°œìƒ ë§¤ìˆ˜ ê¸°íšŒ(íˆ¬ììë“¤ì´ ê³µí¬ë¥¼ ëŠë‚Œ)")
        else:
            result.append("âš–ï¸ íŒë‹¨ ìœ ë³´(ì‹œì¥ í˜¼ì¡° ë˜ëŠ” ë¬´ê´€ì‹¬)")
       
        return {
            'date' : df_latest['date'],
            'spread' : df_latest['spread'],
            'comment' : result

        }

    # 40ì˜ ë²•ì¹™

if __name__ == "__main__":
    crawler = MacroCrawler()


    # md_data = crawler.update_margin_debt_data()
    # pmi_data = crawler.update_ism_pmi_data()
    # fp_data = crawler.update_snp_forwardpe_data()
    # pc_data = crawler.update_putcall_ratio()
    # bb_data = crawler.update_bull_bear_spread()

    data = crawler.update_ism_pmi_data()
    print(data)
