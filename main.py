from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from macro_crawling import MacroCrawler
import pandas as pd
import matplotlib.pyplot as plt
from io import BytesIO
import traceback
import os
import matplotlib as mpl
import matplotlib.font_manager as fm

font_path = os.path.join("fonts", "NanumGothic.ttf")
if os.path.exists(font_path):
    fm.fontManager.addfont(font_path)
    font_prop = fm.FontProperties(fname=font_path)
    mpl.rcParams["font.family"] = font_prop.get_name()
    mpl.rcParams["axes.unicode_minus"] = False
    print(f"âœ… í°íŠ¸ ë“±ë¡ ì™„ë£Œ: {font_prop.get_name()}")
else:
    print("âŒ NanumGothic.ttf í°íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")


app = FastAPI()

@app.get("/")
def root():
    return {"message": "ğŸ“ˆ Macro Signal API"}

@app.get("/check-today-signal")
def check_today_signal():
    try:
        crawler = MacroCrawler()
        today = pd.Timestamp.today().normalize()
        today_month = today.to_period("M")

        result = {
            "date": str(today.date()),
            "zscore_signal": [],
            "mdyoy_signal": []
        }

        df = crawler.merge_m2_margin_sp500_abs()

        # Z-Score
        zscore_df = crawler.generate_zscore_trend_signals(df)
        zscore_df["action_month"] = zscore_df["action_date"].dt.to_period("M")
        zscore_today = zscore_df[zscore_df["action_month"] == today_month]

        for _, row in zscore_today.iterrows():
            result["zscore_signal"].append({
                "signal": row["signal"],
                "original_signal_date": str(row["original_signal_date"].date()),
                "action_date": str(row["action_date"].date()),
                "expected_return_3m": round(row["return_3m"] * 100, 2)
            })

        # Margin Debt YoY
        mdyoy_df = crawler.generate_mdyoy_signals(df)
        mdyoy_df["action_month"] = mdyoy_df["action_date"].dt.to_period("M")
        mdyoy_today = mdyoy_df[mdyoy_df["action_month"] == today_month]
        mdyoy_filtered = mdyoy_today[mdyoy_today["buy_signal"] | mdyoy_today["sell_signal"]]

        for _, row in mdyoy_filtered.iterrows():
            signal_type = "BUY" if row["buy_signal"] else "SELL"
            result["mdyoy_signal"].append({
                "signal": signal_type,
                "signal_date": str(row["signal_date"].date()),
                "action_date": str(row["action_date"].date())
            })

        return result

    except Exception as e:
        print("âŒ /check-today-signal ì—ëŸ¬:", e)
        traceback.print_exc()
        return {"error": str(e)}

@app.get("/plot-mdyoy-graph")
def plot_mdyoy_graph():

    try:
        crawler = MacroCrawler()
        df = crawler.merge_m2_margin_sp500_abs()
        df = crawler.generate_mdyoy_signals(df)

        buf = BytesIO()
        crawler.plot_sp500_with_mdyoy_signals_and_graph(df, save_to=buf)
        buf.seek(0)

        return StreamingResponse(buf, media_type="image/png")
    except Exception as e:
        print("âŒ /plot-mdyoy-graph ì—ëŸ¬:", e)
        traceback.print_exc()
        return {"error": str(e)}

@app.get("/plot-zscore-graph")
def plot_zscore_graph():

    try:
        crawler = MacroCrawler()
        df = crawler.merge_m2_margin_sp500_abs()

        buf = BytesIO()
        crawler.plot_sp500_with_signals_and_graph(df, save_to=buf)
        buf.seek(0)

        return StreamingResponse(buf, media_type="image/png")
    except Exception as e:
        print("âŒ /plot-zscore-graph ì—ëŸ¬:", e)
        traceback.print_exc()
        return {"error": str(e)}

@app.get("/signal-history")
def signal_history():
    try:
        crawler = MacroCrawler()
        df = crawler.merge_m2_margin_sp500_abs()

        result = {
            "zscore_signals": [],
            "mdyoy_signals": []
        }

        zscore_df = crawler.generate_zscore_trend_signals(df)
        for _, row in zscore_df.iterrows():
            result["zscore_signals"].append({
                "signal": row["signal"],
                "original_signal_date": str(row["original_signal_date"].date()),
                "action_date": str(row["action_date"].date()),
                "expected_return_3m": round(row["return_3m"] * 100, 2)
            })

        mdyoy_df = crawler.generate_mdyoy_signals(df)
        filtered_df = mdyoy_df[mdyoy_df["buy_signal"] | mdyoy_df["sell_signal"]]
        for _, row in filtered_df.iterrows():
            signal_type = "BUY" if row["buy_signal"] else "SELL"
            result["mdyoy_signals"].append({
                "signal": signal_type,
                "signal_date": str(row["signal_date"].date()),
                "action_date": str(row["action_date"].date())
            })

        return result
    except Exception as e:
        print("âŒ /signal-history ì—ëŸ¬:", e)
        traceback.print_exc()
        return {"error": str(e)}

@app.get("/rate-correlations")
def rate_correlations(show_plot: bool = False):
    """
    S&P500ê³¼ ì‹¤ì§ˆ 10Y ê¸ˆë¦¬ ë° ê¸ˆë¦¬ìŠ¤í”„ë ˆë“œ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„.
    show_plot=Trueì´ë©´ íˆíŠ¸ë§µ ì´ë¯¸ì§€ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë°˜í™˜.
    """
    try:
        crawler = MacroCrawler()
        result = crawler.analyze_rate_correlations(show_plot=False)

        # show_plot íŒŒë¼ë¯¸í„°ê°€ Trueì´ë©´ íˆíŠ¸ë§µì„ ê·¸ë ¤ StreamingResponseë¡œ ë°˜í™˜
        if show_plot:
            sp500   = crawler.get_sp500()
            df_10y  = crawler.get_10years_treasury_yeild()
            df_2y   = crawler.get_2years_treasury_yeild()
            cpi_yoy = crawler.get_cpi_yoy()
            fed     = crawler.get_fed_funds_rate()

            # ì›” ë‹¨ìœ„ ë‚ ì§œ í†µì¼
            for df in [sp500, df_10y, df_2y, cpi_yoy, fed]:
                df['date'] = pd.to_datetime(df['date']).dt.to_period('M').dt.to_timestamp()

            # ë³‘í•© ë° ìƒê´€í–‰ë ¬ ê³„ì‚°(ìœ„ì—ì„œ ìˆ˜ì •í•œ ì»¬ëŸ¼ ìƒì„± í¬í•¨)
            df = sp500.merge(df_10y[['date','value']], on='date').rename(columns={'value':'10y'})
            df = df.merge(df_2y[['date','value']], on='date').rename(columns={'value':'2y'})
            df = df.merge(cpi_yoy[['date','CPI YOY(%)']], on='date').rename(columns={'CPI YOY(%)':'cpi_yoy'})
            df = df.merge(fed[['date','fed_funds_rate']], on='date')
            df['real_10y'] = df['10y'] - df['cpi_yoy']
            df['spread']   = df['10y'] - df['2y']
            df['ffr_vs_2y']= df['fed_funds_rate'] - df['2y']

            corr = df[['sp500_close','real_10y','spread']].corr()

            # íˆíŠ¸ë§µ ì´ë¯¸ì§€ ìƒì„±
            import matplotlib.pyplot as plt
            import seaborn as sns
            plt.figure(figsize=(8,6))
            sns.heatmap(corr, annot=True, fmt=".2f", cmap='coolwarm', square=True)
            plt.title("S&P500ê³¼ ê¸ˆë¦¬ ê´€ë ¨ ì§€í‘œ ê°„ ìƒê´€ê´€ê³„")
            buf = BytesIO()
            plt.tight_layout()
            plt.savefig(buf, format='png')
            plt.close()
            buf.seek(0)
            return StreamingResponse(buf, media_type="image/png")

        # show_plot=Falseì´ë©´ JSON ë°˜í™˜
        return result

    except Exception as e:
        print("âŒ /rate-correlations ì—ëŸ¬:", e)
        traceback.print_exc()
        return {"error": str(e)}
    

@app.get("/plot-sell-signals")
def plot_sell_signals():
    try:
        crawler = MacroCrawler()
        df = crawler.generate_rate_cut_signals()
        buf = BytesIO()
        # plot_sp500_with_sell_signalsëŠ” plt.show() ëŒ€ì‹  savefigë¥¼ ì§€ì›í•˜ë¯€ë¡œ save_to ì¸ìë¡œ BytesIO ì „ë‹¬
        crawler.plot_sp500_with_sell_signals()  # í•„ìš”í•˜ë‹¤ë©´ ìˆ˜ì •í•˜ì—¬ save_to ë§¤ê°œë³€ìˆ˜ ì¶”ê°€
        plt.savefig(buf, format='png')
        plt.close()
        buf.seek(0)
        return StreamingResponse(buf, media_type="image/png")
    except Exception as e:
        return {"error": str(e)}
    

@app.get("/plot-buy-signals")
def plot_buy_signals():
    try:
        crawler = MacroCrawler()
        df = crawler.generate_buy_signals_from_hike()
        buf = BytesIO()
        crawler.plot_buy_signals_from_hike()  # ë§ˆì°¬ê°€ì§€ë¡œ save_to ë§¤ê°œë³€ìˆ˜ë¥¼ ì¶”ê°€í•˜ëŠ” í¸ì´ ì¢‹ìŠµë‹ˆë‹¤.
        plt.savefig(buf, format='png')
        plt.close()
        buf.seek(0)
        return StreamingResponse(buf, media_type="image/png")
    except Exception as e:
        return {"error": str(e)}