import os
import pandas as pd
import re
import requests
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup



class LEIUpdater:
    def __init__(self, csv_path="lei_data.csv"):
        self.csv_path = csv_path
        try:
            self.df = pd.read_csv(self.csv_path, parse_dates=["date"], encoding='CP949')
            # self.df.columns = self.df.columns.str.strip()
            # self.df.columns = self.df.columns.str.replace('\ufeff', '', regex=False)
            print("âœ… LEI CSV ë¶ˆëŸ¬ì˜¤ê¸° ì„±ê³µ")
        
        except FileNotFoundError:
            print("âš ï¸ CSV íŒŒì¼ì´ ì—†ì–´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            self.df = pd.DataFrame(columns=[
                "Month/Year",
                "PMI"
            ])

    # def load_existing_data(self):
    #     if os.path.exists(self.csv_path):
    #         try:
    #             df = pd.read_csv(self.csv_path)
    #             df = self._preprocess_raw_csv(df)
    #             print(f"âœ… ê¸°ì¡´ PMI CSV ë¡œë“œ ì™„ë£Œ ({len(df)} rows)")
    #             return df
    #         except Exception as e:
    #             print(f"âŒ CSV ë¡œë”© ì˜¤ë¥˜: {e}")
    #             return pd.DataFrame(columns=["Month/Year", "PMI"])
    #     else:
    #         print("ğŸ“ ìƒˆ PMI ë°ì´í„°í”„ë ˆì„ ìƒì„±")
    #         return pd.DataFrame(columns=["Month/Year", "PMI"])

    def extract_date(self, val):
        try:
            # ì˜ˆ: "2025ë…„ 01ì›” 01ì¼ (12ì›”)"
            year_match = re.search(r"(\d{4})ë…„", val)
            announce_month_match = re.search(r"(\d{2})ì›”", val)  # ë°œí‘œì¼ì˜ ë‹¬ (ì•ìª½)
            data_month_match = re.search(r"\((\d{1,2})ì›”\)", val)
     
            if not (year_match and data_month_match):
                return None

            year = int(year_match.group(1))
            data_month = int(data_month_match.group(1))

            # ë°œí‘œì¼ì´ ë‹¤ìŒ í•´ì´ê³  ë°ì´í„°ëŠ” 12ì›”ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—°ë„ ë³´ì • í•„ìš”
            if announce_month_match:
                announce_month = int(announce_month_match.group(1))
                if data_month > announce_month:
                    year -= 1  # ë°ì´í„°ëŠ” ì‘ë…„ 12ì›”, ë°œí‘œëŠ” 1ì›”ì¸ ê²½ìš° ë³´ì •

            return pd.Timestamp(f"{year}-{data_month:02d}-01")
        except Exception as e:
            print(f"âŒ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {val} / {e}")
            return None

    def preprocess_raw_csv(self):
        # ë°œí‘œì¼: "2025ë…„ 08ì›” 01ì¼ (7ì›”)" â†’ 2025-07-01
        raw_df = self.df

        df = raw_df.copy()
        # df["Month/Year"] = raw_df["ë°œí‘œì¼"].apply(self.extract_date)
        # df["PMI"] = pd.to_numeric(raw_df["ì‹¤ì œ"], errors="coerce")
        df = df.dropna(subset=["date", "value"])
        df = df[["date", "value"]].drop_duplicates()
        df = df.sort_values("date")
        return df
    
    def get_us_leading_index_actual(self):
        """
        TradingEconomics ì›¹ í˜ì´ì§€ì—ì„œ ë¯¸êµ­ ì„ í–‰ ì§€ìˆ˜ì˜ ì‹¤ì œê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.

        Args:
            url (str): ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ TradingEconomics í˜ì´ì§€ì˜ URL.

        Returns:
            str: ì‹¤ì œê°’ (ì˜ˆ: '98.80') ë˜ëŠ” ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° None.
        """

        url = "https://ko.tradingeconomics.com/united-states/leading-economic-index"
    
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        
        extracted_data = []

        try:
            # ì›¹ í˜ì´ì§€ì— GET ìš”ì²­ ë³´ë‚´ê¸°
            print(f"URLì— ì ‘ì† ì¤‘: {url}")
            response = requests.get(url, headers=headers)
            response.raise_for_status() # HTTP ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì˜ˆì™¸ ë°œìƒ

            # BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±
            soup = BeautifulSoup(response.text, 'html.parser')

            # 'ctl00_ContentPlaceHolder1_ctl00_ctl00_PanelPeers' IDë¥¼ ê°€ì§„ divë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            panel_peers_div = soup.find('div', id='ctl00_ContentPlaceHolder1_ctl00_ctl00_PanelPeers')
            
            if panel_peers_div:
                # í•´ë‹¹ div ì•ˆì—ì„œ 'table-responsive' í´ë˜ìŠ¤ë¥¼ ê°€ì§„ divë¥¼ ì°¾ê³  ê·¸ ì•ˆì˜ 'table table-hover' í…Œì´ë¸”ì„ ì°¾ìŠµë‹ˆë‹¤.
                table_responsive_div = panel_peers_div.find('div', class_='table-responsive')
                if table_responsive_div:
                    data_table = table_responsive_div.find('table', class_='table table-hover')
                    
                    if data_table:
                        # í…Œì´ë¸” í—¤ë” ì¶”ì¶œ
                        header_row = data_table.find('thead').find('tr')
                        if header_row:
                            headers = [th.get_text(strip=True) for th in header_row.find_all('th')]
                            # ì²« ë²ˆì§¸ ë¹ˆ í—¤ë” ì œê±°
                            if headers and headers[0] == '':
                                headers = headers[1:]
                            print(f"ì¶”ì¶œëœ í—¤ë”: {headers}") # ë””ë²„ê¹…ìš©

                            # 'ë§ˆì§€ë§‰'ê³¼ 'ì°¸ê³ ' ì—´ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
                            try:
                                last_index = headers.index("ë§ˆì§€ë§‰")
                                ref_date_index = headers.index("ì°¸ê³ ")
                            except ValueError as e:
                                print(f"ERROR: í•„ìš”í•œ í—¤ë”('ë§ˆì§€ë§‰' ë˜ëŠ” 'ì°¸ê³ ')ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                                return []

                            # ë°ì´í„° í–‰ ìˆœíšŒ: tbody ìœ ë¬´ì™€ ìƒê´€ì—†ì´ í…Œì´ë¸” ë‚´ì˜ ëª¨ë“  <tr>ì„ ì°¾ê³ , í—¤ë” ë‹¤ìŒ í–‰ë¶€í„° ë°ì´í„°ë¡œ ì²˜ë¦¬
                            all_table_rows = data_table.find_all('tr')
                            
                            # í—¤ë” í–‰ ë‹¤ìŒë¶€í„° ì‹¤ì œ ë°ì´í„° í–‰ìœ¼ë¡œ ê°„ì£¼
                            # í—¤ë”ê°€ <thead> ì•ˆì— ìˆê³ , ë°ì´í„°ëŠ” <tbody> ì•ˆì— ëª…ì‹œë  ìˆ˜ë„ ìˆì§€ë§Œ,
                            # <tbody>ê°€ ì—†ëŠ” ê²½ìš° <tr>ì´ <table> ë°”ë¡œ ì•„ë˜ì— ì˜¬ ìˆ˜ ìˆìŒ.
                            # ë”°ë¼ì„œ thead ì•ˆì˜ trì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ trì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
                            data_rows = [row for row in all_table_rows if row.find_parent('thead') is None]

                            if data_rows:
                                for row in data_rows:
                                    # ì²« ë²ˆì§¸ tdëŠ” ì§€í‘œ ì´ë¦„ì´ë¯€ë¡œ ë”°ë¡œ ì²˜ë¦¬
                                    indicator_name_tag = row.find('td', style="padding-left: 10px; text-align: left;")
                                    indicator_name = indicator_name_tag.get_text(strip=True) if indicator_name_tag else "N/A"

                                    # ì§€í‘œ ì´ë¦„ ì…€ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì…€ì—ì„œ ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
                                    data_cells_excluding_indicator_name = row.find_all('td')[1:] 
                                    processed_data_cells = [cell.get_text(strip=True) for cell in data_cells_excluding_indicator_name]

                                    last_value = None
                                    ref_date = None

                                    # ì¶”ì¶œëœ í—¤ë”ì˜ ì¸ë±ìŠ¤ì— ë”°ë¼ ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
                                    if last_index < len(processed_data_cells):
                                        last_value = processed_data_cells[last_index]
                                    if ref_date_index < len(processed_data_cells):
                                        ref_date = processed_data_cells[ref_date_index]
                                    
                                    extracted_data.append({
                                        "indicator": indicator_name,
                                        "value": last_value,
                                        "date": ref_date
                                    })
                            else:
                                print("ERROR: í…Œì´ë¸”ì—ì„œ ë°ì´í„° í–‰(<tr>)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            print("ERROR: í…Œì´ë¸” í—¤ë” í–‰(<thead><tr>)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        print("ERROR: 'table table-hover' í´ë˜ìŠ¤ë¥¼ ê°€ì§„ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    print("ERROR: 'table-responsive' divë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print("ERROR: 'ctl00_ContentPlaceHolder1_ctl00_ctl00_PanelPeers' IDë¥¼ ê°€ì§„ divë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        except requests.exceptions.RequestException as e:
            print(f"ì›¹ í˜ì´ì§€ì— ì ‘ì†í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        except Exception as e:
            print(f"ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        return extracted_data[0]


    def parse_tradingeconomics_date(self, date_str):
        """
        'Jul 2025' â†’ pd.Timestamp('2025-07-01')
        """
        try:
            return pd.to_datetime(date_str + "-01", format="%b %Y-%d")
        except Exception as e:
            print(f"âŒ ë°œí‘œì¼ íŒŒì‹± ì‹¤íŒ¨: {date_str} / {e}")
            return None
        
    def update_csv(self):
        latest = self.get_us_leading_index_actual()  # {'ì§€í‘œëª…': ..., 'ê°’': '49.00', 'ë°œí‘œì¼': 'Jul 2025'}
        if not latest:
            print("âŒ LEI ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return self.df

        # 1. ë‚ ì§œ íŒŒì‹±
        month_year = self.parse_tradingeconomics_date(latest["date"])
        print("ë°ì´í„° ê¸°ì¤€ ì—°ì›” : ", month_year)
        if month_year is None:
            print("âŒ ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨")
            return self.df

        # 2. ì¤‘ë³µ ì²´í¬
        processed_df = self.df
        
        if (processed_df["date"] == month_year).any():
            print(f"ğŸ“­ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” LEI ë°ì´í„°ì…ë‹ˆë‹¤: {month_year.date()}")
            return processed_df

        # 3. ê°’ ë³€í™˜
        try:
            lei_value = float(latest["value"])
        except:
            print("âŒ LEI ê°’ ë³€í™˜ ì‹¤íŒ¨:", latest["value"])
            return processed_df

        # 4. ì›ë³¸ dfì— ìƒˆ í–‰ ì¶”ê°€
        new_row = pd.DataFrame([{
            "date": month_year.strftime("%Y-%m-%d"),
            "value" : lei_value
        }])
        self.df = pd.concat([self.df, new_row], ignore_index=True)


        # 5. ì €ì¥
        try:
            self.df.to_csv(self.csv_path, index=False, encoding="CP949")
            print(f"âœ… ìƒˆë¡œìš´ PMI ë°ì´í„° ì €ì¥ ì™„ë£Œ: {month_year.date()} / {lei_value}")
        except Exception as e:
            print("âŒ CSV ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)

        return self.df 

        

if __name__ == "__main__":
    cralwer = LEIUpdater()

    data = cralwer.update_csv()
    print(data)

