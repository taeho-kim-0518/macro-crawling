import streamlit as st
import pandas as pd
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
import random
from bs4 import BeautifulSoup

# --------- ì…€ë ˆë‹ˆì›€ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ---------
def init_driver():
    options = webdriver.ChromeOptions()
    # options.add_argument("--headless")  # ë””ë²„ê¹… ì‹œ ì£¼ì„
    driver = webdriver.Chrome(options=options)
    return driver

# --------- ì‡¼í•‘ ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ í•¨ìˆ˜ ---------
def analyze_shopping_ranking(driver, keyword, store_name):
    url = f"https://search.shopping.naver.com/search/all?query={keyword}"
    driver.get(url)
    time.sleep(random.uniform(2, 4))

    # âœ… ìŠ¤í¬ë¡¤ ë‹¤ìš´ì„ í†µí•´ ì¶”ê°€ ìƒí’ˆ ë¡œë”© ìœ ë„
    SCROLL_PAUSE_TIME = 1.0
    last_height = driver.execute_script("return document.body.scrollHeight")
    for _ in range(6):
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(SCROLL_PAUSE_TIME)
        new_height = driver.execute_script("return document.body.scrollHeight")
        if new_height == last_height:
            break
        last_height = new_height

    soup = BeautifulSoup(driver.page_source, "html.parser")

    all_elements = soup.select("div.adProduct_item__T7utB, div.superSavingProduct_item__6mR7_, div.product_item__KQayS")

    top_ads, mid_ads, products = [], [], []
    encountered_product = False
    ad_classnames = ["adProduct_item__T7utB", "superSavingProduct_item__6mR7_"]

    for el in all_elements:
        class_list = el.get("class", [])
        if any(cls in ad_classnames for cls in class_list):
            if not encountered_product:
                top_ads.append(el)
            else:
                mid_ads.append(el)
        elif "product_item__KQayS" in class_list:
            products.append(el)
            encountered_product = True

    def extract_store_name_from_ad(container):
        try:
            mall_divs = container.find_all("div")
            for div in mall_divs:
                cls_list = div.get("class", [])
                for cls in cls_list:
                    if cls.startswith("adProduct_mall_title__") or cls.startswith("superSavingProduct_mall_title__"):
                        a_tag = div.find("a")
                        if a_tag:
                            return a_tag.text.strip()
        except:
            return None
        return None

    def extract_store_name(container):
        for div in container.find_all("div"):
            if "product_mall_title__" in div.get("class", [""])[0]:
                a_tag = div.find("a")
                if a_tag:
                    return a_tag.text.strip()
        return None

    my_ad_index = None
    all_ads = top_ads + mid_ads
    for idx, ad in enumerate(all_ads, 1):
        name = extract_store_name_from_ad(ad)
        if name and store_name in name:
            my_ad_index = idx
            break

    my_product_index = None
    for idx, item in enumerate(products, 1):
        name = extract_store_name(item)
        if name and store_name in name:
            my_product_index = idx
            break

    return {
        "keyword": keyword,
        "ìƒë‹¨_ê´‘ê³ _ê°œìˆ˜": len(top_ads),
        "ì¤‘ë‹¨_ê´‘ê³ _ê°œìˆ˜": len(mid_ads),
        "ê´‘ê³ _ìƒí’ˆ_ê°œìˆ˜": len(all_ads),
        "ì¼ë°˜_ìƒí’ˆ_ê°œìˆ˜": len(products),
        "ê´‘ê³ _ë…¸ì¶œ": "ë…¸ì¶œë¨" if my_ad_index else "ë¯¸ë…¸ì¶œ",
        "ê´‘ê³ _ìˆœìœ„": my_ad_index if my_ad_index else "-",
        "ì¼ë°˜_ë…¸ì¶œ": "ë…¸ì¶œë¨" if my_product_index else "ë¯¸ë…¸ì¶œ",
        "ì¼ë°˜_ìˆœìœ„": my_product_index if my_product_index else "-"
    }

# --------- Streamlit UI ---------
st.set_page_config(page_title="ë„¤ì´ë²„ ì‡¼í•‘ ìˆœìœ„ ë¶„ì„ê¸°", layout="wide")
st.title("ğŸ›ï¸ ë„¤ì´ë²„ ì‡¼í•‘ ìˆœìœ„ ë¶„ì„ê¸°")

store_name = st.text_input("âœ… ë‚´ ì‡¼í•‘ëª° ì´ë¦„", placeholder="ì˜ˆ: í•˜ì´ê·¸ë¦°ì›°")
mode = st.radio("í‚¤ì›Œë“œ ì…ë ¥ ë°©ì‹ ì„ íƒ", ["ì§ì ‘ ì…ë ¥", "CSV ì—…ë¡œë“œ"])

keywords = []
if mode == "ì§ì ‘ ì…ë ¥":
    keywords_input = st.text_area("ğŸ“ í‚¤ì›Œë“œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”", placeholder="ì˜ˆ: ì—¬ì ì›í”¼ìŠ¤, ê°•ì•„ì§€ ì‚¬ë£Œ")
    if keywords_input:
        keywords = [kw.strip() for kw in keywords_input.split(",") if kw.strip()]
elif mode == "CSV ì—…ë¡œë“œ":
    uploaded_file = st.file_uploader("ğŸ“‚ í‚¤ì›Œë“œê°€ ë‹´ê¸´ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš” (ì»¬ëŸ¼ëª…: keyword)", type="csv")
    if uploaded_file:
        try:
            df = pd.read_csv(uploaded_file, encoding="cp949")
            if "keyword" in df.columns:
                keywords = df["keyword"].dropna().tolist()
                st.success(f"{len(keywords)}ê°œì˜ í‚¤ì›Œë“œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                st.error("CSV íŒŒì¼ì— 'keyword' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

if st.button("ğŸš€ ë¶„ì„ ì‹œì‘"):
    if not store_name:
        st.warning("â— ì‡¼í•‘ëª° ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif not keywords:
        st.warning("â— í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ê±°ë‚˜ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    else:
        st.info("ë¸Œë¼ìš°ì €ë¥¼ ì—´ê³  ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
        driver = init_driver()
        results = []
        progress = st.progress(0)
        for idx, kw in enumerate(keywords):
            st.write(f"ğŸ” {kw} ë¶„ì„ ì¤‘...")
            try:
                result = analyze_shopping_ranking(driver, kw, store_name)
                results.append(result)
            except Exception as e:
                results.append({"keyword": kw, "ì—ëŸ¬": str(e)})
            progress.progress((idx + 1) / len(keywords))
        driver.quit()
        df_result = pd.DataFrame(results)
        st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
        st.dataframe(df_result)
        csv_data = df_result.to_csv(index=False, encoding="utf-8-sig")
        st.download_button("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)", csv_data, file_name="shopping_ranking_result.csv", mime="text/csv")